2019-01-29 08:35:25.090 UTC [localconfig] completeInitialization -> INFO 001[0m Kafka.Version unset, setting to 0.10.2.0
[36m2019-01-29 08:35:25.091 UTC [bccsp_sw] openKeyStore -> DEBU 002[0m KeyStore opened at [/etc/hyperledger/fabric/orderer/msp/keystore]...done
[36m2019-01-29 08:35:25.091 UTC [bccsp] initBCCSP -> DEBU 003[0m Initialize BCCSP [SW]
[36m2019-01-29 08:35:25.091 UTC [msp] getPemMaterialFromDir -> DEBU 004[0m Reading directory /etc/hyperledger/fabric/orderer/msp/signcerts
[36m2019-01-29 08:35:25.091 UTC [msp] getPemMaterialFromDir -> DEBU 005[0m Inspecting file /etc/hyperledger/fabric/orderer/msp/signcerts/orderer0.hospital2.switch2logic.co.za-cert.pem
[36m2019-01-29 08:35:25.091 UTC [msp] getPemMaterialFromDir -> DEBU 006[0m Reading directory /etc/hyperledger/fabric/orderer/msp/cacerts
[36m2019-01-29 08:35:25.091 UTC [msp] getPemMaterialFromDir -> DEBU 007[0m Inspecting file /etc/hyperledger/fabric/orderer/msp/cacerts/ca.switch2logic.co.za-cert.pem
[36m2019-01-29 08:35:25.091 UTC [msp] getPemMaterialFromDir -> DEBU 008[0m Reading directory /etc/hyperledger/fabric/orderer/msp/admincerts
[36m2019-01-29 08:35:25.092 UTC [msp] getPemMaterialFromDir -> DEBU 009[0m Inspecting file /etc/hyperledger/fabric/orderer/msp/admincerts/Admin@switch2logic.co.za-cert.pem
[36m2019-01-29 08:35:25.092 UTC [msp] getPemMaterialFromDir -> DEBU 00a[0m Reading directory /etc/hyperledger/fabric/orderer/msp/intermediatecerts
[36m2019-01-29 08:35:25.092 UTC [msp] getMspConfig -> DEBU 00b[0m Intermediate certs folder not found at [/etc/hyperledger/fabric/orderer/msp/intermediatecerts]. Skipping. [stat /etc/hyperledger/fabric/orderer/msp/intermediatecerts: no such file or directory]
[36m2019-01-29 08:35:25.092 UTC [msp] getPemMaterialFromDir -> DEBU 00c[0m Reading directory /etc/hyperledger/fabric/orderer/msp/tlscacerts
[36m2019-01-29 08:35:25.092 UTC [msp] getPemMaterialFromDir -> DEBU 00d[0m Inspecting file /etc/hyperledger/fabric/orderer/msp/tlscacerts/tlsca.switch2logic.co.za-cert.pem
[36m2019-01-29 08:35:25.092 UTC [msp] getPemMaterialFromDir -> DEBU 00e[0m Reading directory /etc/hyperledger/fabric/orderer/msp/tlsintermediatecerts
[36m2019-01-29 08:35:25.092 UTC [msp] getMspConfig -> DEBU 00f[0m TLS intermediate certs folder not found at [/etc/hyperledger/fabric/orderer/msp/tlsintermediatecerts]. Skipping. [stat /etc/hyperledger/fabric/orderer/msp/tlsintermediatecerts: no such file or directory]
[36m2019-01-29 08:35:25.092 UTC [msp] getPemMaterialFromDir -> DEBU 010[0m Reading directory /etc/hyperledger/fabric/orderer/msp/crls
[36m2019-01-29 08:35:25.092 UTC [msp] getMspConfig -> DEBU 011[0m crls folder not found at [/etc/hyperledger/fabric/orderer/msp/crls]. Skipping. [stat /etc/hyperledger/fabric/orderer/msp/crls: no such file or directory]
[36m2019-01-29 08:35:25.092 UTC [msp] getMspConfig -> DEBU 012[0m MSP configuration file not found at [/etc/hyperledger/fabric/orderer/msp/config.yaml]: [stat /etc/hyperledger/fabric/orderer/msp/config.yaml: no such file or directory]
[36m2019-01-29 08:35:25.093 UTC [msp] newBccspMsp -> DEBU 013[0m Creating BCCSP-based MSP instance
[36m2019-01-29 08:35:25.093 UTC [msp] New -> DEBU 014[0m Creating Cache-MSP instance
[36m2019-01-29 08:35:25.093 UTC [msp] loadLocaMSP -> DEBU 015[0m Created new local MSP
[36m2019-01-29 08:35:25.093 UTC [msp] Setup -> DEBU 016[0m Setting up MSP instance OrdererMSP
[36m2019-01-29 08:35:25.093 UTC [msp/identity] newIdentity -> DEBU 017[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICSzCCAfKgAwIBAgIRAO7EFp+tGDrZX/4Yn1ExG4IwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowdzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEe
MBwGA1UEAxMVY2Euc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZI
zj0DAQcDQgAE+ci0VrQQEnBN2VlYMEvGL0RvqwQ9zVhgyxdKDi9AB8iyQ0dhyWzJ
CZ9MnAWGk29pw9b+9HdNkbalpJKWkcctJ6NfMF0wDgYDVR0PAQH/BAQDAgGmMA8G
A1UdJQQIMAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgGIY2e0Pm
0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDRwAwRAIgcoBa
RHN5r57Qu7sd8TwCzfyJI+uozczAYI2SsN06iKgCIAeAP4FbTHxjqSLcNZMNGbTZ
YWA1h+rDBMa99duId/0D
-----END CERTIFICATE-----
[36m2019-01-29 08:35:25.093 UTC [msp/identity] newIdentity -> DEBU 018[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICHzCCAcWgAwIBAgIQRo5Qm6m11gCv1i2SXwRJAjAKBggqhkjOPQQDAjB3MQsw
CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy
YW5jaXNjbzEbMBkGA1UEChMSc3dpdGNoMmxvZ2ljLmNvLnphMR4wHAYDVQQDExVj
YS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkwMTI5MDc0MTU0WhcNMjkwMTI2MDc0
MTU0WjBdMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UE
BxMNU2FuIEZyYW5jaXNjbzEhMB8GA1UEAwwYQWRtaW5Ac3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE0QeSwnrMZdy7TKSYF/JzQ12C
vfINZcjx7xyeUuj/96gj42fjc1ctn7oo/tDl1eJNZbDhFvkRzefYmxtoSnH5Y6NN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgGIY2
e0Pm0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDSAAwRQIh
AM8EkjCZIKrAf9sL1d1fThizng+66jmEVlKPbTpimVbiAiAhCJZoeBIJGcgxbCr2
5Rd2IW34zWcPhemkNZvCKv27WA==
-----END CERTIFICATE-----
[36m2019-01-29 08:35:25.120 UTC [msp/identity] newIdentity -> DEBU 019[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICLDCCAdOgAwIBAgIRALSnb5cS69ZjMJpS1JIoZEkwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowajELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xLjAsBgNVBAMTJW9yZGVyZXIwLmhvc3BpdGFsMi5z
d2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAAS6h69N
Iqb4d5ts04E2IRVEEawOWRIUoNntvpfHT6SnxVjSZi7exzn/YOTi0QQd6NGQa5iu
PFOZElkdCuGbgkyHo00wSzAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH/BAIwADAr
BgNVHSMEJDAigCAYhjZ7Q+bQZRvQvEDbHV3XtyLU0UWvqf/t8icEQrGycTAKBggq
hkjOPQQDAgNHADBEAiAqTM16gxhM8p3qA85cIM2a/xQXiZG35c3etBeP0/9uGAIg
FY2RcB+w2BjTJYTMYwIWQj/N9KTuAHugDITJ8afv1IU=
-----END CERTIFICATE-----
[36m2019-01-29 08:35:25.121 UTC [bccsp_sw] loadPrivateKey -> DEBU 01a[0m Loading private key [6cc0af06e32c6be74c9cb70b0bbf8dc9b0729ca7c2db8fba1fcd4ed4a9dfedd6] at [/etc/hyperledger/fabric/orderer/msp/keystore/6cc0af06e32c6be74c9cb70b0bbf8dc9b0729ca7c2db8fba1fcd4ed4a9dfedd6_sk]...
[36m2019-01-29 08:35:25.121 UTC [msp/identity] newIdentity -> DEBU 01b[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICLDCCAdOgAwIBAgIRALSnb5cS69ZjMJpS1JIoZEkwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowajELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xLjAsBgNVBAMTJW9yZGVyZXIwLmhvc3BpdGFsMi5z
d2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAAS6h69N
Iqb4d5ts04E2IRVEEawOWRIUoNntvpfHT6SnxVjSZi7exzn/YOTi0QQd6NGQa5iu
PFOZElkdCuGbgkyHo00wSzAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH/BAIwADAr
BgNVHSMEJDAigCAYhjZ7Q+bQZRvQvEDbHV3XtyLU0UWvqf/t8icEQrGycTAKBggq
hkjOPQQDAgNHADBEAiAqTM16gxhM8p3qA85cIM2a/xQXiZG35c3etBeP0/9uGAIg
FY2RcB+w2BjTJYTMYwIWQj/N9KTuAHugDITJ8afv1IU=
-----END CERTIFICATE-----
[36m2019-01-29 08:35:25.121 UTC [msp] setupSigningIdentity -> DEBU 01c[0m Signing identity expires at 2029-01-26 07:41:54 +0000 UTC
[36m2019-01-29 08:35:25.121 UTC [msp] Validate -> DEBU 01d[0m MSP OrdererMSP validating identity
2019-01-29 08:35:25.122 UTC [orderer/common/server] prettyPrintStruct -> INFO 01e[0m Orderer config values:
	General.LedgerType = "file"
	General.ListenAddress = "0.0.0.0"
	General.ListenPort = 7050
	General.TLS.Enabled = true
	General.TLS.PrivateKey = "/etc/hyperledger/fabric/orderer/tls/server.key"
	General.TLS.Certificate = "/etc/hyperledger/fabric/orderer/tls/server.crt"
	General.TLS.RootCAs = [/etc/hyperledger/fabric/orderer/tls/ca.crt]
	General.TLS.ClientAuthRequired = false
	General.TLS.ClientRootCAs = []
	General.Keepalive.ServerMinInterval = 1m0s
	General.Keepalive.ServerInterval = 2h0m0s
	General.Keepalive.ServerTimeout = 20s
	General.GenesisMethod = "file"
	General.GenesisProfile = "SampleInsecureSolo"
	General.SystemChannel = "test-system-channel-name"
	General.GenesisFile = "/etc/hyperledger/fabric/orderer/channel-artifacts/genesis.block"
	General.Profile.Enabled = false
	General.Profile.Address = "0.0.0.0:6060"
	General.LogLevel = "debug"
	General.LogFormat = "%{color}%{time:2006-01-02 15:04:05.000 MST} [%{module}] %{shortfunc} -> %{level:.4s} %{id:03x}%{color:reset} %{message}"
	General.LocalMSPDir = "/etc/hyperledger/fabric/orderer/msp"
	General.LocalMSPID = "OrdererMSP"
	General.BCCSP.ProviderName = "SW"
	General.BCCSP.SwOpts.SecLevel = 256
	General.BCCSP.SwOpts.HashFamily = "SHA2"
	General.BCCSP.SwOpts.Ephemeral = false
	General.BCCSP.SwOpts.FileKeystore.KeyStorePath = "/etc/hyperledger/fabric/orderer/msp/keystore"
	General.BCCSP.SwOpts.DummyKeystore =
	General.BCCSP.PluginOpts =
	General.Authentication.TimeWindow = 15m0s
	FileLedger.Location = "/var/hyperledger/production/orderer"
	FileLedger.Prefix = "hyperledger-fabric-ordererledger"
	RAMLedger.HistorySize = 1000
	Kafka.Retry.ShortInterval = 1s
	Kafka.Retry.ShortTotal = 30s
	Kafka.Retry.LongInterval = 5m0s
	Kafka.Retry.LongTotal = 12h0m0s
	Kafka.Retry.NetworkTimeouts.DialTimeout = 10s
	Kafka.Retry.NetworkTimeouts.ReadTimeout = 10s
	Kafka.Retry.NetworkTimeouts.WriteTimeout = 10s
	Kafka.Retry.Metadata.RetryMax = 3
	Kafka.Retry.Metadata.RetryBackoff = 250ms
	Kafka.Retry.Producer.RetryMax = 3
	Kafka.Retry.Producer.RetryBackoff = 100ms
	Kafka.Retry.Consumer.RetryBackoff = 2s
	Kafka.Verbose = true
	Kafka.Version = 0.10.2.0
	Kafka.TLS.Enabled = false
	Kafka.TLS.PrivateKey = ""
	Kafka.TLS.Certificate = ""
	Kafka.TLS.RootCAs = []
	Kafka.TLS.ClientAuthRequired = false
	Kafka.TLS.ClientRootCAs = []
	Debug.BroadcastTraceDir = ""
	Debug.DeliverTraceDir = ""
2019-01-29 08:35:25.122 UTC [orderer/common/server] initializeServerConfig -> INFO 01f[0m Starting orderer with TLS enabled
[36m2019-01-29 08:35:25.122 UTC [orderer/common/server] createLedgerFactory -> DEBU 020[0m Ledger dir: /var/hyperledger/production/orderer
[36m2019-01-29 08:35:25.122 UTC [kvledger.util] CreateDirIfMissing -> DEBU 021[0m CreateDirIfMissing [/var/hyperledger/production/orderer/index/]
[36m2019-01-29 08:35:25.123 UTC [kvledger.util] logDirStatus -> DEBU 022[0m Before creating dir - [/var/hyperledger/production/orderer/index/] does not exist
[36m2019-01-29 08:35:25.123 UTC [kvledger.util] logDirStatus -> DEBU 023[0m After creating dir - [/var/hyperledger/production/orderer/index/] exists
[36m2019-01-29 08:35:25.137 UTC [fsblkstorage] newBlockfileMgr -> DEBU 024[0m newBlockfileMgr() initializing file-based block storage for ledger: testchainid 
[36m2019-01-29 08:35:25.137 UTC [kvledger.util] CreateDirIfMissing -> DEBU 025[0m CreateDirIfMissing [/var/hyperledger/production/orderer/chains/testchainid/]
[36m2019-01-29 08:35:25.137 UTC [kvledger.util] logDirStatus -> DEBU 026[0m Before creating dir - [/var/hyperledger/production/orderer/chains/testchainid/] does not exist
[36m2019-01-29 08:35:25.137 UTC [kvledger.util] logDirStatus -> DEBU 027[0m After creating dir - [/var/hyperledger/production/orderer/chains/testchainid/] exists
2019-01-29 08:35:25.137 UTC [fsblkstorage] newBlockfileMgr -> INFO 028[0m Getting block information from block storage
[36m2019-01-29 08:35:25.137 UTC [fsblkstorage] constructCheckpointInfoFromBlockFiles -> DEBU 029[0m Retrieving checkpoint info from block files
[36m2019-01-29 08:35:25.137 UTC [fsblkstorage] retrieveLastFileSuffix -> DEBU 02a[0m retrieveLastFileSuffix()
[36m2019-01-29 08:35:25.137 UTC [fsblkstorage] retrieveLastFileSuffix -> DEBU 02b[0m retrieveLastFileSuffix() - biggestFileNum = -1
[36m2019-01-29 08:35:25.137 UTC [fsblkstorage] constructCheckpointInfoFromBlockFiles -> DEBU 02c[0m Last file number found = -1
[36m2019-01-29 08:35:25.137 UTC [fsblkstorage] constructCheckpointInfoFromBlockFiles -> DEBU 02d[0m No block file found
[36m2019-01-29 08:35:25.138 UTC [fsblkstorage] newBlockfileMgr -> DEBU 02e[0m Info constructed by scanning the blocks dir = (*fsblkstorage.checkpointInfo)(0xc4201964c0)(latestFileChunkSuffixNum=[0], latestFileChunksize=[0], isChainEmpty=[true], lastBlockNumber=[0])
[36m2019-01-29 08:35:25.140 UTC [fsblkstorage] newBlockIndex -> DEBU 02f[0m newBlockIndex() - indexItems:[[BlockNum]]
[36m2019-01-29 08:35:25.142 UTC [fsblkstorage] indexBlock -> DEBU 030[0m Indexing block [blockNum=0, blockHash=[]byte{0xc8, 0x4c, 0x51, 0xe5, 0x9, 0x21, 0xc0, 0x29, 0x44, 0x5, 0xe4, 0x1d, 0x16, 0xcb, 0x62, 0x34, 0x27, 0x3f, 0x63, 0xb3, 0x7a, 0x24, 0x4, 0x38, 0xcc, 0x9f, 0x32, 0x57, 0x82, 0x77, 0xd7, 0xe3} txOffsets=
txId=1ca8e655ef3c6dabf8d05124961ee605d33f75882de63b75c8df80edea408fb6 locPointer=offset=39, bytesLength=18451
]
[36m2019-01-29 08:35:25.144 UTC [fsblkstorage] updateCheckpoint -> DEBU 031[0m Broadcasting about update checkpointInfo: latestFileChunkSuffixNum=[0], latestFileChunksize=[18495], isChainEmpty=[false], lastBlockNumber=[0]
[36m2019-01-29 08:35:25.145 UTC [fsblkstorage] Next -> DEBU 032[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=0
[36m2019-01-29 08:35:25.145 UTC [fsblkstorage] newBlockfileStream -> DEBU 033[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[0]
[36m2019-01-29 08:35:25.145 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 034[0m Remaining bytes=[18495], Going to peek [8] bytes
[36m2019-01-29 08:35:25.146 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 035[0m Returning blockbytes - length=[18492], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 08:35:25.146 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 036[0m blockbytes [18492] read from file [0]
[36m2019-01-29 08:35:25.146 UTC [fsblkstorage] Next -> DEBU 037[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=0
[36m2019-01-29 08:35:25.146 UTC [fsblkstorage] newBlockfileStream -> DEBU 038[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[0]
[36m2019-01-29 08:35:25.147 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 039[0m Remaining bytes=[18495], Going to peek [8] bytes
[36m2019-01-29 08:35:25.147 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 03a[0m Returning blockbytes - length=[18492], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 08:35:25.147 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 03b[0m blockbytes [18492] read from file [0]
[36m2019-01-29 08:35:25.147 UTC [common/channelconfig] NewStandardValues -> DEBU 03c[0m Initializing protos for *channelconfig.ChannelProtos
[36m2019-01-29 08:35:25.147 UTC [common/channelconfig] initializeProtosStruct -> DEBU 03d[0m Processing field: HashingAlgorithm
[36m2019-01-29 08:35:25.148 UTC [common/channelconfig] initializeProtosStruct -> DEBU 03e[0m Processing field: BlockDataHashingStructure
[36m2019-01-29 08:35:25.148 UTC [common/channelconfig] initializeProtosStruct -> DEBU 03f[0m Processing field: OrdererAddresses
[36m2019-01-29 08:35:25.148 UTC [common/channelconfig] initializeProtosStruct -> DEBU 040[0m Processing field: Consortium
[36m2019-01-29 08:35:25.148 UTC [common/channelconfig] initializeProtosStruct -> DEBU 041[0m Processing field: Capabilities
[36m2019-01-29 08:35:25.148 UTC [common/channelconfig] NewStandardValues -> DEBU 042[0m Initializing protos for *channelconfig.ConsortiumProtos
[36m2019-01-29 08:35:25.148 UTC [common/channelconfig] initializeProtosStruct -> DEBU 043[0m Processing field: ChannelCreationPolicy
[36m2019-01-29 08:35:25.148 UTC [common/channelconfig] NewStandardValues -> DEBU 044[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 08:35:25.148 UTC [common/channelconfig] initializeProtosStruct -> DEBU 045[0m Processing field: MSP
[36m2019-01-29 08:35:25.148 UTC [common/channelconfig] validateMSP -> DEBU 046[0m Setting up MSP for org Hospital1MSP
[36m2019-01-29 08:35:25.148 UTC [msp] newBccspMsp -> DEBU 047[0m Creating BCCSP-based MSP instance
[36m2019-01-29 08:35:25.148 UTC [msp] New -> DEBU 048[0m Creating Cache-MSP instance
[36m2019-01-29 08:35:25.149 UTC [msp] Setup -> DEBU 049[0m Setting up MSP instance Hospital1MSP
[36m2019-01-29 08:35:25.149 UTC [msp/identity] newIdentity -> DEBU 04a[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdDCCAhugAwIBAgIQZxH8VsnceZxXgKxlURLgVTAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMS5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQX9V4k/h/3pFxByKDscjgQrC0YS/bSbKvzSG2Z2PvltEWp40qB9OaKUN0GQYzo
yK2Etdvyjfd1OFwaTjpGSvv9o18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCBVU7DoP9Msf/nNTNl6
5FxwAXZ82eaGBT7zWYdyh4QbBjAKBggqhkjOPQQDAgNHADBEAiBmXGWQbxCGRp0c
5/y9qJyciB1CDHsknRZDjNzt5f563wIgMy7VPi1R8DpIIIRN9B3mfhDpRa+J+8PA
S4DOJy7rjp4=
-----END CERTIFICATE-----
[36m2019-01-29 08:35:25.150 UTC [msp/identity] newIdentity -> DEBU 04b[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfWgAwIBAgIQbzxpSKiuJCzDiDlZp+XbWDAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjB4MQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZyYW5jaXNjbzEPMA0GA1UECxMG
Y2xpZW50MSswKQYDVQQDDCJBZG1pbkBob3NwaXRhbDEuc3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEnpADl8+aUBcVWv6q3IgMQ4yg
ISawQ0wamHmpSv+/b1B5hf4V2HyoPrawIr45+o4/Qz++WazZlyY7PkoT27r7KaNN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgVVOw
6D/TLH/5zUzZeuRccAF2fNnmhgU+81mHcoeEGwYwCgYIKoZIzj0EAwIDSAAwRQIh
ALavdMm9i6xSsnWdlliMh10s6dmGBaXO0CxaCowLJIMtAiBEduudGJymDDE1zbiX
YwX83cYWZHUcYV8IXeZPFymC+w==
-----END CERTIFICATE-----
[36m2019-01-29 08:35:25.151 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 04c[0m Checking if identity satisfies role [CLIENT] for Hospital1MSP
[36m2019-01-29 08:35:25.151 UTC [msp] Validate -> DEBU 04d[0m MSP Hospital1MSP validating identity
[36m2019-01-29 08:35:25.151 UTC [msp] getCertificationChain -> DEBU 04e[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 08:35:25.152 UTC [msp] hasOURole -> DEBU 04f[0m MSP Hospital1MSP checking if the identity is a client
[36m2019-01-29 08:35:25.152 UTC [msp] getCertificationChain -> DEBU 050[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 08:35:25.152 UTC [common/channelconfig] NewStandardValues -> DEBU 051[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 08:35:25.152 UTC [common/channelconfig] initializeProtosStruct -> DEBU 052[0m Processing field: MSP
[36m2019-01-29 08:35:25.152 UTC [common/channelconfig] validateMSP -> DEBU 053[0m Setting up MSP for org Hospital2MSP
[36m2019-01-29 08:35:25.152 UTC [msp] newBccspMsp -> DEBU 054[0m Creating BCCSP-based MSP instance
[36m2019-01-29 08:35:25.152 UTC [msp] New -> DEBU 055[0m Creating Cache-MSP instance
[36m2019-01-29 08:35:25.152 UTC [msp] Setup -> DEBU 056[0m Setting up MSP instance Hospital2MSP
[36m2019-01-29 08:35:25.152 UTC [msp/identity] newIdentity -> DEBU 057[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdjCCAhygAwIBAgIRALZ3Pffn/xWUtUWPSK6CYVAwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFowgYsxCzAJBgNVBAYTAlVTMRMwEQYD
VQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4gRnJhbmNpc2NvMSUwIwYDVQQK
Exxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMSgwJgYDVQQDEx9jYS5ob3Nw
aXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcD
QgAESzVpiz6P4mIb+KwvrttcXJKZR5i137Is4298E7OrkYdAg0tB4rpfKTXzUMwW
vI12cTDujpyaZSiqQ3/zP4fOQqNfMF0wDgYDVR0PAQH/BAQDAgGmMA8GA1UdJQQI
MAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQg8QJqWKPaX24HINwR
S6sINFSwRD+440/ccSnvFVaGF24wCgYIKoZIzj0EAwIDSAAwRQIhAPO2Nng3/nqb
cKPliUqVPVjBMu+D55M90+jexWSOpkjcAiADPx8qv9exZ4BfP3+G49Qzpx0Meblj
53vzUgYFa/0EXw==
-----END CERTIFICATE-----
[36m2019-01-29 08:35:25.152 UTC [msp/identity] newIdentity -> DEBU 058[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAJ6XtHMTTW1JzdpD54qCc3wwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwyLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABA+z1rb9aA1HwHfNLi9V9VZe
bdwT4MXak445zGz4DXzRUsmNeBngzntKb6qpgHQpeFtzbzLx+zwiynRDvfdzORGj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIPEC
alij2l9uByDcEUurCDRUsEQ/uONP3HEp7xVWhhduMAoGCCqGSM49BAMCA0cAMEQC
IA8A3CCJeCasyy7gYd/M1aHYmwWsecY7UY7cVUGy4XOxAiB0rrmfnGW6JA11PDCu
+5c5Rpn0jF5ddsFn+UIpzBFvmg==
-----END CERTIFICATE-----
[36m2019-01-29 08:35:25.153 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 059[0m Checking if identity satisfies role [CLIENT] for Hospital2MSP
[36m2019-01-29 08:35:25.153 UTC [msp] Validate -> DEBU 05a[0m MSP Hospital2MSP validating identity
[36m2019-01-29 08:35:25.153 UTC [msp] getCertificationChain -> DEBU 05b[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 08:35:25.153 UTC [msp] hasOURole -> DEBU 05c[0m MSP Hospital2MSP checking if the identity is a client
[36m2019-01-29 08:35:25.153 UTC [msp] getCertificationChain -> DEBU 05d[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 08:35:25.154 UTC [common/channelconfig] NewStandardValues -> DEBU 05e[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 08:35:25.154 UTC [common/channelconfig] initializeProtosStruct -> DEBU 05f[0m Processing field: MSP
[36m2019-01-29 08:35:25.154 UTC [common/channelconfig] validateMSP -> DEBU 060[0m Setting up MSP for org Hospital3MSP
[36m2019-01-29 08:35:25.154 UTC [msp] newBccspMsp -> DEBU 061[0m Creating BCCSP-based MSP instance
[36m2019-01-29 08:35:25.154 UTC [msp] New -> DEBU 062[0m Creating Cache-MSP instance
[36m2019-01-29 08:35:25.154 UTC [msp] Setup -> DEBU 063[0m Setting up MSP instance Hospital3MSP
[36m2019-01-29 08:35:25.154 UTC [msp/identity] newIdentity -> DEBU 064[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdTCCAhugAwIBAgIQCCXeHGgObIJo8aq4AdvgVjAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMy5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQm1Oo/AEu7ZZToE15Y5ntlaN128Hs/exX3jNH5nO6r4tvyFtBBNEn1ecXxxPtm
dmQ+nPHONorLwDC42SMAKwfro18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCA7vVWFXWpgZBojQ1ZL
xUvgBLeia59MivIRcjxmYanpyTAKBggqhkjOPQQDAgNIADBFAiEAlOUoPtpfO8V7
vFRCanjU5zZWGO5ajFlPDJjjDTy3UrwCICrUYV32JrR/m3dslCl15dSThHrKtYCC
Ehvyw1+lNqiG
-----END CERTIFICATE-----
[36m2019-01-29 08:35:25.154 UTC [msp/identity] newIdentity -> DEBU 065[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAI8BA/5Jf+5m8ncI+D7aSiMwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwzLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABF1IehIKIjh8tXYZ7rw4QOuc
g/tpBAkJeOt44zr/LepbjhyFW8vIRnkw75i6Wcg+LOoAS+2NFNg2oNjqg//yCHWj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIDu9
VYVdamBkGiNDVkvFS+AEt6Jrn0yK8hFyPGZhqenJMAoGCCqGSM49BAMCA0cAMEQC
IFyc85pwbCAxGNdw4fflsX2I3HrP3h93YAB2zSDC8HtkAiAQxblAZfEnXUiQKrqE
8I10bYJqD6pJz1jb3Pv+4xplTA==
-----END CERTIFICATE-----
[36m2019-01-29 08:35:25.155 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 066[0m Checking if identity satisfies role [CLIENT] for Hospital3MSP
[36m2019-01-29 08:35:25.155 UTC [msp] Validate -> DEBU 067[0m MSP Hospital3MSP validating identity
[36m2019-01-29 08:35:25.155 UTC [msp] getCertificationChain -> DEBU 068[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 08:35:25.155 UTC [msp] hasOURole -> DEBU 069[0m MSP Hospital3MSP checking if the identity is a client
[36m2019-01-29 08:35:25.155 UTC [msp] getCertificationChain -> DEBU 06a[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 08:35:25.155 UTC [common/channelconfig] NewStandardValues -> DEBU 06b[0m Initializing protos for *channelconfig.OrdererProtos
[36m2019-01-29 08:35:25.155 UTC [common/channelconfig] initializeProtosStruct -> DEBU 06c[0m Processing field: ConsensusType
[36m2019-01-29 08:35:25.155 UTC [common/channelconfig] initializeProtosStruct -> DEBU 06d[0m Processing field: BatchSize
[36m2019-01-29 08:35:25.155 UTC [common/channelconfig] initializeProtosStruct -> DEBU 06e[0m Processing field: BatchTimeout
[36m2019-01-29 08:35:25.155 UTC [common/channelconfig] initializeProtosStruct -> DEBU 06f[0m Processing field: KafkaBrokers
[36m2019-01-29 08:35:25.155 UTC [common/channelconfig] initializeProtosStruct -> DEBU 070[0m Processing field: ChannelRestrictions
[36m2019-01-29 08:35:25.155 UTC [common/channelconfig] initializeProtosStruct -> DEBU 071[0m Processing field: Capabilities
[36m2019-01-29 08:35:25.155 UTC [common/channelconfig] NewStandardValues -> DEBU 072[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 08:35:25.156 UTC [common/channelconfig] initializeProtosStruct -> DEBU 073[0m Processing field: MSP
[36m2019-01-29 08:35:25.156 UTC [common/channelconfig] validateMSP -> DEBU 074[0m Setting up MSP for org OrdererOrg
[36m2019-01-29 08:35:25.156 UTC [msp] newBccspMsp -> DEBU 075[0m Creating BCCSP-based MSP instance
[36m2019-01-29 08:35:25.156 UTC [msp] New -> DEBU 076[0m Creating Cache-MSP instance
[36m2019-01-29 08:35:25.156 UTC [msp] Setup -> DEBU 077[0m Setting up MSP instance OrdererMSP
[36m2019-01-29 08:35:25.156 UTC [msp/identity] newIdentity -> DEBU 078[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICSzCCAfKgAwIBAgIRAO7EFp+tGDrZX/4Yn1ExG4IwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowdzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEe
MBwGA1UEAxMVY2Euc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZI
zj0DAQcDQgAE+ci0VrQQEnBN2VlYMEvGL0RvqwQ9zVhgyxdKDi9AB8iyQ0dhyWzJ
CZ9MnAWGk29pw9b+9HdNkbalpJKWkcctJ6NfMF0wDgYDVR0PAQH/BAQDAgGmMA8G
A1UdJQQIMAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgGIY2e0Pm
0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDRwAwRAIgcoBa
RHN5r57Qu7sd8TwCzfyJI+uozczAYI2SsN06iKgCIAeAP4FbTHxjqSLcNZMNGbTZ
YWA1h+rDBMa99duId/0D
-----END CERTIFICATE-----
[36m2019-01-29 08:35:25.156 UTC [msp/identity] newIdentity -> DEBU 079[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICHzCCAcWgAwIBAgIQRo5Qm6m11gCv1i2SXwRJAjAKBggqhkjOPQQDAjB3MQsw
CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy
YW5jaXNjbzEbMBkGA1UEChMSc3dpdGNoMmxvZ2ljLmNvLnphMR4wHAYDVQQDExVj
YS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkwMTI5MDc0MTU0WhcNMjkwMTI2MDc0
MTU0WjBdMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UE
BxMNU2FuIEZyYW5jaXNjbzEhMB8GA1UEAwwYQWRtaW5Ac3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE0QeSwnrMZdy7TKSYF/JzQ12C
vfINZcjx7xyeUuj/96gj42fjc1ctn7oo/tDl1eJNZbDhFvkRzefYmxtoSnH5Y6NN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgGIY2
e0Pm0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDSAAwRQIh
AM8EkjCZIKrAf9sL1d1fThizng+66jmEVlKPbTpimVbiAiAhCJZoeBIJGcgxbCr2
5Rd2IW34zWcPhemkNZvCKv27WA==
-----END CERTIFICATE-----
[36m2019-01-29 08:35:25.156 UTC [msp] Validate -> DEBU 07a[0m MSP OrdererMSP validating identity
[36m2019-01-29 08:35:25.157 UTC [msp] Setup -> DEBU 07b[0m Setting up the MSP manager (4 msps)
[36m2019-01-29 08:35:25.157 UTC [msp] Setup -> DEBU 07c[0m MSP manager setup complete, setup 4 msps
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 07d[0m Proposed new policy Admins for Channel/Consortiums/HospitalConsortium/Hospital1MSP
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 07e[0m Proposed new policy Readers for Channel/Consortiums/HospitalConsortium/Hospital1MSP
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 07f[0m Proposed new policy Writers for Channel/Consortiums/HospitalConsortium/Hospital1MSP
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 080[0m Proposed new policy Admins for Channel/Consortiums/HospitalConsortium/Hospital2MSP
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 081[0m Proposed new policy Readers for Channel/Consortiums/HospitalConsortium/Hospital2MSP
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 082[0m Proposed new policy Writers for Channel/Consortiums/HospitalConsortium/Hospital2MSP
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 083[0m Proposed new policy Admins for Channel/Consortiums/HospitalConsortium/Hospital3MSP
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 084[0m Proposed new policy Readers for Channel/Consortiums/HospitalConsortium/Hospital3MSP
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 085[0m Proposed new policy Writers for Channel/Consortiums/HospitalConsortium/Hospital3MSP
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 086[0m Proposed new policy Admins for Channel/Consortiums
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 087[0m Proposed new policy Readers for Channel/Orderer/OrdererOrg
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 088[0m Proposed new policy Writers for Channel/Orderer/OrdererOrg
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 089[0m Proposed new policy Admins for Channel/Orderer/OrdererOrg
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 08a[0m Proposed new policy Admins for Channel/Orderer
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 08b[0m Proposed new policy Readers for Channel/Orderer
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 08c[0m Proposed new policy Writers for Channel/Orderer
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 08d[0m Proposed new policy BlockValidation for Channel/Orderer
[36m2019-01-29 08:35:25.157 UTC [policies] GetPolicy -> DEBU 08e[0m Returning dummy reject all policy because Writers could not be found in Channel/Consortiums/Writers
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 08f[0m Proposed new policy Writers for Channel
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 090[0m Proposed new policy Admins for Channel
[36m2019-01-29 08:35:25.157 UTC [policies] GetPolicy -> DEBU 091[0m Returning dummy reject all policy because Readers could not be found in Channel/Consortiums/Readers
[36m2019-01-29 08:35:25.157 UTC [policies] NewManagerImpl -> DEBU 092[0m Proposed new policy Readers for Channel
[36m2019-01-29 08:35:25.157 UTC [common/configtx] addToMap -> DEBU 093[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 08:35:25.157 UTC [common/configtx] addToMap -> DEBU 094[0m Adding to config map: [Group]  /Channel/Consortiums
[36m2019-01-29 08:35:25.157 UTC [common/configtx] addToMap -> DEBU 095[0m Adding to config map: [Group]  /Channel/Consortiums/HospitalConsortium
[36m2019-01-29 08:35:25.157 UTC [common/configtx] addToMap -> DEBU 096[0m Adding to config map: [Group]  /Channel/Consortiums/HospitalConsortium/Hospital2MSP
[36m2019-01-29 08:35:25.157 UTC [common/configtx] addToMap -> DEBU 097[0m Adding to config map: [Value]  /Channel/Consortiums/HospitalConsortium/Hospital2MSP/MSP
[36m2019-01-29 08:35:25.157 UTC [common/configtx] addToMap -> DEBU 098[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital2MSP/Writers
[36m2019-01-29 08:35:25.157 UTC [common/configtx] addToMap -> DEBU 099[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital2MSP/Admins
[36m2019-01-29 08:35:25.157 UTC [common/configtx] addToMap -> DEBU 09a[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital2MSP/Readers
[36m2019-01-29 08:35:25.157 UTC [common/configtx] addToMap -> DEBU 09b[0m Adding to config map: [Group]  /Channel/Consortiums/HospitalConsortium/Hospital3MSP
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 09c[0m Adding to config map: [Value]  /Channel/Consortiums/HospitalConsortium/Hospital3MSP/MSP
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 09d[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital3MSP/Admins
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 09e[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital3MSP/Readers
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 09f[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital3MSP/Writers
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0a0[0m Adding to config map: [Group]  /Channel/Consortiums/HospitalConsortium/Hospital1MSP
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0a1[0m Adding to config map: [Value]  /Channel/Consortiums/HospitalConsortium/Hospital1MSP/MSP
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0a2[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital1MSP/Admins
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0a3[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital1MSP/Readers
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0a4[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital1MSP/Writers
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0a5[0m Adding to config map: [Value]  /Channel/Consortiums/HospitalConsortium/ChannelCreationPolicy
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0a6[0m Adding to config map: [Policy] /Channel/Consortiums/Admins
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0a7[0m Adding to config map: [Group]  /Channel/Orderer
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0a8[0m Adding to config map: [Group]  /Channel/Orderer/OrdererOrg
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0a9[0m Adding to config map: [Value]  /Channel/Orderer/OrdererOrg/MSP
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0aa[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Readers
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0ab[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Writers
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0ac[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Admins
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0ad[0m Adding to config map: [Value]  /Channel/Orderer/Capabilities
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0ae[0m Adding to config map: [Value]  /Channel/Orderer/KafkaBrokers
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0af[0m Adding to config map: [Value]  /Channel/Orderer/ConsensusType
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0b0[0m Adding to config map: [Value]  /Channel/Orderer/BatchSize
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0b1[0m Adding to config map: [Value]  /Channel/Orderer/BatchTimeout
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0b2[0m Adding to config map: [Value]  /Channel/Orderer/ChannelRestrictions
[36m2019-01-29 08:35:25.158 UTC [common/configtx] addToMap -> DEBU 0b3[0m Adding to config map: [Policy] /Channel/Orderer/Admins
[36m2019-01-29 08:35:25.159 UTC [common/configtx] addToMap -> DEBU 0b4[0m Adding to config map: [Policy] /Channel/Orderer/Readers
[36m2019-01-29 08:35:25.159 UTC [common/configtx] addToMap -> DEBU 0b5[0m Adding to config map: [Policy] /Channel/Orderer/Writers
[36m2019-01-29 08:35:25.159 UTC [common/configtx] addToMap -> DEBU 0b6[0m Adding to config map: [Policy] /Channel/Orderer/BlockValidation
[36m2019-01-29 08:35:25.159 UTC [common/configtx] addToMap -> DEBU 0b7[0m Adding to config map: [Value]  /Channel/HashingAlgorithm
[36m2019-01-29 08:35:25.159 UTC [common/configtx] addToMap -> DEBU 0b8[0m Adding to config map: [Value]  /Channel/BlockDataHashingStructure
[36m2019-01-29 08:35:25.159 UTC [common/configtx] addToMap -> DEBU 0b9[0m Adding to config map: [Value]  /Channel/OrdererAddresses
[36m2019-01-29 08:35:25.159 UTC [common/configtx] addToMap -> DEBU 0ba[0m Adding to config map: [Value]  /Channel/Capabilities
[36m2019-01-29 08:35:25.159 UTC [common/configtx] addToMap -> DEBU 0bb[0m Adding to config map: [Policy] /Channel/Admins
[36m2019-01-29 08:35:25.159 UTC [common/configtx] addToMap -> DEBU 0bc[0m Adding to config map: [Policy] /Channel/Readers
[36m2019-01-29 08:35:25.159 UTC [common/configtx] addToMap -> DEBU 0bd[0m Adding to config map: [Policy] /Channel/Writers
[36m2019-01-29 08:35:25.159 UTC [common/channelconfig] LogSanityChecks -> DEBU 0be[0m As expected, current configuration has policy '/Channel/Readers'
[36m2019-01-29 08:35:25.159 UTC [common/channelconfig] LogSanityChecks -> DEBU 0bf[0m As expected, current configuration has policy '/Channel/Writers'
[36m2019-01-29 08:35:25.159 UTC [policies] Manager -> DEBU 0c0[0m Manager Channel looking up path [Application]
[36m2019-01-29 08:35:25.160 UTC [policies] Manager -> DEBU 0c1[0m Manager Channel has managers Consortiums
[36m2019-01-29 08:35:25.160 UTC [policies] Manager -> DEBU 0c2[0m Manager Channel has managers Orderer
[36m2019-01-29 08:35:25.160 UTC [policies] Manager -> DEBU 0c3[0m Manager Channel looking up path [Orderer]
[36m2019-01-29 08:35:25.160 UTC [policies] Manager -> DEBU 0c4[0m Manager Channel has managers Consortiums
[36m2019-01-29 08:35:25.160 UTC [policies] Manager -> DEBU 0c5[0m Manager Channel has managers Orderer
[36m2019-01-29 08:35:25.160 UTC [policies] Manager -> DEBU 0c6[0m Manager Channel/Orderer looking up path []
[36m2019-01-29 08:35:25.160 UTC [policies] Manager -> DEBU 0c7[0m Manager Channel/Orderer has managers OrdererOrg
[36m2019-01-29 08:35:25.160 UTC [common/channelconfig] LogSanityChecks -> DEBU 0c8[0m As expected, current configuration has policy '/Channel/Orderer/BlockValidation'
[36m2019-01-29 08:35:25.160 UTC [common/capabilities] Supported -> DEBU 0c9[0m Orderer capability V1_1 is supported and is enabled
[36m2019-01-29 08:35:25.160 UTC [common/capabilities] Supported -> DEBU 0ca[0m Channel capability V1_1 is supported and is enabled
[36m2019-01-29 08:35:25.160 UTC [fsblkstorage] Next -> DEBU 0cb[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=0
[36m2019-01-29 08:35:25.160 UTC [fsblkstorage] newBlockfileStream -> DEBU 0cc[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[0]
[36m2019-01-29 08:35:25.160 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0cd[0m Remaining bytes=[18495], Going to peek [8] bytes
[36m2019-01-29 08:35:25.160 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0ce[0m Returning blockbytes - length=[18492], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 08:35:25.160 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0cf[0m blockbytes [18492] read from file [0]
[36m2019-01-29 08:35:25.160 UTC [orderer/commmon/multichannel] newBlockWriter -> DEBU 0d0[0m [channel: testchainid] Creating block writer for tip of chain (blockNumber=0, lastConfigBlockNum=0, lastConfigSeq=0)
2019-01-29 08:35:25.160 UTC [orderer/consensus/kafka] newChain -> INFO 0d1[0m [channel: testchainid] Starting chain with last persisted offset -3 and last recorded block 0
[36m2019-01-29 08:35:25.160 UTC [orderer/commmon/multichannel] newChainSupport -> DEBU 0d2[0m [channel: testchainid] Done creating channel support resources
[36m2019-01-29 08:35:25.160 UTC [orderer/common/msgprocessor] NewSystemChannel -> DEBU 0d3[0m Creating system channel msg processor for channel testchainid
[36m2019-01-29 08:35:25.160 UTC [fsblkstorage] Next -> DEBU 0d4[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=0
[36m2019-01-29 08:35:25.160 UTC [fsblkstorage] newBlockfileStream -> DEBU 0d5[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[0]
[36m2019-01-29 08:35:25.160 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0d6[0m Remaining bytes=[18495], Going to peek [8] bytes
[36m2019-01-29 08:35:25.160 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0d7[0m Returning blockbytes - length=[18492], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 08:35:25.160 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0d8[0m blockbytes [18492] read from file [0]
2019-01-29 08:35:25.160 UTC [orderer/commmon/multichannel] NewRegistrar -> INFO 0d9[0m Starting system channel 'testchainid' with genesis block hash c84c51e50921c0294405e41d16cb6234273f63b37a240438cc9f32578277d7e3 and orderer type kafka
2019-01-29 08:35:25.160 UTC [orderer/common/server] Start -> INFO 0da[0m Starting orderer:
 Version: 1.2.0
 Commit SHA: cae2ad4
 Go version: go1.10
 OS/Arch: linux/amd64
 Experimental features: false
2019-01-29 08:35:25.161 UTC [orderer/common/server] Start -> INFO 0db[0m Beginning to serve requests
2019-01-29 08:35:25.161 UTC [orderer/consensus/kafka] setupProducerForChannel -> INFO 0dc[0m [channel: testchainid] Setting up the producer for this channel...
[36m2019-01-29 08:35:25.161 UTC [orderer/consensus/kafka] try -> DEBU 0dd[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 08:35:25.161 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 0de[0m Initializing new client
[36m2019-01-29 08:35:25.161 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 0df[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:35:25.161 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 0e0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:35:25.161 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 0e1[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 08:35:25.162 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 0e2[0m Connected to broker at kafka0.switch2logic.co.za:9092 (unregistered)
[36m2019-01-29 08:35:25.163 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 0e3[0m client/brokers registered new broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 08:35:25.164 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 0e4[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 08:35:25.164 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 0e5[0m client/brokers registered new broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 08:35:25.164 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 0e6[0m Successfully initialized new client
[36m2019-01-29 08:35:25.164 UTC [orderer/consensus/kafka] try -> DEBU 0e7[0m [channel: testchainid] Error is nil, breaking the retry loop
2019-01-29 08:35:25.164 UTC [orderer/consensus/kafka] startThread -> INFO 0e8[0m [channel: testchainid] Producer set up successfully
2019-01-29 08:35:25.164 UTC [orderer/consensus/kafka] sendConnectMessage -> INFO 0e9[0m [channel: testchainid] About to post the CONNECT message...
[36m2019-01-29 08:35:25.164 UTC [orderer/consensus/kafka] try -> DEBU 0ea[0m [channel: testchainid] Attempting to post the CONNECT message...
[36m2019-01-29 08:35:25.164 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 0eb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:35:25.164 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU 0ec[0m producer/broker/1 starting up
[36m2019-01-29 08:35:25.164 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU 0ed[0m producer/broker/1 state change to [open] on testchainid/0
[36m2019-01-29 08:35:25.165 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 0ee[0m Connected to broker at kafka1.switch2logic.co.za:9092 (registered as #1)
[36m2019-01-29 08:35:25.174 UTC [orderer/consensus/kafka] try -> DEBU 0ef[0m [channel: testchainid] Error is nil, breaking the retry loop
2019-01-29 08:35:25.174 UTC [orderer/consensus/kafka] startThread -> INFO 0f0[0m [channel: testchainid] CONNECT message posted successfully
2019-01-29 08:35:25.174 UTC [orderer/consensus/kafka] setupParentConsumerForChannel -> INFO 0f1[0m [channel: testchainid] Setting up the parent consumer for this channel...
[36m2019-01-29 08:35:25.174 UTC [orderer/consensus/kafka] try -> DEBU 0f2[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 08:35:25.174 UTC [orderer/consensus/kafka/sarama] NewConsumer -> DEBU 0f3[0m Initializing new client
[36m2019-01-29 08:35:25.174 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 0f4[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:35:25.174 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 0f5[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:35:25.174 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 0f6[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 08:35:25.175 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 0f7[0m Connected to broker at kafka0.switch2logic.co.za:9092 (unregistered)
[36m2019-01-29 08:35:25.178 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 0f8[0m client/brokers registered new broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 08:35:25.178 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 0f9[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 08:35:25.178 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 0fa[0m client/brokers registered new broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 08:35:25.178 UTC [orderer/consensus/kafka/sarama] NewConsumer -> DEBU 0fb[0m Successfully initialized new client
[36m2019-01-29 08:35:25.178 UTC [orderer/consensus/kafka] try -> DEBU 0fc[0m [channel: testchainid] Error is nil, breaking the retry loop
2019-01-29 08:35:25.178 UTC [orderer/consensus/kafka] startThread -> INFO 0fd[0m [channel: testchainid] Parent consumer set up successfully
2019-01-29 08:35:25.178 UTC [orderer/consensus/kafka] setupChannelConsumerForChannel -> INFO 0fe[0m [channel: testchainid] Setting up the channel consumer for this channel (start offset: -2)...
[36m2019-01-29 08:35:25.179 UTC [orderer/consensus/kafka] try -> DEBU 0ff[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 08:35:25.179 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 100[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:35:25.179 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 101[0m Connected to broker at kafka1.switch2logic.co.za:9092 (registered as #1)
[36m2019-01-29 08:35:25.181 UTC [orderer/consensus/kafka/sarama] subscriptionConsumer -> DEBU 103[0m consumer/broker/1 added subscription to testchainid/0
[36m2019-01-29 08:35:25.181 UTC [orderer/consensus/kafka] try -> DEBU 102[0m [channel: testchainid] Error is nil, breaking the retry loop
2019-01-29 08:35:25.181 UTC [orderer/consensus/kafka] startThread -> INFO 104[0m [channel: testchainid] Channel consumer set up successfully
2019-01-29 08:35:25.181 UTC [orderer/consensus/kafka] startThread -> INFO 105[0m [channel: testchainid] Start phase completed successfully
[36m2019-01-29 08:35:25.183 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 106[0m [channel: testchainid] Successfully unmarshalled consumed message, offset is 0. Inspecting type...
[36m2019-01-29 08:35:25.183 UTC [orderer/consensus/kafka] processConnect -> DEBU 107[0m [channel: testchainid] It's a connect message - ignoring
[36m2019-01-29 08:35:25.183 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 108[0m [channel: testchainid] Successfully unmarshalled consumed message, offset is 1. Inspecting type...
[36m2019-01-29 08:35:25.183 UTC [orderer/consensus/kafka] processConnect -> DEBU 109[0m [channel: testchainid] It's a connect message - ignoring
[36m2019-01-29 08:35:25.183 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 10a[0m [channel: testchainid] Successfully unmarshalled consumed message, offset is 2. Inspecting type...
[36m2019-01-29 08:35:25.183 UTC [orderer/consensus/kafka] processConnect -> DEBU 10b[0m [channel: testchainid] It's a connect message - ignoring
[36m2019-01-29 08:35:25.183 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 10c[0m [channel: testchainid] Successfully unmarshalled consumed message, offset is 3. Inspecting type...
[36m2019-01-29 08:35:25.183 UTC [orderer/consensus/kafka] processConnect -> DEBU 10d[0m [channel: testchainid] It's a connect message - ignoring
[36m2019-01-29 08:42:47.098 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 10e[0m [channel: testchainid] Successfully unmarshalled consumed message, offset is 4. Inspecting type...
[36m2019-01-29 08:42:47.098 UTC [orderer/consensus/kafka] processConnect -> DEBU 10f[0m [channel: testchainid] It's a connect message - ignoring
[36m2019-01-29 08:45:25.164 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 110[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 08:45:25.179 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 111[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 08:50:44.538 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 112[0m [channel: testchainid] Successfully unmarshalled consumed message, offset is 5. Inspecting type...
[36m2019-01-29 08:50:44.538 UTC [orderer/consensus/kafka] processRegular -> DEBU 113[0m [channel: testchainid] Processing regular Kafka message of type CONFIG
[36m2019-01-29 08:50:44.538 UTC [orderer/consensus/kafka] func2 -> DEBU 114[0m [channel: testchainid] Received config message
[36m2019-01-29 08:50:44.538 UTC [orderer/consensus/kafka] func2 -> DEBU 115[0m [channel: testchainid] Creating isolated block for config message
[36m2019-01-29 08:50:44.539 UTC [common/channelconfig] NewStandardValues -> DEBU 116[0m Initializing protos for *channelconfig.ChannelProtos
[36m2019-01-29 08:50:44.539 UTC [common/channelconfig] initializeProtosStruct -> DEBU 117[0m Processing field: HashingAlgorithm
[36m2019-01-29 08:50:44.539 UTC [common/channelconfig] initializeProtosStruct -> DEBU 118[0m Processing field: BlockDataHashingStructure
[36m2019-01-29 08:50:44.539 UTC [common/channelconfig] initializeProtosStruct -> DEBU 119[0m Processing field: OrdererAddresses
[36m2019-01-29 08:50:44.539 UTC [common/channelconfig] initializeProtosStruct -> DEBU 11a[0m Processing field: Consortium
[36m2019-01-29 08:50:44.539 UTC [common/channelconfig] initializeProtosStruct -> DEBU 11b[0m Processing field: Capabilities
[36m2019-01-29 08:50:44.539 UTC [common/channelconfig] NewStandardValues -> DEBU 11c[0m Initializing protos for *channelconfig.ApplicationProtos
[36m2019-01-29 08:50:44.539 UTC [common/channelconfig] initializeProtosStruct -> DEBU 11d[0m Processing field: ACLs
[36m2019-01-29 08:50:44.540 UTC [common/channelconfig] initializeProtosStruct -> DEBU 11e[0m Processing field: Capabilities
[36m2019-01-29 08:50:44.540 UTC [common/channelconfig] NewStandardValues -> DEBU 11f[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 08:50:44.540 UTC [common/channelconfig] initializeProtosStruct -> DEBU 120[0m Processing field: AnchorPeers
[36m2019-01-29 08:50:44.540 UTC [common/channelconfig] NewStandardValues -> DEBU 121[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 08:50:44.540 UTC [common/channelconfig] initializeProtosStruct -> DEBU 122[0m Processing field: MSP
[36m2019-01-29 08:50:44.540 UTC [common/channelconfig] Validate -> DEBU 123[0m Anchor peers for org Hospital2MSP are 
[36m2019-01-29 08:50:44.540 UTC [common/channelconfig] validateMSP -> DEBU 124[0m Setting up MSP for org Hospital2MSP
[36m2019-01-29 08:50:44.540 UTC [msp] newBccspMsp -> DEBU 125[0m Creating BCCSP-based MSP instance
[36m2019-01-29 08:50:44.540 UTC [msp] New -> DEBU 126[0m Creating Cache-MSP instance
[36m2019-01-29 08:50:44.540 UTC [msp] Setup -> DEBU 127[0m Setting up MSP instance Hospital2MSP
[36m2019-01-29 08:50:44.541 UTC [msp/identity] newIdentity -> DEBU 128[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdjCCAhygAwIBAgIRALZ3Pffn/xWUtUWPSK6CYVAwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFowgYsxCzAJBgNVBAYTAlVTMRMwEQYD
VQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4gRnJhbmNpc2NvMSUwIwYDVQQK
Exxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMSgwJgYDVQQDEx9jYS5ob3Nw
aXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcD
QgAESzVpiz6P4mIb+KwvrttcXJKZR5i137Is4298E7OrkYdAg0tB4rpfKTXzUMwW
vI12cTDujpyaZSiqQ3/zP4fOQqNfMF0wDgYDVR0PAQH/BAQDAgGmMA8GA1UdJQQI
MAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQg8QJqWKPaX24HINwR
S6sINFSwRD+440/ccSnvFVaGF24wCgYIKoZIzj0EAwIDSAAwRQIhAPO2Nng3/nqb
cKPliUqVPVjBMu+D55M90+jexWSOpkjcAiADPx8qv9exZ4BfP3+G49Qzpx0Meblj
53vzUgYFa/0EXw==
-----END CERTIFICATE-----
[36m2019-01-29 08:50:44.541 UTC [msp/identity] newIdentity -> DEBU 129[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAJ6XtHMTTW1JzdpD54qCc3wwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwyLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABA+z1rb9aA1HwHfNLi9V9VZe
bdwT4MXak445zGz4DXzRUsmNeBngzntKb6qpgHQpeFtzbzLx+zwiynRDvfdzORGj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIPEC
alij2l9uByDcEUurCDRUsEQ/uONP3HEp7xVWhhduMAoGCCqGSM49BAMCA0cAMEQC
IA8A3CCJeCasyy7gYd/M1aHYmwWsecY7UY7cVUGy4XOxAiB0rrmfnGW6JA11PDCu
+5c5Rpn0jF5ddsFn+UIpzBFvmg==
-----END CERTIFICATE-----
[36m2019-01-29 08:50:44.543 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 12a[0m Checking if identity satisfies role [CLIENT] for Hospital2MSP
[36m2019-01-29 08:50:44.543 UTC [msp] Validate -> DEBU 12b[0m MSP Hospital2MSP validating identity
[36m2019-01-29 08:50:44.544 UTC [msp] getCertificationChain -> DEBU 12c[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 08:50:44.545 UTC [msp] hasOURole -> DEBU 12d[0m MSP Hospital2MSP checking if the identity is a client
[36m2019-01-29 08:50:44.545 UTC [msp] getCertificationChain -> DEBU 12e[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 08:50:44.545 UTC [common/channelconfig] NewStandardValues -> DEBU 12f[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 08:50:44.545 UTC [common/channelconfig] initializeProtosStruct -> DEBU 130[0m Processing field: AnchorPeers
[36m2019-01-29 08:50:44.545 UTC [common/channelconfig] NewStandardValues -> DEBU 131[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 08:50:44.545 UTC [common/channelconfig] initializeProtosStruct -> DEBU 132[0m Processing field: MSP
[36m2019-01-29 08:50:44.545 UTC [common/channelconfig] Validate -> DEBU 133[0m Anchor peers for org Hospital3MSP are 
[36m2019-01-29 08:50:44.545 UTC [common/channelconfig] validateMSP -> DEBU 134[0m Setting up MSP for org Hospital3MSP
[36m2019-01-29 08:50:44.545 UTC [msp] newBccspMsp -> DEBU 135[0m Creating BCCSP-based MSP instance
[36m2019-01-29 08:50:44.545 UTC [msp] New -> DEBU 136[0m Creating Cache-MSP instance
[36m2019-01-29 08:50:44.546 UTC [msp] Setup -> DEBU 137[0m Setting up MSP instance Hospital3MSP
[36m2019-01-29 08:50:44.546 UTC [msp/identity] newIdentity -> DEBU 138[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdTCCAhugAwIBAgIQCCXeHGgObIJo8aq4AdvgVjAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMy5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQm1Oo/AEu7ZZToE15Y5ntlaN128Hs/exX3jNH5nO6r4tvyFtBBNEn1ecXxxPtm
dmQ+nPHONorLwDC42SMAKwfro18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCA7vVWFXWpgZBojQ1ZL
xUvgBLeia59MivIRcjxmYanpyTAKBggqhkjOPQQDAgNIADBFAiEAlOUoPtpfO8V7
vFRCanjU5zZWGO5ajFlPDJjjDTy3UrwCICrUYV32JrR/m3dslCl15dSThHrKtYCC
Ehvyw1+lNqiG
-----END CERTIFICATE-----
[36m2019-01-29 08:50:44.547 UTC [msp/identity] newIdentity -> DEBU 139[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAI8BA/5Jf+5m8ncI+D7aSiMwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwzLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABF1IehIKIjh8tXYZ7rw4QOuc
g/tpBAkJeOt44zr/LepbjhyFW8vIRnkw75i6Wcg+LOoAS+2NFNg2oNjqg//yCHWj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIDu9
VYVdamBkGiNDVkvFS+AEt6Jrn0yK8hFyPGZhqenJMAoGCCqGSM49BAMCA0cAMEQC
IFyc85pwbCAxGNdw4fflsX2I3HrP3h93YAB2zSDC8HtkAiAQxblAZfEnXUiQKrqE
8I10bYJqD6pJz1jb3Pv+4xplTA==
-----END CERTIFICATE-----
[36m2019-01-29 08:50:44.548 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 13a[0m Checking if identity satisfies role [CLIENT] for Hospital3MSP
[36m2019-01-29 08:50:44.548 UTC [msp] Validate -> DEBU 13b[0m MSP Hospital3MSP validating identity
[36m2019-01-29 08:50:44.548 UTC [msp] getCertificationChain -> DEBU 13c[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 08:50:44.549 UTC [msp] hasOURole -> DEBU 13d[0m MSP Hospital3MSP checking if the identity is a client
[36m2019-01-29 08:50:44.549 UTC [msp] getCertificationChain -> DEBU 13e[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 08:50:44.550 UTC [common/channelconfig] NewStandardValues -> DEBU 13f[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 08:50:44.550 UTC [common/channelconfig] initializeProtosStruct -> DEBU 140[0m Processing field: AnchorPeers
[36m2019-01-29 08:50:44.550 UTC [common/channelconfig] NewStandardValues -> DEBU 141[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 08:50:44.550 UTC [common/channelconfig] initializeProtosStruct -> DEBU 142[0m Processing field: MSP
[36m2019-01-29 08:50:44.550 UTC [common/channelconfig] Validate -> DEBU 143[0m Anchor peers for org Hospital1MSP are 
[36m2019-01-29 08:50:44.550 UTC [common/channelconfig] validateMSP -> DEBU 144[0m Setting up MSP for org Hospital1MSP
[36m2019-01-29 08:50:44.550 UTC [msp] newBccspMsp -> DEBU 145[0m Creating BCCSP-based MSP instance
[36m2019-01-29 08:50:44.550 UTC [msp] New -> DEBU 146[0m Creating Cache-MSP instance
[36m2019-01-29 08:50:44.550 UTC [msp] Setup -> DEBU 147[0m Setting up MSP instance Hospital1MSP
[36m2019-01-29 08:50:44.551 UTC [msp/identity] newIdentity -> DEBU 148[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdDCCAhugAwIBAgIQZxH8VsnceZxXgKxlURLgVTAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMS5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQX9V4k/h/3pFxByKDscjgQrC0YS/bSbKvzSG2Z2PvltEWp40qB9OaKUN0GQYzo
yK2Etdvyjfd1OFwaTjpGSvv9o18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCBVU7DoP9Msf/nNTNl6
5FxwAXZ82eaGBT7zWYdyh4QbBjAKBggqhkjOPQQDAgNHADBEAiBmXGWQbxCGRp0c
5/y9qJyciB1CDHsknRZDjNzt5f563wIgMy7VPi1R8DpIIIRN9B3mfhDpRa+J+8PA
S4DOJy7rjp4=
-----END CERTIFICATE-----
[36m2019-01-29 08:50:44.551 UTC [msp/identity] newIdentity -> DEBU 149[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfWgAwIBAgIQbzxpSKiuJCzDiDlZp+XbWDAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjB4MQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZyYW5jaXNjbzEPMA0GA1UECxMG
Y2xpZW50MSswKQYDVQQDDCJBZG1pbkBob3NwaXRhbDEuc3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEnpADl8+aUBcVWv6q3IgMQ4yg
ISawQ0wamHmpSv+/b1B5hf4V2HyoPrawIr45+o4/Qz++WazZlyY7PkoT27r7KaNN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgVVOw
6D/TLH/5zUzZeuRccAF2fNnmhgU+81mHcoeEGwYwCgYIKoZIzj0EAwIDSAAwRQIh
ALavdMm9i6xSsnWdlliMh10s6dmGBaXO0CxaCowLJIMtAiBEduudGJymDDE1zbiX
YwX83cYWZHUcYV8IXeZPFymC+w==
-----END CERTIFICATE-----
[36m2019-01-29 08:50:44.552 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 14a[0m Checking if identity satisfies role [CLIENT] for Hospital1MSP
[36m2019-01-29 08:50:44.552 UTC [msp] Validate -> DEBU 14b[0m MSP Hospital1MSP validating identity
[36m2019-01-29 08:50:44.552 UTC [msp] getCertificationChain -> DEBU 14c[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 08:50:44.563 UTC [msp] hasOURole -> DEBU 14d[0m MSP Hospital1MSP checking if the identity is a client
[36m2019-01-29 08:50:44.563 UTC [msp] getCertificationChain -> DEBU 14e[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 08:50:44.563 UTC [common/channelconfig] NewStandardValues -> DEBU 14f[0m Initializing protos for *channelconfig.OrdererProtos
[36m2019-01-29 08:50:44.564 UTC [common/channelconfig] initializeProtosStruct -> DEBU 150[0m Processing field: ConsensusType
[36m2019-01-29 08:50:44.566 UTC [common/channelconfig] initializeProtosStruct -> DEBU 151[0m Processing field: BatchSize
[36m2019-01-29 08:50:44.567 UTC [common/channelconfig] initializeProtosStruct -> DEBU 152[0m Processing field: BatchTimeout
[36m2019-01-29 08:50:44.567 UTC [common/channelconfig] initializeProtosStruct -> DEBU 153[0m Processing field: KafkaBrokers
[36m2019-01-29 08:50:44.567 UTC [common/channelconfig] initializeProtosStruct -> DEBU 154[0m Processing field: ChannelRestrictions
[36m2019-01-29 08:50:44.568 UTC [common/channelconfig] initializeProtosStruct -> DEBU 155[0m Processing field: Capabilities
[36m2019-01-29 08:50:44.568 UTC [common/channelconfig] NewStandardValues -> DEBU 156[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 08:50:44.569 UTC [common/channelconfig] initializeProtosStruct -> DEBU 157[0m Processing field: MSP
[36m2019-01-29 08:50:44.569 UTC [common/channelconfig] validateMSP -> DEBU 158[0m Setting up MSP for org OrdererOrg
[36m2019-01-29 08:50:44.569 UTC [msp] newBccspMsp -> DEBU 159[0m Creating BCCSP-based MSP instance
[36m2019-01-29 08:50:44.569 UTC [msp] New -> DEBU 15a[0m Creating Cache-MSP instance
[36m2019-01-29 08:50:44.569 UTC [msp] Setup -> DEBU 15b[0m Setting up MSP instance OrdererMSP
[36m2019-01-29 08:50:44.576 UTC [msp/identity] newIdentity -> DEBU 15c[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICSzCCAfKgAwIBAgIRAO7EFp+tGDrZX/4Yn1ExG4IwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowdzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEe
MBwGA1UEAxMVY2Euc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZI
zj0DAQcDQgAE+ci0VrQQEnBN2VlYMEvGL0RvqwQ9zVhgyxdKDi9AB8iyQ0dhyWzJ
CZ9MnAWGk29pw9b+9HdNkbalpJKWkcctJ6NfMF0wDgYDVR0PAQH/BAQDAgGmMA8G
A1UdJQQIMAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgGIY2e0Pm
0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDRwAwRAIgcoBa
RHN5r57Qu7sd8TwCzfyJI+uozczAYI2SsN06iKgCIAeAP4FbTHxjqSLcNZMNGbTZ
YWA1h+rDBMa99duId/0D
-----END CERTIFICATE-----
[36m2019-01-29 08:50:44.577 UTC [msp/identity] newIdentity -> DEBU 15d[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICHzCCAcWgAwIBAgIQRo5Qm6m11gCv1i2SXwRJAjAKBggqhkjOPQQDAjB3MQsw
CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy
YW5jaXNjbzEbMBkGA1UEChMSc3dpdGNoMmxvZ2ljLmNvLnphMR4wHAYDVQQDExVj
YS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkwMTI5MDc0MTU0WhcNMjkwMTI2MDc0
MTU0WjBdMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UE
BxMNU2FuIEZyYW5jaXNjbzEhMB8GA1UEAwwYQWRtaW5Ac3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE0QeSwnrMZdy7TKSYF/JzQ12C
vfINZcjx7xyeUuj/96gj42fjc1ctn7oo/tDl1eJNZbDhFvkRzefYmxtoSnH5Y6NN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgGIY2
e0Pm0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDSAAwRQIh
AM8EkjCZIKrAf9sL1d1fThizng+66jmEVlKPbTpimVbiAiAhCJZoeBIJGcgxbCr2
5Rd2IW34zWcPhemkNZvCKv27WA==
-----END CERTIFICATE-----
[36m2019-01-29 08:50:44.578 UTC [msp] Validate -> DEBU 15e[0m MSP OrdererMSP validating identity
[36m2019-01-29 08:50:44.582 UTC [msp] Setup -> DEBU 15f[0m Setting up the MSP manager (4 msps)
[36m2019-01-29 08:50:44.583 UTC [msp] Setup -> DEBU 160[0m MSP manager setup complete, setup 4 msps
[36m2019-01-29 08:50:44.583 UTC [policies] NewManagerImpl -> DEBU 161[0m Proposed new policy Admins for Channel/Application/Hospital1MSP
[36m2019-01-29 08:50:44.583 UTC [policies] NewManagerImpl -> DEBU 162[0m Proposed new policy Readers for Channel/Application/Hospital1MSP
[36m2019-01-29 08:50:44.583 UTC [policies] NewManagerImpl -> DEBU 163[0m Proposed new policy Writers for Channel/Application/Hospital1MSP
[36m2019-01-29 08:50:44.583 UTC [policies] NewManagerImpl -> DEBU 164[0m Proposed new policy Readers for Channel/Application/Hospital2MSP
[36m2019-01-29 08:50:44.583 UTC [policies] NewManagerImpl -> DEBU 165[0m Proposed new policy Writers for Channel/Application/Hospital2MSP
[36m2019-01-29 08:50:44.583 UTC [policies] NewManagerImpl -> DEBU 166[0m Proposed new policy Admins for Channel/Application/Hospital2MSP
[36m2019-01-29 08:50:44.583 UTC [policies] NewManagerImpl -> DEBU 167[0m Proposed new policy Admins for Channel/Application/Hospital3MSP
[36m2019-01-29 08:50:44.583 UTC [policies] NewManagerImpl -> DEBU 168[0m Proposed new policy Readers for Channel/Application/Hospital3MSP
[36m2019-01-29 08:50:44.583 UTC [policies] NewManagerImpl -> DEBU 169[0m Proposed new policy Writers for Channel/Application/Hospital3MSP
[36m2019-01-29 08:50:44.584 UTC [policies] NewManagerImpl -> DEBU 16a[0m Proposed new policy Writers for Channel/Application
[36m2019-01-29 08:50:44.584 UTC [policies] NewManagerImpl -> DEBU 16b[0m Proposed new policy Admins for Channel/Application
[36m2019-01-29 08:50:44.584 UTC [policies] NewManagerImpl -> DEBU 16c[0m Proposed new policy Readers for Channel/Application
[36m2019-01-29 08:50:44.584 UTC [policies] NewManagerImpl -> DEBU 16d[0m Proposed new policy Admins for Channel/Orderer/OrdererOrg
[36m2019-01-29 08:50:44.584 UTC [policies] NewManagerImpl -> DEBU 16e[0m Proposed new policy Readers for Channel/Orderer/OrdererOrg
[36m2019-01-29 08:50:44.584 UTC [policies] NewManagerImpl -> DEBU 16f[0m Proposed new policy Writers for Channel/Orderer/OrdererOrg
[36m2019-01-29 08:50:44.584 UTC [policies] NewManagerImpl -> DEBU 170[0m Proposed new policy Readers for Channel/Orderer
[36m2019-01-29 08:50:44.585 UTC [policies] NewManagerImpl -> DEBU 171[0m Proposed new policy Writers for Channel/Orderer
[36m2019-01-29 08:50:44.585 UTC [policies] NewManagerImpl -> DEBU 172[0m Proposed new policy BlockValidation for Channel/Orderer
[36m2019-01-29 08:50:44.585 UTC [policies] NewManagerImpl -> DEBU 173[0m Proposed new policy Admins for Channel/Orderer
[36m2019-01-29 08:50:44.585 UTC [policies] NewManagerImpl -> DEBU 174[0m Proposed new policy Readers for Channel
[36m2019-01-29 08:50:44.586 UTC [policies] NewManagerImpl -> DEBU 175[0m Proposed new policy Writers for Channel
[36m2019-01-29 08:50:44.586 UTC [policies] NewManagerImpl -> DEBU 176[0m Proposed new policy Admins for Channel
[36m2019-01-29 08:50:44.586 UTC [common/configtx] addToMap -> DEBU 177[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 08:50:44.586 UTC [common/configtx] addToMap -> DEBU 178[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 08:50:44.586 UTC [common/configtx] addToMap -> DEBU 179[0m Adding to config map: [Group]  /Channel/Application/Hospital1MSP
[36m2019-01-29 08:50:44.587 UTC [common/configtx] addToMap -> DEBU 17a[0m Adding to config map: [Value]  /Channel/Application/Hospital1MSP/MSP
[36m2019-01-29 08:50:44.587 UTC [common/configtx] addToMap -> DEBU 17b[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Admins
[36m2019-01-29 08:50:44.588 UTC [common/configtx] addToMap -> DEBU 17c[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Readers
[36m2019-01-29 08:50:44.588 UTC [common/configtx] addToMap -> DEBU 17d[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Writers
[36m2019-01-29 08:50:44.588 UTC [common/configtx] addToMap -> DEBU 17e[0m Adding to config map: [Group]  /Channel/Application/Hospital2MSP
[36m2019-01-29 08:50:44.588 UTC [common/configtx] addToMap -> DEBU 17f[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/MSP
[36m2019-01-29 08:50:44.588 UTC [common/configtx] addToMap -> DEBU 180[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 08:50:44.588 UTC [common/configtx] addToMap -> DEBU 181[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 08:50:44.588 UTC [common/configtx] addToMap -> DEBU 182[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 08:50:44.588 UTC [common/configtx] addToMap -> DEBU 183[0m Adding to config map: [Group]  /Channel/Application/Hospital3MSP
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 184[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/MSP
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 185[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Admins
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 186[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Readers
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 187[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Writers
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 188[0m Adding to config map: [Value]  /Channel/Application/Capabilities
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 189[0m Adding to config map: [Policy] /Channel/Application/Writers
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 18a[0m Adding to config map: [Policy] /Channel/Application/Admins
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 18b[0m Adding to config map: [Policy] /Channel/Application/Readers
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 18c[0m Adding to config map: [Group]  /Channel/Orderer
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 18d[0m Adding to config map: [Group]  /Channel/Orderer/OrdererOrg
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 18e[0m Adding to config map: [Value]  /Channel/Orderer/OrdererOrg/MSP
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 18f[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Writers
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 190[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Admins
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 191[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Readers
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 192[0m Adding to config map: [Value]  /Channel/Orderer/BatchSize
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 193[0m Adding to config map: [Value]  /Channel/Orderer/BatchTimeout
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 194[0m Adding to config map: [Value]  /Channel/Orderer/ChannelRestrictions
[36m2019-01-29 08:50:44.589 UTC [common/configtx] addToMap -> DEBU 195[0m Adding to config map: [Value]  /Channel/Orderer/Capabilities
[36m2019-01-29 08:50:44.590 UTC [common/configtx] addToMap -> DEBU 196[0m Adding to config map: [Value]  /Channel/Orderer/KafkaBrokers
[36m2019-01-29 08:50:44.590 UTC [common/configtx] addToMap -> DEBU 197[0m Adding to config map: [Value]  /Channel/Orderer/ConsensusType
[36m2019-01-29 08:50:44.590 UTC [common/configtx] addToMap -> DEBU 198[0m Adding to config map: [Policy] /Channel/Orderer/Writers
[36m2019-01-29 08:50:44.590 UTC [common/configtx] addToMap -> DEBU 199[0m Adding to config map: [Policy] /Channel/Orderer/BlockValidation
[36m2019-01-29 08:50:44.590 UTC [common/configtx] addToMap -> DEBU 19a[0m Adding to config map: [Policy] /Channel/Orderer/Admins
[36m2019-01-29 08:50:44.590 UTC [common/configtx] addToMap -> DEBU 19b[0m Adding to config map: [Policy] /Channel/Orderer/Readers
[36m2019-01-29 08:50:44.590 UTC [common/configtx] addToMap -> DEBU 19c[0m Adding to config map: [Value]  /Channel/Consortium
[36m2019-01-29 08:50:44.590 UTC [common/configtx] addToMap -> DEBU 19d[0m Adding to config map: [Value]  /Channel/HashingAlgorithm
[36m2019-01-29 08:50:44.590 UTC [common/configtx] addToMap -> DEBU 19e[0m Adding to config map: [Value]  /Channel/BlockDataHashingStructure
[36m2019-01-29 08:50:44.590 UTC [common/configtx] addToMap -> DEBU 19f[0m Adding to config map: [Value]  /Channel/OrdererAddresses
[36m2019-01-29 08:50:44.590 UTC [common/configtx] addToMap -> DEBU 1a0[0m Adding to config map: [Value]  /Channel/Capabilities
[36m2019-01-29 08:50:44.591 UTC [common/configtx] addToMap -> DEBU 1a1[0m Adding to config map: [Policy] /Channel/Readers
[36m2019-01-29 08:50:44.591 UTC [common/configtx] addToMap -> DEBU 1a2[0m Adding to config map: [Policy] /Channel/Writers
[36m2019-01-29 08:50:44.591 UTC [common/configtx] addToMap -> DEBU 1a3[0m Adding to config map: [Policy] /Channel/Admins
[36m2019-01-29 08:50:44.591 UTC [common/channelconfig] LogSanityChecks -> DEBU 1a4[0m As expected, current configuration has policy '/Channel/Readers'
[36m2019-01-29 08:50:44.591 UTC [common/channelconfig] LogSanityChecks -> DEBU 1a5[0m As expected, current configuration has policy '/Channel/Writers'
[36m2019-01-29 08:50:44.591 UTC [policies] Manager -> DEBU 1a6[0m Manager Channel looking up path [Application]
[36m2019-01-29 08:50:44.591 UTC [policies] Manager -> DEBU 1a7[0m Manager Channel has managers Application
[36m2019-01-29 08:50:44.591 UTC [policies] Manager -> DEBU 1a8[0m Manager Channel has managers Orderer
[36m2019-01-29 08:50:44.591 UTC [policies] Manager -> DEBU 1a9[0m Manager Channel/Application looking up path []
[36m2019-01-29 08:50:44.591 UTC [policies] Manager -> DEBU 1aa[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 08:50:44.591 UTC [policies] Manager -> DEBU 1ab[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 08:50:44.591 UTC [policies] Manager -> DEBU 1ac[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 08:50:44.591 UTC [common/channelconfig] LogSanityChecks -> DEBU 1ad[0m As expected, current configuration has policy '/Channel/Application/Readers'
[36m2019-01-29 08:50:44.592 UTC [common/channelconfig] LogSanityChecks -> DEBU 1ae[0m As expected, current configuration has policy '/Channel/Application/Writers'
[36m2019-01-29 08:50:44.592 UTC [common/channelconfig] LogSanityChecks -> DEBU 1af[0m As expected, current configuration has policy '/Channel/Application/Admins'
[36m2019-01-29 08:50:44.592 UTC [policies] Manager -> DEBU 1b0[0m Manager Channel looking up path [Orderer]
[36m2019-01-29 08:50:44.592 UTC [policies] Manager -> DEBU 1b1[0m Manager Channel has managers Application
[36m2019-01-29 08:50:44.592 UTC [policies] Manager -> DEBU 1b2[0m Manager Channel has managers Orderer
[36m2019-01-29 08:50:44.592 UTC [policies] Manager -> DEBU 1b3[0m Manager Channel/Orderer looking up path []
[36m2019-01-29 08:50:44.592 UTC [policies] Manager -> DEBU 1b4[0m Manager Channel/Orderer has managers OrdererOrg
[36m2019-01-29 08:50:44.592 UTC [common/channelconfig] LogSanityChecks -> DEBU 1b5[0m As expected, current configuration has policy '/Channel/Orderer/BlockValidation'
[36m2019-01-29 08:50:44.592 UTC [common/capabilities] Supported -> DEBU 1b6[0m Orderer capability V1_1 is supported and is enabled
[36m2019-01-29 08:50:44.592 UTC [common/capabilities] Supported -> DEBU 1b7[0m Channel capability V1_1 is supported and is enabled
[36m2019-01-29 08:50:44.592 UTC [fsblkstorage] newBlockfileMgr -> DEBU 1b8[0m newBlockfileMgr() initializing file-based block storage for ledger: comunitychannel 
[36m2019-01-29 08:50:44.592 UTC [kvledger.util] CreateDirIfMissing -> DEBU 1b9[0m CreateDirIfMissing [/var/hyperledger/production/orderer/chains/comunitychannel/]
[36m2019-01-29 08:50:44.592 UTC [kvledger.util] logDirStatus -> DEBU 1ba[0m Before creating dir - [/var/hyperledger/production/orderer/chains/comunitychannel/] does not exist
[36m2019-01-29 08:50:44.592 UTC [kvledger.util] logDirStatus -> DEBU 1bb[0m After creating dir - [/var/hyperledger/production/orderer/chains/comunitychannel/] exists
2019-01-29 08:50:44.593 UTC [fsblkstorage] newBlockfileMgr -> INFO 1bc[0m Getting block information from block storage
[36m2019-01-29 08:50:44.593 UTC [fsblkstorage] constructCheckpointInfoFromBlockFiles -> DEBU 1bd[0m Retrieving checkpoint info from block files
[36m2019-01-29 08:50:44.593 UTC [fsblkstorage] retrieveLastFileSuffix -> DEBU 1be[0m retrieveLastFileSuffix()
[36m2019-01-29 08:50:44.593 UTC [fsblkstorage] retrieveLastFileSuffix -> DEBU 1bf[0m retrieveLastFileSuffix() - biggestFileNum = -1
[36m2019-01-29 08:50:44.593 UTC [fsblkstorage] constructCheckpointInfoFromBlockFiles -> DEBU 1c0[0m Last file number found = -1
[36m2019-01-29 08:50:44.593 UTC [fsblkstorage] constructCheckpointInfoFromBlockFiles -> DEBU 1c1[0m No block file found
[36m2019-01-29 08:50:44.593 UTC [fsblkstorage] newBlockfileMgr -> DEBU 1c2[0m Info constructed by scanning the blocks dir = (*fsblkstorage.checkpointInfo)(0xc4203db6e0)(latestFileChunkSuffixNum=[0], latestFileChunksize=[0], isChainEmpty=[true], lastBlockNumber=[0])
[36m2019-01-29 08:50:44.595 UTC [fsblkstorage] newBlockIndex -> DEBU 1c3[0m newBlockIndex() - indexItems:[[BlockNum]]
[36m2019-01-29 08:50:44.606 UTC [fsblkstorage] indexBlock -> DEBU 1c4[0m Indexing block [blockNum=0, blockHash=[]byte{0x8, 0x71, 0xb0, 0xf, 0xc2, 0x82, 0x96, 0xbf, 0x59, 0x7d, 0xbb, 0x42, 0x74, 0x92, 0x69, 0x18, 0x64, 0xe3, 0xfa, 0x97, 0xec, 0x91, 0x6d, 0x3f, 0x65, 0x5b, 0x8a, 0x3e, 0x7, 0xc0, 0x9b, 0xb2} txOffsets=
txId= locPointer=offset=39, bytesLength=21701
]
[36m2019-01-29 08:50:44.609 UTC [fsblkstorage] updateCheckpoint -> DEBU 1c5[0m Broadcasting about update checkpointInfo: latestFileChunkSuffixNum=[0], latestFileChunksize=[21745], isChainEmpty=[false], lastBlockNumber=[0]
[36m2019-01-29 08:50:44.609 UTC [fsblkstorage] Next -> DEBU 1c6[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=0
[36m2019-01-29 08:50:44.609 UTC [fsblkstorage] newBlockfileStream -> DEBU 1c7[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/comunitychannel/blockfile_000000], startOffset=[0]
[36m2019-01-29 08:50:44.609 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 1c8[0m Remaining bytes=[21745], Going to peek [8] bytes
[36m2019-01-29 08:50:44.610 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 1c9[0m Returning blockbytes - length=[21742], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 08:50:44.610 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 1ca[0m blockbytes [21742] read from file [0]
[36m2019-01-29 08:50:44.610 UTC [orderer/commmon/multichannel] newBlockWriter -> DEBU 1cb[0m [channel: comunitychannel] Creating block writer for tip of chain (blockNumber=0, lastConfigBlockNum=0, lastConfigSeq=1)
2019-01-29 08:50:44.610 UTC [orderer/consensus/kafka] newChain -> INFO 1cc[0m [channel: comunitychannel] Starting chain with last persisted offset -3 and last recorded block 0
[36m2019-01-29 08:50:44.610 UTC [orderer/commmon/multichannel] newChainSupport -> DEBU 1cd[0m [channel: comunitychannel] Done creating channel support resources
2019-01-29 08:50:44.611 UTC [orderer/commmon/multichannel] newChain -> INFO 1ce[0m Created and starting new chain comunitychannel
[36m2019-01-29 08:50:44.611 UTC [msp] GetDefaultSigningIdentity -> DEBU 1cf[0m Obtaining default signing identity
[36m2019-01-29 08:50:44.611 UTC [msp] GetDefaultSigningIdentity -> DEBU 1d1[0m Obtaining default signing identity
[36m2019-01-29 08:50:44.611 UTC [msp/identity] Sign -> DEBU 1d2[0m Sign: plaintext: 0ABD060A0A4F7264657265724D535012...03D85088F4235A86CFD335225E1971E5 
[36m2019-01-29 08:50:44.611 UTC [msp/identity] Sign -> DEBU 1d3[0m Sign: digest: 430D3CA0C51A1BAA7DFDBE71B978F937FA282C78EC89333210C3C9CC58FF2D81 
2019-01-29 08:50:44.611 UTC [orderer/consensus/kafka] setupProducerForChannel -> INFO 1d0[0m [channel: comunitychannel] Setting up the producer for this channel...
[36m2019-01-29 08:50:44.611 UTC [orderer/consensus/kafka] try -> DEBU 1d4[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 08:50:44.611 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 1d5[0m Initializing new client
[36m2019-01-29 08:50:44.611 UTC [msp] GetDefaultSigningIdentity -> DEBU 1d6[0m Obtaining default signing identity
[36m2019-01-29 08:50:44.611 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 1d7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:50:44.611 UTC [orderer/commmon/multichannel] addLastConfigSignature -> DEBU 1d8[0m [channel: testchainid] About to write block, setting its LAST_CONFIG to 0
[36m2019-01-29 08:50:44.611 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1d9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:50:44.611 UTC [msp] GetDefaultSigningIdentity -> DEBU 1da[0m Obtaining default signing identity
[36m2019-01-29 08:50:44.611 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1db[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 08:50:44.611 UTC [msp/identity] Sign -> DEBU 1dc[0m Sign: plaintext: 0ABD060A0A4F7264657265724D535012...03D85088F4235A86CFD335225E1971E5 
[36m2019-01-29 08:50:44.611 UTC [msp/identity] Sign -> DEBU 1dd[0m Sign: digest: 9C9030B1CBBE3CB777569028BD7FFDB9C2FBFAB0BE0FD929EEE2AD6E4ABB3F4A 
[36m2019-01-29 08:50:44.612 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1de[0m Connected to broker at kafka0.switch2logic.co.za:9092 (unregistered)
[36m2019-01-29 08:50:44.615 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 1df[0m client/brokers registered new broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 08:50:44.615 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 1e0[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 08:50:44.615 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 1e2[0m client/brokers registered new broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 08:50:44.615 UTC [fsblkstorage] indexBlock -> DEBU 1e1[0m Indexing block [blockNum=1, blockHash=[]byte{0x98, 0x95, 0xc2, 0xd0, 0x46, 0x74, 0x58, 0xd2, 0x7a, 0xcf, 0xfc, 0x9b, 0x37, 0x5, 0x97, 0xa, 0x8a, 0xc0, 0x5, 0x46, 0x5b, 0x95, 0x7b, 0x3c, 0xc2, 0x17, 0x8e, 0x2c, 0xd1, 0x10, 0x37, 0xc4} txOffsets=
txId= locPointer=offset=71, bytesLength=22670
]
[36m2019-01-29 08:50:44.615 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 1e3[0m Successfully initialized new client
[36m2019-01-29 08:50:44.615 UTC [orderer/consensus/kafka] try -> DEBU 1e4[0m [channel: comunitychannel] Error is nil, breaking the retry loop
2019-01-29 08:50:44.615 UTC [orderer/consensus/kafka] startThread -> INFO 1e5[0m [channel: comunitychannel] Producer set up successfully
2019-01-29 08:50:44.615 UTC [orderer/consensus/kafka] sendConnectMessage -> INFO 1e6[0m [channel: comunitychannel] About to post the CONNECT message...
[36m2019-01-29 08:50:44.615 UTC [orderer/consensus/kafka] try -> DEBU 1e7[0m [channel: comunitychannel] Attempting to post the CONNECT message...
[36m2019-01-29 08:50:44.615 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1e8[0m client/metadata fetching metadata for [comunitychannel] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 08:50:44.622 UTC [fsblkstorage] updateCheckpoint -> DEBU 1e9[0m Broadcasting about update checkpointInfo: latestFileChunkSuffixNum=[0], latestFileChunksize=[43120], isChainEmpty=[false], lastBlockNumber=[1]
[36m2019-01-29 08:50:44.622 UTC [orderer/commmon/multichannel] commitBlock -> DEBU 1ea[0m [channel: testchainid] Wrote block 1
[36m2019-01-29 08:50:44.636 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1eb[0m client/metadata found some partitions to be leaderless
[36m2019-01-29 08:50:44.636 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 1ec[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 08:50:44.890 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1ed[0m client/metadata fetching metadata for [comunitychannel] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 08:50:44.894 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1ee[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:50:44.894 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU 1ef[0m producer/broker/0 starting up
[36m2019-01-29 08:50:44.894 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU 1f0[0m producer/broker/0 state change to [open] on comunitychannel/0
[36m2019-01-29 08:50:44.895 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1f1[0m Connected to broker at kafka0.switch2logic.co.za:9092 (registered as #0)
[36m2019-01-29 08:50:45.829 UTC [orderer/consensus/kafka] try -> DEBU 1f2[0m [channel: comunitychannel] Error is nil, breaking the retry loop
2019-01-29 08:50:45.829 UTC [orderer/consensus/kafka] startThread -> INFO 1f3[0m [channel: comunitychannel] CONNECT message posted successfully
2019-01-29 08:50:45.830 UTC [orderer/consensus/kafka] setupParentConsumerForChannel -> INFO 1f4[0m [channel: comunitychannel] Setting up the parent consumer for this channel...
[36m2019-01-29 08:50:45.830 UTC [orderer/consensus/kafka] try -> DEBU 1f5[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 08:50:45.830 UTC [orderer/consensus/kafka/sarama] NewConsumer -> DEBU 1f6[0m Initializing new client
[36m2019-01-29 08:50:45.830 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 1f7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:50:45.830 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1f8[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:50:45.831 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1f9[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 08:50:45.832 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1fa[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.149:11092: connect: connection refused
[36m2019-01-29 08:50:45.832 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1fb[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.149:11092: connect: connection refused
[36m2019-01-29 08:50:45.832 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1fc[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:50:45.832 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1fd[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 08:50:45.834 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1fe[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp 10.0.0.150:10092: connect: connection refused
[36m2019-01-29 08:50:45.834 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1ff[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.150:10092: connect: connection refused
[36m2019-01-29 08:50:45.834 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 200[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:50:45.834 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 201[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 08:50:45.835 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 202[0m Connected to broker at kafka0.switch2logic.co.za:9092 (unregistered)
[36m2019-01-29 08:50:45.837 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 203[0m client/brokers registered new broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 08:50:45.838 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 204[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 08:50:45.838 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 205[0m client/brokers registered new broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 08:50:45.838 UTC [orderer/consensus/kafka/sarama] NewConsumer -> DEBU 206[0m Successfully initialized new client
[36m2019-01-29 08:50:45.838 UTC [orderer/consensus/kafka] try -> DEBU 207[0m [channel: comunitychannel] Error is nil, breaking the retry loop
2019-01-29 08:50:45.838 UTC [orderer/consensus/kafka] startThread -> INFO 208[0m [channel: comunitychannel] Parent consumer set up successfully
2019-01-29 08:50:45.838 UTC [orderer/consensus/kafka] setupChannelConsumerForChannel -> INFO 209[0m [channel: comunitychannel] Setting up the channel consumer for this channel (start offset: -2)...
[36m2019-01-29 08:50:45.838 UTC [orderer/consensus/kafka] try -> DEBU 20a[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 08:50:45.838 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 20b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 08:50:45.839 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 20c[0m Connected to broker at kafka0.switch2logic.co.za:9092 (registered as #0)
[36m2019-01-29 08:50:45.851 UTC [orderer/consensus/kafka] try -> DEBU 20d[0m [channel: comunitychannel] Error is nil, breaking the retry loop
2019-01-29 08:50:45.851 UTC [orderer/consensus/kafka] startThread -> INFO 20f[0m [channel: comunitychannel] Channel consumer set up successfully
2019-01-29 08:50:45.851 UTC [orderer/consensus/kafka] startThread -> INFO 210[0m [channel: comunitychannel] Start phase completed successfully
[36m2019-01-29 08:50:45.851 UTC [orderer/consensus/kafka/sarama] subscriptionConsumer -> DEBU 20e[0m consumer/broker/0 added subscription to comunitychannel/0
[36m2019-01-29 08:50:45.866 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 211[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 0. Inspecting type...
[36m2019-01-29 08:50:45.866 UTC [orderer/consensus/kafka] processConnect -> DEBU 212[0m [channel: comunitychannel] It's a connect message - ignoring
[36m2019-01-29 08:50:45.866 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 213[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 1. Inspecting type...
[36m2019-01-29 08:50:45.866 UTC [orderer/consensus/kafka] processConnect -> DEBU 214[0m [channel: comunitychannel] It's a connect message - ignoring
[36m2019-01-29 08:50:45.866 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 215[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 2. Inspecting type...
[36m2019-01-29 08:50:45.866 UTC [orderer/consensus/kafka] processConnect -> DEBU 216[0m [channel: comunitychannel] It's a connect message - ignoring
[36m2019-01-29 08:55:25.576 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 217[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 08:55:25.591 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 218[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:00:45.027 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 219[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:00:46.251 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 21a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:05:25.576 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 21b[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:05:25.591 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 21c[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:10:45.461 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 21d[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:10:46.684 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 21e[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:15:26.010 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 21f[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:15:26.025 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 220[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:20:45.461 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 221[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:20:46.684 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 222[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:25:26.010 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 223[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:25:26.025 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 224[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:30:45.474 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 225[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:30:46.697 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 226[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:35:26.022 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 227[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:35:26.038 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 228[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:40:45.474 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 229[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:40:46.697 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 22a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:45:26.023 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 22b[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:45:26.038 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 22c[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:50:45.474 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 22d[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:50:46.697 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 22e[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:55:26.023 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 22f[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 09:55:26.038 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 230[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:00:45.474 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 231[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:00:46.697 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 232[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:05:26.023 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 233[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:05:26.038 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 234[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:10:45.474 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 235[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:10:46.697 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 236[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:15:26.023 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 237[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:15:26.038 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 238[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:17:03.067 UTC [grpc] Printf -> DEBU 239[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.229:53610": tls: first record does not look like a TLS handshake
[36m2019-01-29 10:20:44.820 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 23a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:20:46.044 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 23b[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:25:25.862 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 23c[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:25:25.877 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 23d[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:30:46.032 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 23e[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:30:47.256 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 23f[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
2019-01-29 10:33:55.183 UTC [localconfig] completeInitialization -> INFO 001[0m Kafka.Version unset, setting to 0.10.2.0
[36m2019-01-29 10:33:55.190 UTC [bccsp_sw] openKeyStore -> DEBU 002[0m KeyStore opened at [/etc/hyperledger/fabric/orderer/msp/keystore]...done
[36m2019-01-29 10:33:55.190 UTC [bccsp] initBCCSP -> DEBU 003[0m Initialize BCCSP [SW]
[36m2019-01-29 10:33:55.191 UTC [msp] getPemMaterialFromDir -> DEBU 004[0m Reading directory /etc/hyperledger/fabric/orderer/msp/signcerts
[36m2019-01-29 10:33:55.192 UTC [msp] getPemMaterialFromDir -> DEBU 005[0m Inspecting file /etc/hyperledger/fabric/orderer/msp/signcerts/orderer0.hospital2.switch2logic.co.za-cert.pem
[36m2019-01-29 10:33:55.193 UTC [msp] getPemMaterialFromDir -> DEBU 006[0m Reading directory /etc/hyperledger/fabric/orderer/msp/cacerts
[36m2019-01-29 10:33:55.193 UTC [msp] getPemMaterialFromDir -> DEBU 007[0m Inspecting file /etc/hyperledger/fabric/orderer/msp/cacerts/ca.switch2logic.co.za-cert.pem
[36m2019-01-29 10:33:55.193 UTC [msp] getPemMaterialFromDir -> DEBU 008[0m Reading directory /etc/hyperledger/fabric/orderer/msp/admincerts
[36m2019-01-29 10:33:55.193 UTC [msp] getPemMaterialFromDir -> DEBU 009[0m Inspecting file /etc/hyperledger/fabric/orderer/msp/admincerts/Admin@switch2logic.co.za-cert.pem
[36m2019-01-29 10:33:55.194 UTC [msp] getPemMaterialFromDir -> DEBU 00a[0m Reading directory /etc/hyperledger/fabric/orderer/msp/intermediatecerts
[36m2019-01-29 10:33:55.194 UTC [msp] getMspConfig -> DEBU 00b[0m Intermediate certs folder not found at [/etc/hyperledger/fabric/orderer/msp/intermediatecerts]. Skipping. [stat /etc/hyperledger/fabric/orderer/msp/intermediatecerts: no such file or directory]
[36m2019-01-29 10:33:55.194 UTC [msp] getPemMaterialFromDir -> DEBU 00c[0m Reading directory /etc/hyperledger/fabric/orderer/msp/tlscacerts
[36m2019-01-29 10:33:55.194 UTC [msp] getPemMaterialFromDir -> DEBU 00d[0m Inspecting file /etc/hyperledger/fabric/orderer/msp/tlscacerts/tlsca.switch2logic.co.za-cert.pem
[36m2019-01-29 10:33:55.194 UTC [msp] getPemMaterialFromDir -> DEBU 00e[0m Reading directory /etc/hyperledger/fabric/orderer/msp/tlsintermediatecerts
[36m2019-01-29 10:33:55.194 UTC [msp] getMspConfig -> DEBU 00f[0m TLS intermediate certs folder not found at [/etc/hyperledger/fabric/orderer/msp/tlsintermediatecerts]. Skipping. [stat /etc/hyperledger/fabric/orderer/msp/tlsintermediatecerts: no such file or directory]
[36m2019-01-29 10:33:55.194 UTC [msp] getPemMaterialFromDir -> DEBU 010[0m Reading directory /etc/hyperledger/fabric/orderer/msp/crls
[36m2019-01-29 10:33:55.194 UTC [msp] getMspConfig -> DEBU 011[0m crls folder not found at [/etc/hyperledger/fabric/orderer/msp/crls]. Skipping. [stat /etc/hyperledger/fabric/orderer/msp/crls: no such file or directory]
[36m2019-01-29 10:33:55.194 UTC [msp] getMspConfig -> DEBU 012[0m MSP configuration file not found at [/etc/hyperledger/fabric/orderer/msp/config.yaml]: [stat /etc/hyperledger/fabric/orderer/msp/config.yaml: no such file or directory]
[36m2019-01-29 10:33:55.194 UTC [msp] newBccspMsp -> DEBU 013[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:33:55.194 UTC [msp] New -> DEBU 014[0m Creating Cache-MSP instance
[36m2019-01-29 10:33:55.194 UTC [msp] loadLocaMSP -> DEBU 015[0m Created new local MSP
[36m2019-01-29 10:33:55.195 UTC [msp] Setup -> DEBU 016[0m Setting up MSP instance OrdererMSP
[36m2019-01-29 10:33:55.195 UTC [msp/identity] newIdentity -> DEBU 017[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICSzCCAfKgAwIBAgIRAO7EFp+tGDrZX/4Yn1ExG4IwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowdzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEe
MBwGA1UEAxMVY2Euc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZI
zj0DAQcDQgAE+ci0VrQQEnBN2VlYMEvGL0RvqwQ9zVhgyxdKDi9AB8iyQ0dhyWzJ
CZ9MnAWGk29pw9b+9HdNkbalpJKWkcctJ6NfMF0wDgYDVR0PAQH/BAQDAgGmMA8G
A1UdJQQIMAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgGIY2e0Pm
0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDRwAwRAIgcoBa
RHN5r57Qu7sd8TwCzfyJI+uozczAYI2SsN06iKgCIAeAP4FbTHxjqSLcNZMNGbTZ
YWA1h+rDBMa99duId/0D
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.196 UTC [msp/identity] newIdentity -> DEBU 018[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICHzCCAcWgAwIBAgIQRo5Qm6m11gCv1i2SXwRJAjAKBggqhkjOPQQDAjB3MQsw
CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy
YW5jaXNjbzEbMBkGA1UEChMSc3dpdGNoMmxvZ2ljLmNvLnphMR4wHAYDVQQDExVj
YS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkwMTI5MDc0MTU0WhcNMjkwMTI2MDc0
MTU0WjBdMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UE
BxMNU2FuIEZyYW5jaXNjbzEhMB8GA1UEAwwYQWRtaW5Ac3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE0QeSwnrMZdy7TKSYF/JzQ12C
vfINZcjx7xyeUuj/96gj42fjc1ctn7oo/tDl1eJNZbDhFvkRzefYmxtoSnH5Y6NN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgGIY2
e0Pm0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDSAAwRQIh
AM8EkjCZIKrAf9sL1d1fThizng+66jmEVlKPbTpimVbiAiAhCJZoeBIJGcgxbCr2
5Rd2IW34zWcPhemkNZvCKv27WA==
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.259 UTC [msp/identity] newIdentity -> DEBU 019[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICLDCCAdOgAwIBAgIRALSnb5cS69ZjMJpS1JIoZEkwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowajELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xLjAsBgNVBAMTJW9yZGVyZXIwLmhvc3BpdGFsMi5z
d2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAAS6h69N
Iqb4d5ts04E2IRVEEawOWRIUoNntvpfHT6SnxVjSZi7exzn/YOTi0QQd6NGQa5iu
PFOZElkdCuGbgkyHo00wSzAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH/BAIwADAr
BgNVHSMEJDAigCAYhjZ7Q+bQZRvQvEDbHV3XtyLU0UWvqf/t8icEQrGycTAKBggq
hkjOPQQDAgNHADBEAiAqTM16gxhM8p3qA85cIM2a/xQXiZG35c3etBeP0/9uGAIg
FY2RcB+w2BjTJYTMYwIWQj/N9KTuAHugDITJ8afv1IU=
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.260 UTC [bccsp_sw] loadPrivateKey -> DEBU 01a[0m Loading private key [6cc0af06e32c6be74c9cb70b0bbf8dc9b0729ca7c2db8fba1fcd4ed4a9dfedd6] at [/etc/hyperledger/fabric/orderer/msp/keystore/6cc0af06e32c6be74c9cb70b0bbf8dc9b0729ca7c2db8fba1fcd4ed4a9dfedd6_sk]...
[36m2019-01-29 10:33:55.260 UTC [msp/identity] newIdentity -> DEBU 01b[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICLDCCAdOgAwIBAgIRALSnb5cS69ZjMJpS1JIoZEkwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowajELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xLjAsBgNVBAMTJW9yZGVyZXIwLmhvc3BpdGFsMi5z
d2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAAS6h69N
Iqb4d5ts04E2IRVEEawOWRIUoNntvpfHT6SnxVjSZi7exzn/YOTi0QQd6NGQa5iu
PFOZElkdCuGbgkyHo00wSzAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH/BAIwADAr
BgNVHSMEJDAigCAYhjZ7Q+bQZRvQvEDbHV3XtyLU0UWvqf/t8icEQrGycTAKBggq
hkjOPQQDAgNHADBEAiAqTM16gxhM8p3qA85cIM2a/xQXiZG35c3etBeP0/9uGAIg
FY2RcB+w2BjTJYTMYwIWQj/N9KTuAHugDITJ8afv1IU=
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.261 UTC [msp] setupSigningIdentity -> DEBU 01c[0m Signing identity expires at 2029-01-26 07:41:54 +0000 UTC
[36m2019-01-29 10:33:55.261 UTC [msp] Validate -> DEBU 01d[0m MSP OrdererMSP validating identity
2019-01-29 10:33:55.262 UTC [orderer/common/server] prettyPrintStruct -> INFO 01e[0m Orderer config values:
	General.LedgerType = "file"
	General.ListenAddress = "0.0.0.0"
	General.ListenPort = 7050
	General.TLS.Enabled = true
	General.TLS.PrivateKey = "/etc/hyperledger/fabric/orderer/tls/server.key"
	General.TLS.Certificate = "/etc/hyperledger/fabric/orderer/tls/server.crt"
	General.TLS.RootCAs = [/etc/hyperledger/fabric/orderer/tls/ca.crt]
	General.TLS.ClientAuthRequired = false
	General.TLS.ClientRootCAs = []
	General.Keepalive.ServerMinInterval = 1m0s
	General.Keepalive.ServerInterval = 2h0m0s
	General.Keepalive.ServerTimeout = 20s
	General.GenesisMethod = "file"
	General.GenesisProfile = "SampleInsecureSolo"
	General.SystemChannel = "test-system-channel-name"
	General.GenesisFile = "/etc/hyperledger/fabric/orderer/channel-artifacts/genesis.block"
	General.Profile.Enabled = false
	General.Profile.Address = "0.0.0.0:6060"
	General.LogLevel = "debug"
	General.LogFormat = "%{color}%{time:2006-01-02 15:04:05.000 MST} [%{module}] %{shortfunc} -> %{level:.4s} %{id:03x}%{color:reset} %{message}"
	General.LocalMSPDir = "/etc/hyperledger/fabric/orderer/msp"
	General.LocalMSPID = "OrdererMSP"
	General.BCCSP.ProviderName = "SW"
	General.BCCSP.SwOpts.SecLevel = 256
	General.BCCSP.SwOpts.HashFamily = "SHA2"
	General.BCCSP.SwOpts.Ephemeral = false
	General.BCCSP.SwOpts.FileKeystore.KeyStorePath = "/etc/hyperledger/fabric/orderer/msp/keystore"
	General.BCCSP.SwOpts.DummyKeystore =
	General.BCCSP.PluginOpts =
	General.Authentication.TimeWindow = 15m0s
	FileLedger.Location = "/var/hyperledger/production/orderer"
	FileLedger.Prefix = "hyperledger-fabric-ordererledger"
	RAMLedger.HistorySize = 1000
	Kafka.Retry.ShortInterval = 1s
	Kafka.Retry.ShortTotal = 30s
	Kafka.Retry.LongInterval = 5m0s
	Kafka.Retry.LongTotal = 12h0m0s
	Kafka.Retry.NetworkTimeouts.DialTimeout = 10s
	Kafka.Retry.NetworkTimeouts.ReadTimeout = 10s
	Kafka.Retry.NetworkTimeouts.WriteTimeout = 10s
	Kafka.Retry.Metadata.RetryMax = 3
	Kafka.Retry.Metadata.RetryBackoff = 250ms
	Kafka.Retry.Producer.RetryMax = 3
	Kafka.Retry.Producer.RetryBackoff = 100ms
	Kafka.Retry.Consumer.RetryBackoff = 2s
	Kafka.Verbose = true
	Kafka.Version = 0.10.2.0
	Kafka.TLS.Enabled = false
	Kafka.TLS.PrivateKey = ""
	Kafka.TLS.Certificate = ""
	Kafka.TLS.RootCAs = []
	Kafka.TLS.ClientAuthRequired = false
	Kafka.TLS.ClientRootCAs = []
	Debug.BroadcastTraceDir = ""
	Debug.DeliverTraceDir = ""
2019-01-29 10:33:55.263 UTC [orderer/common/server] initializeServerConfig -> INFO 01f[0m Starting orderer with TLS enabled
[36m2019-01-29 10:33:55.265 UTC [orderer/common/server] createLedgerFactory -> DEBU 020[0m Ledger dir: /var/hyperledger/production/orderer
[36m2019-01-29 10:33:55.265 UTC [kvledger.util] CreateDirIfMissing -> DEBU 021[0m CreateDirIfMissing [/var/hyperledger/production/orderer/index/]
[36m2019-01-29 10:33:55.266 UTC [kvledger.util] logDirStatus -> DEBU 022[0m Before creating dir - [/var/hyperledger/production/orderer/index/] exists
[36m2019-01-29 10:33:55.266 UTC [kvledger.util] logDirStatus -> DEBU 023[0m After creating dir - [/var/hyperledger/production/orderer/index/] exists
[36m2019-01-29 10:33:55.311 UTC [orderer/common/server] createSubDir -> DEBU 024[0m Found chains sub-dir and using it
2019-01-29 10:33:55.312 UTC [orderer/common/server] initializeMultichannelRegistrar -> INFO 025[0m Not bootstrapping because of existing chains
[36m2019-01-29 10:33:55.313 UTC [fsblkstorage] newBlockfileMgr -> DEBU 026[0m newBlockfileMgr() initializing file-based block storage for ledger: comunitychannel 
[36m2019-01-29 10:33:55.313 UTC [kvledger.util] CreateDirIfMissing -> DEBU 027[0m CreateDirIfMissing [/var/hyperledger/production/orderer/chains/comunitychannel/]
[36m2019-01-29 10:33:55.313 UTC [kvledger.util] logDirStatus -> DEBU 028[0m Before creating dir - [/var/hyperledger/production/orderer/chains/comunitychannel/] exists
[36m2019-01-29 10:33:55.317 UTC [kvledger.util] logDirStatus -> DEBU 029[0m After creating dir - [/var/hyperledger/production/orderer/chains/comunitychannel/] exists
[36m2019-01-29 10:33:55.318 UTC [fsblkstorage] loadCurrentInfo -> DEBU 02a[0m loaded checkpointInfo:latestFileChunkSuffixNum=[0], latestFileChunksize=[21745], isChainEmpty=[false], lastBlockNumber=[0]
[36m2019-01-29 10:33:55.318 UTC [fsblkstorage] newBlockfileMgr -> DEBU 02b[0m Synching block information from block storage (if needed)
[36m2019-01-29 10:33:55.318 UTC [fsblkstorage] syncCPInfoFromFS -> DEBU 02c[0m Starting checkpoint=latestFileChunkSuffixNum=[0], latestFileChunksize=[21745], isChainEmpty=[false], lastBlockNumber=[0]
[36m2019-01-29 10:33:55.318 UTC [fsblkstorage] syncCPInfoFromFS -> DEBU 02d[0m status of file [/var/hyperledger/production/orderer/chains/comunitychannel/blockfile_000000]: exists=[true], size=[21745]
[36m2019-01-29 10:33:55.321 UTC [fsblkstorage] newBlockIndex -> DEBU 02e[0m newBlockIndex() - indexItems:[[BlockNum]]
[36m2019-01-29 10:33:55.321 UTC [fsblkstorage] syncIndex -> DEBU 02f[0m Both the block files and indices are in sync.
[36m2019-01-29 10:33:55.321 UTC [fsblkstorage] retrieveBlockHeaderByNumber -> DEBU 030[0m retrieveBlockHeaderByNumber() - blockNum = [0]
[36m2019-01-29 10:33:55.321 UTC [fsblkstorage] newBlockfileStream -> DEBU 031[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/comunitychannel/blockfile_000000], startOffset=[0]
[36m2019-01-29 10:33:55.321 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 032[0m Remaining bytes=[21745], Going to peek [8] bytes
[36m2019-01-29 10:33:55.322 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 033[0m Returning blockbytes - length=[21742], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 10:33:55.322 UTC [fsblkstorage] Next -> DEBU 034[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=0
[36m2019-01-29 10:33:55.322 UTC [fsblkstorage] newBlockfileStream -> DEBU 035[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/comunitychannel/blockfile_000000], startOffset=[0]
[36m2019-01-29 10:33:55.322 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 036[0m Remaining bytes=[21745], Going to peek [8] bytes
[36m2019-01-29 10:33:55.322 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 037[0m Returning blockbytes - length=[21742], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 10:33:55.323 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 038[0m blockbytes [21742] read from file [0]
[36m2019-01-29 10:33:55.323 UTC [fsblkstorage] Next -> DEBU 039[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=0
[36m2019-01-29 10:33:55.323 UTC [fsblkstorage] newBlockfileStream -> DEBU 03a[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/comunitychannel/blockfile_000000], startOffset=[0]
[36m2019-01-29 10:33:55.323 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 03b[0m Remaining bytes=[21745], Going to peek [8] bytes
[36m2019-01-29 10:33:55.323 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 03c[0m Returning blockbytes - length=[21742], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 10:33:55.323 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 03d[0m blockbytes [21742] read from file [0]
[36m2019-01-29 10:33:55.324 UTC [common/channelconfig] NewStandardValues -> DEBU 03e[0m Initializing protos for *channelconfig.ChannelProtos
[36m2019-01-29 10:33:55.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 03f[0m Processing field: HashingAlgorithm
[36m2019-01-29 10:33:55.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 040[0m Processing field: BlockDataHashingStructure
[36m2019-01-29 10:33:55.326 UTC [common/channelconfig] initializeProtosStruct -> DEBU 041[0m Processing field: OrdererAddresses
[36m2019-01-29 10:33:55.326 UTC [common/channelconfig] initializeProtosStruct -> DEBU 042[0m Processing field: Consortium
[36m2019-01-29 10:33:55.326 UTC [common/channelconfig] initializeProtosStruct -> DEBU 043[0m Processing field: Capabilities
[36m2019-01-29 10:33:55.326 UTC [common/channelconfig] NewStandardValues -> DEBU 044[0m Initializing protos for *channelconfig.ApplicationProtos
[36m2019-01-29 10:33:55.326 UTC [common/channelconfig] initializeProtosStruct -> DEBU 045[0m Processing field: ACLs
[36m2019-01-29 10:33:55.326 UTC [common/channelconfig] initializeProtosStruct -> DEBU 046[0m Processing field: Capabilities
[36m2019-01-29 10:33:55.326 UTC [common/channelconfig] NewStandardValues -> DEBU 047[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 10:33:55.327 UTC [common/channelconfig] initializeProtosStruct -> DEBU 048[0m Processing field: AnchorPeers
[36m2019-01-29 10:33:55.327 UTC [common/channelconfig] NewStandardValues -> DEBU 049[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:33:55.327 UTC [common/channelconfig] initializeProtosStruct -> DEBU 04a[0m Processing field: MSP
[36m2019-01-29 10:33:55.327 UTC [common/channelconfig] Validate -> DEBU 04b[0m Anchor peers for org Hospital1MSP are 
[36m2019-01-29 10:33:55.327 UTC [common/channelconfig] validateMSP -> DEBU 04c[0m Setting up MSP for org Hospital1MSP
[36m2019-01-29 10:33:55.327 UTC [msp] newBccspMsp -> DEBU 04d[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:33:55.327 UTC [msp] New -> DEBU 04e[0m Creating Cache-MSP instance
[36m2019-01-29 10:33:55.327 UTC [msp] Setup -> DEBU 04f[0m Setting up MSP instance Hospital1MSP
[36m2019-01-29 10:33:55.328 UTC [msp/identity] newIdentity -> DEBU 050[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdDCCAhugAwIBAgIQZxH8VsnceZxXgKxlURLgVTAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMS5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQX9V4k/h/3pFxByKDscjgQrC0YS/bSbKvzSG2Z2PvltEWp40qB9OaKUN0GQYzo
yK2Etdvyjfd1OFwaTjpGSvv9o18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCBVU7DoP9Msf/nNTNl6
5FxwAXZ82eaGBT7zWYdyh4QbBjAKBggqhkjOPQQDAgNHADBEAiBmXGWQbxCGRp0c
5/y9qJyciB1CDHsknRZDjNzt5f563wIgMy7VPi1R8DpIIIRN9B3mfhDpRa+J+8PA
S4DOJy7rjp4=
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.328 UTC [msp/identity] newIdentity -> DEBU 051[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfWgAwIBAgIQbzxpSKiuJCzDiDlZp+XbWDAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjB4MQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZyYW5jaXNjbzEPMA0GA1UECxMG
Y2xpZW50MSswKQYDVQQDDCJBZG1pbkBob3NwaXRhbDEuc3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEnpADl8+aUBcVWv6q3IgMQ4yg
ISawQ0wamHmpSv+/b1B5hf4V2HyoPrawIr45+o4/Qz++WazZlyY7PkoT27r7KaNN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgVVOw
6D/TLH/5zUzZeuRccAF2fNnmhgU+81mHcoeEGwYwCgYIKoZIzj0EAwIDSAAwRQIh
ALavdMm9i6xSsnWdlliMh10s6dmGBaXO0CxaCowLJIMtAiBEduudGJymDDE1zbiX
YwX83cYWZHUcYV8IXeZPFymC+w==
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.329 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 052[0m Checking if identity satisfies role [CLIENT] for Hospital1MSP
[36m2019-01-29 10:33:55.329 UTC [msp] Validate -> DEBU 053[0m MSP Hospital1MSP validating identity
[36m2019-01-29 10:33:55.330 UTC [msp] getCertificationChain -> DEBU 054[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 10:33:55.330 UTC [msp] hasOURole -> DEBU 055[0m MSP Hospital1MSP checking if the identity is a client
[36m2019-01-29 10:33:55.330 UTC [msp] getCertificationChain -> DEBU 056[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 10:33:55.330 UTC [common/channelconfig] NewStandardValues -> DEBU 057[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 10:33:55.331 UTC [common/channelconfig] initializeProtosStruct -> DEBU 058[0m Processing field: AnchorPeers
[36m2019-01-29 10:33:55.331 UTC [common/channelconfig] NewStandardValues -> DEBU 059[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:33:55.331 UTC [common/channelconfig] initializeProtosStruct -> DEBU 05a[0m Processing field: MSP
[36m2019-01-29 10:33:55.331 UTC [common/channelconfig] Validate -> DEBU 05b[0m Anchor peers for org Hospital2MSP are 
[36m2019-01-29 10:33:55.331 UTC [common/channelconfig] validateMSP -> DEBU 05c[0m Setting up MSP for org Hospital2MSP
[36m2019-01-29 10:33:55.331 UTC [msp] newBccspMsp -> DEBU 05d[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:33:55.331 UTC [msp] New -> DEBU 05e[0m Creating Cache-MSP instance
[36m2019-01-29 10:33:55.331 UTC [msp] Setup -> DEBU 05f[0m Setting up MSP instance Hospital2MSP
[36m2019-01-29 10:33:55.332 UTC [msp/identity] newIdentity -> DEBU 060[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdjCCAhygAwIBAgIRALZ3Pffn/xWUtUWPSK6CYVAwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFowgYsxCzAJBgNVBAYTAlVTMRMwEQYD
VQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4gRnJhbmNpc2NvMSUwIwYDVQQK
Exxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMSgwJgYDVQQDEx9jYS5ob3Nw
aXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcD
QgAESzVpiz6P4mIb+KwvrttcXJKZR5i137Is4298E7OrkYdAg0tB4rpfKTXzUMwW
vI12cTDujpyaZSiqQ3/zP4fOQqNfMF0wDgYDVR0PAQH/BAQDAgGmMA8GA1UdJQQI
MAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQg8QJqWKPaX24HINwR
S6sINFSwRD+440/ccSnvFVaGF24wCgYIKoZIzj0EAwIDSAAwRQIhAPO2Nng3/nqb
cKPliUqVPVjBMu+D55M90+jexWSOpkjcAiADPx8qv9exZ4BfP3+G49Qzpx0Meblj
53vzUgYFa/0EXw==
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.332 UTC [msp/identity] newIdentity -> DEBU 061[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAJ6XtHMTTW1JzdpD54qCc3wwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwyLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABA+z1rb9aA1HwHfNLi9V9VZe
bdwT4MXak445zGz4DXzRUsmNeBngzntKb6qpgHQpeFtzbzLx+zwiynRDvfdzORGj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIPEC
alij2l9uByDcEUurCDRUsEQ/uONP3HEp7xVWhhduMAoGCCqGSM49BAMCA0cAMEQC
IA8A3CCJeCasyy7gYd/M1aHYmwWsecY7UY7cVUGy4XOxAiB0rrmfnGW6JA11PDCu
+5c5Rpn0jF5ddsFn+UIpzBFvmg==
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.333 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 062[0m Checking if identity satisfies role [CLIENT] for Hospital2MSP
[36m2019-01-29 10:33:55.334 UTC [msp] Validate -> DEBU 063[0m MSP Hospital2MSP validating identity
[36m2019-01-29 10:33:55.334 UTC [msp] getCertificationChain -> DEBU 064[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 10:33:55.334 UTC [msp] hasOURole -> DEBU 065[0m MSP Hospital2MSP checking if the identity is a client
[36m2019-01-29 10:33:55.334 UTC [msp] getCertificationChain -> DEBU 066[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 10:33:55.335 UTC [common/channelconfig] NewStandardValues -> DEBU 067[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 10:33:55.335 UTC [common/channelconfig] initializeProtosStruct -> DEBU 068[0m Processing field: AnchorPeers
[36m2019-01-29 10:33:55.335 UTC [common/channelconfig] NewStandardValues -> DEBU 069[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:33:55.335 UTC [common/channelconfig] initializeProtosStruct -> DEBU 06a[0m Processing field: MSP
[36m2019-01-29 10:33:55.335 UTC [common/channelconfig] Validate -> DEBU 06b[0m Anchor peers for org Hospital3MSP are 
[36m2019-01-29 10:33:55.335 UTC [common/channelconfig] validateMSP -> DEBU 06c[0m Setting up MSP for org Hospital3MSP
[36m2019-01-29 10:33:55.335 UTC [msp] newBccspMsp -> DEBU 06d[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:33:55.336 UTC [msp] New -> DEBU 06e[0m Creating Cache-MSP instance
[36m2019-01-29 10:33:55.336 UTC [msp] Setup -> DEBU 06f[0m Setting up MSP instance Hospital3MSP
[36m2019-01-29 10:33:55.336 UTC [msp/identity] newIdentity -> DEBU 070[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdTCCAhugAwIBAgIQCCXeHGgObIJo8aq4AdvgVjAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMy5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQm1Oo/AEu7ZZToE15Y5ntlaN128Hs/exX3jNH5nO6r4tvyFtBBNEn1ecXxxPtm
dmQ+nPHONorLwDC42SMAKwfro18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCA7vVWFXWpgZBojQ1ZL
xUvgBLeia59MivIRcjxmYanpyTAKBggqhkjOPQQDAgNIADBFAiEAlOUoPtpfO8V7
vFRCanjU5zZWGO5ajFlPDJjjDTy3UrwCICrUYV32JrR/m3dslCl15dSThHrKtYCC
Ehvyw1+lNqiG
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.337 UTC [msp/identity] newIdentity -> DEBU 071[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAI8BA/5Jf+5m8ncI+D7aSiMwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwzLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABF1IehIKIjh8tXYZ7rw4QOuc
g/tpBAkJeOt44zr/LepbjhyFW8vIRnkw75i6Wcg+LOoAS+2NFNg2oNjqg//yCHWj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIDu9
VYVdamBkGiNDVkvFS+AEt6Jrn0yK8hFyPGZhqenJMAoGCCqGSM49BAMCA0cAMEQC
IFyc85pwbCAxGNdw4fflsX2I3HrP3h93YAB2zSDC8HtkAiAQxblAZfEnXUiQKrqE
8I10bYJqD6pJz1jb3Pv+4xplTA==
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.338 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 072[0m Checking if identity satisfies role [CLIENT] for Hospital3MSP
[36m2019-01-29 10:33:55.338 UTC [msp] Validate -> DEBU 073[0m MSP Hospital3MSP validating identity
[36m2019-01-29 10:33:55.338 UTC [msp] getCertificationChain -> DEBU 074[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 10:33:55.339 UTC [msp] hasOURole -> DEBU 075[0m MSP Hospital3MSP checking if the identity is a client
[36m2019-01-29 10:33:55.339 UTC [msp] getCertificationChain -> DEBU 076[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 10:33:55.339 UTC [common/channelconfig] NewStandardValues -> DEBU 077[0m Initializing protos for *channelconfig.OrdererProtos
[36m2019-01-29 10:33:55.339 UTC [common/channelconfig] initializeProtosStruct -> DEBU 078[0m Processing field: ConsensusType
[36m2019-01-29 10:33:55.339 UTC [common/channelconfig] initializeProtosStruct -> DEBU 079[0m Processing field: BatchSize
[36m2019-01-29 10:33:55.340 UTC [common/channelconfig] initializeProtosStruct -> DEBU 07a[0m Processing field: BatchTimeout
[36m2019-01-29 10:33:55.340 UTC [common/channelconfig] initializeProtosStruct -> DEBU 07b[0m Processing field: KafkaBrokers
[36m2019-01-29 10:33:55.340 UTC [common/channelconfig] initializeProtosStruct -> DEBU 07c[0m Processing field: ChannelRestrictions
[36m2019-01-29 10:33:55.340 UTC [common/channelconfig] initializeProtosStruct -> DEBU 07d[0m Processing field: Capabilities
[36m2019-01-29 10:33:55.340 UTC [common/channelconfig] NewStandardValues -> DEBU 07e[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:33:55.340 UTC [common/channelconfig] initializeProtosStruct -> DEBU 07f[0m Processing field: MSP
[36m2019-01-29 10:33:55.340 UTC [common/channelconfig] validateMSP -> DEBU 080[0m Setting up MSP for org OrdererOrg
[36m2019-01-29 10:33:55.340 UTC [msp] newBccspMsp -> DEBU 081[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:33:55.341 UTC [msp] New -> DEBU 082[0m Creating Cache-MSP instance
[36m2019-01-29 10:33:55.341 UTC [msp] Setup -> DEBU 083[0m Setting up MSP instance OrdererMSP
[36m2019-01-29 10:33:55.341 UTC [msp/identity] newIdentity -> DEBU 084[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICSzCCAfKgAwIBAgIRAO7EFp+tGDrZX/4Yn1ExG4IwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowdzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEe
MBwGA1UEAxMVY2Euc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZI
zj0DAQcDQgAE+ci0VrQQEnBN2VlYMEvGL0RvqwQ9zVhgyxdKDi9AB8iyQ0dhyWzJ
CZ9MnAWGk29pw9b+9HdNkbalpJKWkcctJ6NfMF0wDgYDVR0PAQH/BAQDAgGmMA8G
A1UdJQQIMAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgGIY2e0Pm
0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDRwAwRAIgcoBa
RHN5r57Qu7sd8TwCzfyJI+uozczAYI2SsN06iKgCIAeAP4FbTHxjqSLcNZMNGbTZ
YWA1h+rDBMa99duId/0D
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.342 UTC [msp/identity] newIdentity -> DEBU 085[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICHzCCAcWgAwIBAgIQRo5Qm6m11gCv1i2SXwRJAjAKBggqhkjOPQQDAjB3MQsw
CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy
YW5jaXNjbzEbMBkGA1UEChMSc3dpdGNoMmxvZ2ljLmNvLnphMR4wHAYDVQQDExVj
YS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkwMTI5MDc0MTU0WhcNMjkwMTI2MDc0
MTU0WjBdMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UE
BxMNU2FuIEZyYW5jaXNjbzEhMB8GA1UEAwwYQWRtaW5Ac3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE0QeSwnrMZdy7TKSYF/JzQ12C
vfINZcjx7xyeUuj/96gj42fjc1ctn7oo/tDl1eJNZbDhFvkRzefYmxtoSnH5Y6NN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgGIY2
e0Pm0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDSAAwRQIh
AM8EkjCZIKrAf9sL1d1fThizng+66jmEVlKPbTpimVbiAiAhCJZoeBIJGcgxbCr2
5Rd2IW34zWcPhemkNZvCKv27WA==
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.342 UTC [msp] Validate -> DEBU 086[0m MSP OrdererMSP validating identity
[36m2019-01-29 10:33:55.343 UTC [msp] Setup -> DEBU 087[0m Setting up the MSP manager (4 msps)
[36m2019-01-29 10:33:55.343 UTC [msp] Setup -> DEBU 088[0m MSP manager setup complete, setup 4 msps
[36m2019-01-29 10:33:55.343 UTC [policies] NewManagerImpl -> DEBU 089[0m Proposed new policy Admins for Channel/Orderer/OrdererOrg
[36m2019-01-29 10:33:55.343 UTC [policies] NewManagerImpl -> DEBU 08a[0m Proposed new policy Readers for Channel/Orderer/OrdererOrg
[36m2019-01-29 10:33:55.343 UTC [policies] NewManagerImpl -> DEBU 08b[0m Proposed new policy Writers for Channel/Orderer/OrdererOrg
[36m2019-01-29 10:33:55.343 UTC [policies] NewManagerImpl -> DEBU 08c[0m Proposed new policy Writers for Channel/Orderer
[36m2019-01-29 10:33:55.343 UTC [policies] NewManagerImpl -> DEBU 08d[0m Proposed new policy BlockValidation for Channel/Orderer
[36m2019-01-29 10:33:55.343 UTC [policies] NewManagerImpl -> DEBU 08e[0m Proposed new policy Admins for Channel/Orderer
[36m2019-01-29 10:33:55.343 UTC [policies] NewManagerImpl -> DEBU 08f[0m Proposed new policy Readers for Channel/Orderer
[36m2019-01-29 10:33:55.343 UTC [policies] NewManagerImpl -> DEBU 090[0m Proposed new policy Admins for Channel/Application/Hospital1MSP
[36m2019-01-29 10:33:55.343 UTC [policies] NewManagerImpl -> DEBU 091[0m Proposed new policy Readers for Channel/Application/Hospital1MSP
[36m2019-01-29 10:33:55.343 UTC [policies] NewManagerImpl -> DEBU 092[0m Proposed new policy Writers for Channel/Application/Hospital1MSP
[36m2019-01-29 10:33:55.344 UTC [policies] NewManagerImpl -> DEBU 093[0m Proposed new policy Readers for Channel/Application/Hospital2MSP
[36m2019-01-29 10:33:55.344 UTC [policies] NewManagerImpl -> DEBU 094[0m Proposed new policy Writers for Channel/Application/Hospital2MSP
[36m2019-01-29 10:33:55.344 UTC [policies] NewManagerImpl -> DEBU 095[0m Proposed new policy Admins for Channel/Application/Hospital2MSP
[36m2019-01-29 10:33:55.344 UTC [policies] NewManagerImpl -> DEBU 096[0m Proposed new policy Admins for Channel/Application/Hospital3MSP
[36m2019-01-29 10:33:55.344 UTC [policies] NewManagerImpl -> DEBU 097[0m Proposed new policy Readers for Channel/Application/Hospital3MSP
[36m2019-01-29 10:33:55.344 UTC [policies] NewManagerImpl -> DEBU 098[0m Proposed new policy Writers for Channel/Application/Hospital3MSP
[36m2019-01-29 10:33:55.344 UTC [policies] NewManagerImpl -> DEBU 099[0m Proposed new policy Writers for Channel/Application
[36m2019-01-29 10:33:55.344 UTC [policies] NewManagerImpl -> DEBU 09a[0m Proposed new policy Admins for Channel/Application
[36m2019-01-29 10:33:55.344 UTC [policies] NewManagerImpl -> DEBU 09b[0m Proposed new policy Readers for Channel/Application
[36m2019-01-29 10:33:55.344 UTC [policies] NewManagerImpl -> DEBU 09c[0m Proposed new policy Writers for Channel
[36m2019-01-29 10:33:55.345 UTC [policies] NewManagerImpl -> DEBU 09d[0m Proposed new policy Admins for Channel
[36m2019-01-29 10:33:55.345 UTC [policies] NewManagerImpl -> DEBU 09e[0m Proposed new policy Readers for Channel
[36m2019-01-29 10:33:55.345 UTC [common/configtx] addToMap -> DEBU 09f[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 10:33:55.345 UTC [common/configtx] addToMap -> DEBU 0a0[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 10:33:55.346 UTC [common/configtx] addToMap -> DEBU 0a1[0m Adding to config map: [Group]  /Channel/Application/Hospital1MSP
[36m2019-01-29 10:33:55.346 UTC [common/configtx] addToMap -> DEBU 0a2[0m Adding to config map: [Value]  /Channel/Application/Hospital1MSP/MSP
[36m2019-01-29 10:33:55.354 UTC [common/configtx] addToMap -> DEBU 0a3[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Admins
[36m2019-01-29 10:33:55.355 UTC [common/configtx] addToMap -> DEBU 0a4[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Readers
[36m2019-01-29 10:33:55.355 UTC [common/configtx] addToMap -> DEBU 0a5[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Writers
[36m2019-01-29 10:33:55.355 UTC [common/configtx] addToMap -> DEBU 0a6[0m Adding to config map: [Group]  /Channel/Application/Hospital2MSP
[36m2019-01-29 10:33:55.355 UTC [common/configtx] addToMap -> DEBU 0a7[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/MSP
[36m2019-01-29 10:33:55.355 UTC [common/configtx] addToMap -> DEBU 0a8[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 10:33:55.355 UTC [common/configtx] addToMap -> DEBU 0a9[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 10:33:55.356 UTC [common/configtx] addToMap -> DEBU 0aa[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 10:33:55.356 UTC [common/configtx] addToMap -> DEBU 0ab[0m Adding to config map: [Group]  /Channel/Application/Hospital3MSP
[36m2019-01-29 10:33:55.356 UTC [common/configtx] addToMap -> DEBU 0ac[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/MSP
[36m2019-01-29 10:33:55.356 UTC [common/configtx] addToMap -> DEBU 0ad[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Admins
[36m2019-01-29 10:33:55.356 UTC [common/configtx] addToMap -> DEBU 0ae[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Readers
[36m2019-01-29 10:33:55.356 UTC [common/configtx] addToMap -> DEBU 0af[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Writers
[36m2019-01-29 10:33:55.356 UTC [common/configtx] addToMap -> DEBU 0b0[0m Adding to config map: [Value]  /Channel/Application/Capabilities
[36m2019-01-29 10:33:55.356 UTC [common/configtx] addToMap -> DEBU 0b1[0m Adding to config map: [Policy] /Channel/Application/Writers
[36m2019-01-29 10:33:55.357 UTC [common/configtx] addToMap -> DEBU 0b2[0m Adding to config map: [Policy] /Channel/Application/Admins
[36m2019-01-29 10:33:55.357 UTC [common/configtx] addToMap -> DEBU 0b3[0m Adding to config map: [Policy] /Channel/Application/Readers
[36m2019-01-29 10:33:55.357 UTC [common/configtx] addToMap -> DEBU 0b4[0m Adding to config map: [Group]  /Channel/Orderer
[36m2019-01-29 10:33:55.357 UTC [common/configtx] addToMap -> DEBU 0b5[0m Adding to config map: [Group]  /Channel/Orderer/OrdererOrg
[36m2019-01-29 10:33:55.358 UTC [common/configtx] addToMap -> DEBU 0b6[0m Adding to config map: [Value]  /Channel/Orderer/OrdererOrg/MSP
[36m2019-01-29 10:33:55.358 UTC [common/configtx] addToMap -> DEBU 0b7[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Admins
[36m2019-01-29 10:33:55.358 UTC [common/configtx] addToMap -> DEBU 0b8[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Readers
[36m2019-01-29 10:33:55.358 UTC [common/configtx] addToMap -> DEBU 0b9[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Writers
[36m2019-01-29 10:33:55.358 UTC [common/configtx] addToMap -> DEBU 0ba[0m Adding to config map: [Value]  /Channel/Orderer/BatchSize
[36m2019-01-29 10:33:55.358 UTC [common/configtx] addToMap -> DEBU 0bb[0m Adding to config map: [Value]  /Channel/Orderer/BatchTimeout
[36m2019-01-29 10:33:55.359 UTC [common/configtx] addToMap -> DEBU 0bc[0m Adding to config map: [Value]  /Channel/Orderer/ChannelRestrictions
[36m2019-01-29 10:33:55.359 UTC [common/configtx] addToMap -> DEBU 0bd[0m Adding to config map: [Value]  /Channel/Orderer/Capabilities
[36m2019-01-29 10:33:55.359 UTC [common/configtx] addToMap -> DEBU 0be[0m Adding to config map: [Value]  /Channel/Orderer/KafkaBrokers
[36m2019-01-29 10:33:55.359 UTC [common/configtx] addToMap -> DEBU 0bf[0m Adding to config map: [Value]  /Channel/Orderer/ConsensusType
[36m2019-01-29 10:33:55.359 UTC [common/configtx] addToMap -> DEBU 0c0[0m Adding to config map: [Policy] /Channel/Orderer/Writers
[36m2019-01-29 10:33:55.359 UTC [common/configtx] addToMap -> DEBU 0c1[0m Adding to config map: [Policy] /Channel/Orderer/BlockValidation
[36m2019-01-29 10:33:55.360 UTC [common/configtx] addToMap -> DEBU 0c2[0m Adding to config map: [Policy] /Channel/Orderer/Admins
[36m2019-01-29 10:33:55.360 UTC [common/configtx] addToMap -> DEBU 0c3[0m Adding to config map: [Policy] /Channel/Orderer/Readers
[36m2019-01-29 10:33:55.360 UTC [common/configtx] addToMap -> DEBU 0c4[0m Adding to config map: [Value]  /Channel/Capabilities
[36m2019-01-29 10:33:55.360 UTC [common/configtx] addToMap -> DEBU 0c5[0m Adding to config map: [Value]  /Channel/Consortium
[36m2019-01-29 10:33:55.360 UTC [common/configtx] addToMap -> DEBU 0c6[0m Adding to config map: [Value]  /Channel/HashingAlgorithm
[36m2019-01-29 10:33:55.360 UTC [common/configtx] addToMap -> DEBU 0c7[0m Adding to config map: [Value]  /Channel/BlockDataHashingStructure
[36m2019-01-29 10:33:55.360 UTC [common/configtx] addToMap -> DEBU 0c8[0m Adding to config map: [Value]  /Channel/OrdererAddresses
[36m2019-01-29 10:33:55.360 UTC [common/configtx] addToMap -> DEBU 0c9[0m Adding to config map: [Policy] /Channel/Readers
[36m2019-01-29 10:33:55.361 UTC [common/configtx] addToMap -> DEBU 0ca[0m Adding to config map: [Policy] /Channel/Writers
[36m2019-01-29 10:33:55.361 UTC [common/configtx] addToMap -> DEBU 0cb[0m Adding to config map: [Policy] /Channel/Admins
[36m2019-01-29 10:33:55.361 UTC [common/channelconfig] LogSanityChecks -> DEBU 0cc[0m As expected, current configuration has policy '/Channel/Readers'
[36m2019-01-29 10:33:55.361 UTC [common/channelconfig] LogSanityChecks -> DEBU 0cd[0m As expected, current configuration has policy '/Channel/Writers'
[36m2019-01-29 10:33:55.361 UTC [policies] Manager -> DEBU 0ce[0m Manager Channel looking up path [Application]
[36m2019-01-29 10:33:55.361 UTC [policies] Manager -> DEBU 0cf[0m Manager Channel has managers Orderer
[36m2019-01-29 10:33:55.361 UTC [policies] Manager -> DEBU 0d0[0m Manager Channel has managers Application
[36m2019-01-29 10:33:55.361 UTC [policies] Manager -> DEBU 0d1[0m Manager Channel/Application looking up path []
[36m2019-01-29 10:33:55.361 UTC [policies] Manager -> DEBU 0d2[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 10:33:55.361 UTC [policies] Manager -> DEBU 0d3[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 10:33:55.362 UTC [policies] Manager -> DEBU 0d4[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 10:33:55.362 UTC [common/channelconfig] LogSanityChecks -> DEBU 0d5[0m As expected, current configuration has policy '/Channel/Application/Readers'
[36m2019-01-29 10:33:55.362 UTC [common/channelconfig] LogSanityChecks -> DEBU 0d6[0m As expected, current configuration has policy '/Channel/Application/Writers'
[36m2019-01-29 10:33:55.362 UTC [common/channelconfig] LogSanityChecks -> DEBU 0d7[0m As expected, current configuration has policy '/Channel/Application/Admins'
[36m2019-01-29 10:33:55.362 UTC [policies] Manager -> DEBU 0d8[0m Manager Channel looking up path [Orderer]
[36m2019-01-29 10:33:55.362 UTC [policies] Manager -> DEBU 0d9[0m Manager Channel has managers Orderer
[36m2019-01-29 10:33:55.362 UTC [policies] Manager -> DEBU 0da[0m Manager Channel has managers Application
[36m2019-01-29 10:33:55.362 UTC [policies] Manager -> DEBU 0db[0m Manager Channel/Orderer looking up path []
[36m2019-01-29 10:33:55.362 UTC [policies] Manager -> DEBU 0dc[0m Manager Channel/Orderer has managers OrdererOrg
[36m2019-01-29 10:33:55.362 UTC [common/channelconfig] LogSanityChecks -> DEBU 0dd[0m As expected, current configuration has policy '/Channel/Orderer/BlockValidation'
[36m2019-01-29 10:33:55.362 UTC [common/capabilities] Supported -> DEBU 0de[0m Orderer capability V1_1 is supported and is enabled
[36m2019-01-29 10:33:55.363 UTC [common/capabilities] Supported -> DEBU 0df[0m Channel capability V1_1 is supported and is enabled
[36m2019-01-29 10:33:55.363 UTC [orderer/commmon/multichannel] NewRegistrar -> DEBU 0e0[0m Starting chain: comunitychannel
[36m2019-01-29 10:33:55.363 UTC [fsblkstorage] Next -> DEBU 0e1[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=0
[36m2019-01-29 10:33:55.363 UTC [fsblkstorage] newBlockfileStream -> DEBU 0e2[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/comunitychannel/blockfile_000000], startOffset=[0]
[36m2019-01-29 10:33:55.363 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0e3[0m Remaining bytes=[21745], Going to peek [8] bytes
[36m2019-01-29 10:33:55.363 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0e4[0m Returning blockbytes - length=[21742], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 10:33:55.363 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0e5[0m blockbytes [21742] read from file [0]
[36m2019-01-29 10:33:55.364 UTC [orderer/commmon/multichannel] newBlockWriter -> DEBU 0e6[0m [channel: comunitychannel] Creating block writer for tip of chain (blockNumber=0, lastConfigBlockNum=0, lastConfigSeq=1)
2019-01-29 10:33:55.364 UTC [orderer/consensus/kafka] newChain -> INFO 0e7[0m [channel: comunitychannel] Starting chain with last persisted offset -3 and last recorded block 0
[36m2019-01-29 10:33:55.364 UTC [orderer/commmon/multichannel] newChainSupport -> DEBU 0e8[0m [channel: comunitychannel] Done creating channel support resources
[36m2019-01-29 10:33:55.364 UTC [fsblkstorage] newBlockfileMgr -> DEBU 0e9[0m newBlockfileMgr() initializing file-based block storage for ledger: testchainid 
[36m2019-01-29 10:33:55.364 UTC [kvledger.util] CreateDirIfMissing -> DEBU 0eb[0m CreateDirIfMissing [/var/hyperledger/production/orderer/chains/testchainid/]
[36m2019-01-29 10:33:55.364 UTC [kvledger.util] logDirStatus -> DEBU 0ec[0m Before creating dir - [/var/hyperledger/production/orderer/chains/testchainid/] exists
2019-01-29 10:33:55.364 UTC [orderer/consensus/kafka] setupProducerForChannel -> INFO 0ea[0m [channel: comunitychannel] Setting up the producer for this channel...
[36m2019-01-29 10:33:55.365 UTC [orderer/consensus/kafka] try -> DEBU 0ed[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:33:55.365 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 0ee[0m Initializing new client
[36m2019-01-29 10:33:55.365 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 0ef[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.365 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 0f0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.365 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 0f1[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:55.367 UTC [kvledger.util] logDirStatus -> DEBU 0f2[0m After creating dir - [/var/hyperledger/production/orderer/chains/testchainid/] exists
[36m2019-01-29 10:33:55.367 UTC [fsblkstorage] loadCurrentInfo -> DEBU 0f3[0m loaded checkpointInfo:latestFileChunkSuffixNum=[0], latestFileChunksize=[43120], isChainEmpty=[false], lastBlockNumber=[1]
[36m2019-01-29 10:33:55.367 UTC [fsblkstorage] newBlockfileMgr -> DEBU 0f4[0m Synching block information from block storage (if needed)
[36m2019-01-29 10:33:55.367 UTC [fsblkstorage] syncCPInfoFromFS -> DEBU 0f5[0m Starting checkpoint=latestFileChunkSuffixNum=[0], latestFileChunksize=[43120], isChainEmpty=[false], lastBlockNumber=[1]
[36m2019-01-29 10:33:55.367 UTC [fsblkstorage] syncCPInfoFromFS -> DEBU 0f6[0m status of file [/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000]: exists=[true], size=[43120]
[36m2019-01-29 10:33:55.377 UTC [fsblkstorage] newBlockIndex -> DEBU 0f7[0m newBlockIndex() - indexItems:[[BlockNum]]
[36m2019-01-29 10:33:55.377 UTC [fsblkstorage] syncIndex -> DEBU 0f8[0m Both the block files and indices are in sync.
[36m2019-01-29 10:33:55.378 UTC [fsblkstorage] retrieveBlockHeaderByNumber -> DEBU 0f9[0m retrieveBlockHeaderByNumber() - blockNum = [1]
[36m2019-01-29 10:33:55.378 UTC [fsblkstorage] newBlockfileStream -> DEBU 0fa[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[18495]
[36m2019-01-29 10:33:55.378 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0fb[0m Remaining bytes=[24625], Going to peek [8] bytes
[36m2019-01-29 10:33:55.378 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0fc[0m Returning blockbytes - length=[24622], placementInfo={fileNum=[0], startOffset=[18495], bytesOffset=[18498]}
[36m2019-01-29 10:33:55.379 UTC [fsblkstorage] Next -> DEBU 0fd[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=1
[36m2019-01-29 10:33:55.379 UTC [fsblkstorage] newBlockfileStream -> DEBU 0fe[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[18495]
[36m2019-01-29 10:33:55.379 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0ff[0m Remaining bytes=[24625], Going to peek [8] bytes
[36m2019-01-29 10:33:55.379 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 100[0m Returning blockbytes - length=[24622], placementInfo={fileNum=[0], startOffset=[18495], bytesOffset=[18498]}
[36m2019-01-29 10:33:55.379 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 101[0m blockbytes [24622] read from file [0]
[36m2019-01-29 10:33:55.379 UTC [fsblkstorage] Next -> DEBU 102[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=1
[36m2019-01-29 10:33:55.379 UTC [fsblkstorage] newBlockfileStream -> DEBU 103[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[0]
[36m2019-01-29 10:33:55.380 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 104[0m Remaining bytes=[43120], Going to peek [8] bytes
[36m2019-01-29 10:33:55.380 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 105[0m Returning blockbytes - length=[18492], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 10:33:55.380 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 106[0m blockbytes [18492] read from file [0]
[36m2019-01-29 10:33:55.380 UTC [common/channelconfig] NewStandardValues -> DEBU 107[0m Initializing protos for *channelconfig.ChannelProtos
[36m2019-01-29 10:33:55.380 UTC [common/channelconfig] initializeProtosStruct -> DEBU 108[0m Processing field: HashingAlgorithm
[36m2019-01-29 10:33:55.380 UTC [common/channelconfig] initializeProtosStruct -> DEBU 109[0m Processing field: BlockDataHashingStructure
[36m2019-01-29 10:33:55.381 UTC [common/channelconfig] initializeProtosStruct -> DEBU 10a[0m Processing field: OrdererAddresses
[36m2019-01-29 10:33:55.381 UTC [common/channelconfig] initializeProtosStruct -> DEBU 10b[0m Processing field: Consortium
[36m2019-01-29 10:33:55.381 UTC [common/channelconfig] initializeProtosStruct -> DEBU 10c[0m Processing field: Capabilities
[36m2019-01-29 10:33:55.381 UTC [common/channelconfig] NewStandardValues -> DEBU 10d[0m Initializing protos for *channelconfig.ConsortiumProtos
[36m2019-01-29 10:33:55.381 UTC [common/channelconfig] initializeProtosStruct -> DEBU 10e[0m Processing field: ChannelCreationPolicy
[36m2019-01-29 10:33:55.381 UTC [common/channelconfig] NewStandardValues -> DEBU 10f[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:33:55.381 UTC [common/channelconfig] initializeProtosStruct -> DEBU 110[0m Processing field: MSP
[36m2019-01-29 10:33:55.381 UTC [common/channelconfig] validateMSP -> DEBU 111[0m Setting up MSP for org Hospital1MSP
[36m2019-01-29 10:33:55.382 UTC [msp] newBccspMsp -> DEBU 112[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:33:55.382 UTC [msp] New -> DEBU 113[0m Creating Cache-MSP instance
[36m2019-01-29 10:33:55.382 UTC [msp] Setup -> DEBU 114[0m Setting up MSP instance Hospital1MSP
[36m2019-01-29 10:33:55.382 UTC [msp/identity] newIdentity -> DEBU 115[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdDCCAhugAwIBAgIQZxH8VsnceZxXgKxlURLgVTAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMS5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQX9V4k/h/3pFxByKDscjgQrC0YS/bSbKvzSG2Z2PvltEWp40qB9OaKUN0GQYzo
yK2Etdvyjfd1OFwaTjpGSvv9o18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCBVU7DoP9Msf/nNTNl6
5FxwAXZ82eaGBT7zWYdyh4QbBjAKBggqhkjOPQQDAgNHADBEAiBmXGWQbxCGRp0c
5/y9qJyciB1CDHsknRZDjNzt5f563wIgMy7VPi1R8DpIIIRN9B3mfhDpRa+J+8PA
S4DOJy7rjp4=
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.383 UTC [msp/identity] newIdentity -> DEBU 116[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfWgAwIBAgIQbzxpSKiuJCzDiDlZp+XbWDAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjB4MQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZyYW5jaXNjbzEPMA0GA1UECxMG
Y2xpZW50MSswKQYDVQQDDCJBZG1pbkBob3NwaXRhbDEuc3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEnpADl8+aUBcVWv6q3IgMQ4yg
ISawQ0wamHmpSv+/b1B5hf4V2HyoPrawIr45+o4/Qz++WazZlyY7PkoT27r7KaNN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgVVOw
6D/TLH/5zUzZeuRccAF2fNnmhgU+81mHcoeEGwYwCgYIKoZIzj0EAwIDSAAwRQIh
ALavdMm9i6xSsnWdlliMh10s6dmGBaXO0CxaCowLJIMtAiBEduudGJymDDE1zbiX
YwX83cYWZHUcYV8IXeZPFymC+w==
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.384 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 117[0m Checking if identity satisfies role [CLIENT] for Hospital1MSP
[36m2019-01-29 10:33:55.384 UTC [msp] Validate -> DEBU 118[0m MSP Hospital1MSP validating identity
[36m2019-01-29 10:33:55.385 UTC [msp] getCertificationChain -> DEBU 119[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 10:33:55.386 UTC [msp] hasOURole -> DEBU 11a[0m MSP Hospital1MSP checking if the identity is a client
[36m2019-01-29 10:33:55.386 UTC [msp] getCertificationChain -> DEBU 11b[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 10:33:55.386 UTC [common/channelconfig] NewStandardValues -> DEBU 11c[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:33:55.386 UTC [common/channelconfig] initializeProtosStruct -> DEBU 11d[0m Processing field: MSP
[36m2019-01-29 10:33:55.386 UTC [common/channelconfig] validateMSP -> DEBU 11e[0m Setting up MSP for org Hospital2MSP
[36m2019-01-29 10:33:55.386 UTC [msp] newBccspMsp -> DEBU 11f[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:33:55.387 UTC [msp] New -> DEBU 120[0m Creating Cache-MSP instance
[36m2019-01-29 10:33:55.387 UTC [msp] Setup -> DEBU 121[0m Setting up MSP instance Hospital2MSP
[36m2019-01-29 10:33:55.387 UTC [msp/identity] newIdentity -> DEBU 122[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdjCCAhygAwIBAgIRALZ3Pffn/xWUtUWPSK6CYVAwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFowgYsxCzAJBgNVBAYTAlVTMRMwEQYD
VQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4gRnJhbmNpc2NvMSUwIwYDVQQK
Exxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMSgwJgYDVQQDEx9jYS5ob3Nw
aXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcD
QgAESzVpiz6P4mIb+KwvrttcXJKZR5i137Is4298E7OrkYdAg0tB4rpfKTXzUMwW
vI12cTDujpyaZSiqQ3/zP4fOQqNfMF0wDgYDVR0PAQH/BAQDAgGmMA8GA1UdJQQI
MAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQg8QJqWKPaX24HINwR
S6sINFSwRD+440/ccSnvFVaGF24wCgYIKoZIzj0EAwIDSAAwRQIhAPO2Nng3/nqb
cKPliUqVPVjBMu+D55M90+jexWSOpkjcAiADPx8qv9exZ4BfP3+G49Qzpx0Meblj
53vzUgYFa/0EXw==
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.388 UTC [msp/identity] newIdentity -> DEBU 123[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAJ6XtHMTTW1JzdpD54qCc3wwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwyLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABA+z1rb9aA1HwHfNLi9V9VZe
bdwT4MXak445zGz4DXzRUsmNeBngzntKb6qpgHQpeFtzbzLx+zwiynRDvfdzORGj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIPEC
alij2l9uByDcEUurCDRUsEQ/uONP3HEp7xVWhhduMAoGCCqGSM49BAMCA0cAMEQC
IA8A3CCJeCasyy7gYd/M1aHYmwWsecY7UY7cVUGy4XOxAiB0rrmfnGW6JA11PDCu
+5c5Rpn0jF5ddsFn+UIpzBFvmg==
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.389 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 124[0m Checking if identity satisfies role [CLIENT] for Hospital2MSP
[36m2019-01-29 10:33:55.389 UTC [msp] Validate -> DEBU 125[0m MSP Hospital2MSP validating identity
[36m2019-01-29 10:33:55.389 UTC [msp] getCertificationChain -> DEBU 126[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 10:33:55.390 UTC [msp] hasOURole -> DEBU 127[0m MSP Hospital2MSP checking if the identity is a client
[36m2019-01-29 10:33:55.390 UTC [msp] getCertificationChain -> DEBU 128[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 10:33:55.391 UTC [common/channelconfig] NewStandardValues -> DEBU 129[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:33:55.391 UTC [common/channelconfig] initializeProtosStruct -> DEBU 12a[0m Processing field: MSP
[36m2019-01-29 10:33:55.392 UTC [common/channelconfig] validateMSP -> DEBU 12b[0m Setting up MSP for org Hospital3MSP
[36m2019-01-29 10:33:55.392 UTC [msp] newBccspMsp -> DEBU 12c[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:33:55.392 UTC [msp] New -> DEBU 12d[0m Creating Cache-MSP instance
[36m2019-01-29 10:33:55.392 UTC [msp] Setup -> DEBU 12e[0m Setting up MSP instance Hospital3MSP
[36m2019-01-29 10:33:55.393 UTC [msp/identity] newIdentity -> DEBU 12f[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdTCCAhugAwIBAgIQCCXeHGgObIJo8aq4AdvgVjAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMy5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQm1Oo/AEu7ZZToE15Y5ntlaN128Hs/exX3jNH5nO6r4tvyFtBBNEn1ecXxxPtm
dmQ+nPHONorLwDC42SMAKwfro18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCA7vVWFXWpgZBojQ1ZL
xUvgBLeia59MivIRcjxmYanpyTAKBggqhkjOPQQDAgNIADBFAiEAlOUoPtpfO8V7
vFRCanjU5zZWGO5ajFlPDJjjDTy3UrwCICrUYV32JrR/m3dslCl15dSThHrKtYCC
Ehvyw1+lNqiG
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.393 UTC [msp/identity] newIdentity -> DEBU 130[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAI8BA/5Jf+5m8ncI+D7aSiMwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwzLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABF1IehIKIjh8tXYZ7rw4QOuc
g/tpBAkJeOt44zr/LepbjhyFW8vIRnkw75i6Wcg+LOoAS+2NFNg2oNjqg//yCHWj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIDu9
VYVdamBkGiNDVkvFS+AEt6Jrn0yK8hFyPGZhqenJMAoGCCqGSM49BAMCA0cAMEQC
IFyc85pwbCAxGNdw4fflsX2I3HrP3h93YAB2zSDC8HtkAiAQxblAZfEnXUiQKrqE
8I10bYJqD6pJz1jb3Pv+4xplTA==
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.394 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 131[0m Checking if identity satisfies role [CLIENT] for Hospital3MSP
[36m2019-01-29 10:33:55.394 UTC [msp] Validate -> DEBU 132[0m MSP Hospital3MSP validating identity
[36m2019-01-29 10:33:55.395 UTC [msp] getCertificationChain -> DEBU 133[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 10:33:55.395 UTC [msp] hasOURole -> DEBU 134[0m MSP Hospital3MSP checking if the identity is a client
[36m2019-01-29 10:33:55.395 UTC [msp] getCertificationChain -> DEBU 135[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 10:33:55.396 UTC [common/channelconfig] NewStandardValues -> DEBU 136[0m Initializing protos for *channelconfig.OrdererProtos
[36m2019-01-29 10:33:55.396 UTC [common/channelconfig] initializeProtosStruct -> DEBU 137[0m Processing field: ConsensusType
[36m2019-01-29 10:33:55.396 UTC [common/channelconfig] initializeProtosStruct -> DEBU 138[0m Processing field: BatchSize
[36m2019-01-29 10:33:55.396 UTC [common/channelconfig] initializeProtosStruct -> DEBU 139[0m Processing field: BatchTimeout
[36m2019-01-29 10:33:55.396 UTC [common/channelconfig] initializeProtosStruct -> DEBU 13a[0m Processing field: KafkaBrokers
[36m2019-01-29 10:33:55.396 UTC [common/channelconfig] initializeProtosStruct -> DEBU 13b[0m Processing field: ChannelRestrictions
[36m2019-01-29 10:33:55.396 UTC [common/channelconfig] initializeProtosStruct -> DEBU 13c[0m Processing field: Capabilities
[36m2019-01-29 10:33:55.397 UTC [common/channelconfig] NewStandardValues -> DEBU 13d[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:33:55.397 UTC [common/channelconfig] initializeProtosStruct -> DEBU 13e[0m Processing field: MSP
[36m2019-01-29 10:33:55.397 UTC [common/channelconfig] validateMSP -> DEBU 13f[0m Setting up MSP for org OrdererOrg
[36m2019-01-29 10:33:55.397 UTC [msp] newBccspMsp -> DEBU 140[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:33:55.397 UTC [msp] New -> DEBU 141[0m Creating Cache-MSP instance
[36m2019-01-29 10:33:55.397 UTC [msp] Setup -> DEBU 142[0m Setting up MSP instance OrdererMSP
[36m2019-01-29 10:33:55.398 UTC [msp/identity] newIdentity -> DEBU 143[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICSzCCAfKgAwIBAgIRAO7EFp+tGDrZX/4Yn1ExG4IwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowdzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEe
MBwGA1UEAxMVY2Euc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZI
zj0DAQcDQgAE+ci0VrQQEnBN2VlYMEvGL0RvqwQ9zVhgyxdKDi9AB8iyQ0dhyWzJ
CZ9MnAWGk29pw9b+9HdNkbalpJKWkcctJ6NfMF0wDgYDVR0PAQH/BAQDAgGmMA8G
A1UdJQQIMAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgGIY2e0Pm
0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDRwAwRAIgcoBa
RHN5r57Qu7sd8TwCzfyJI+uozczAYI2SsN06iKgCIAeAP4FbTHxjqSLcNZMNGbTZ
YWA1h+rDBMa99duId/0D
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.398 UTC [msp/identity] newIdentity -> DEBU 144[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICHzCCAcWgAwIBAgIQRo5Qm6m11gCv1i2SXwRJAjAKBggqhkjOPQQDAjB3MQsw
CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy
YW5jaXNjbzEbMBkGA1UEChMSc3dpdGNoMmxvZ2ljLmNvLnphMR4wHAYDVQQDExVj
YS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkwMTI5MDc0MTU0WhcNMjkwMTI2MDc0
MTU0WjBdMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UE
BxMNU2FuIEZyYW5jaXNjbzEhMB8GA1UEAwwYQWRtaW5Ac3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE0QeSwnrMZdy7TKSYF/JzQ12C
vfINZcjx7xyeUuj/96gj42fjc1ctn7oo/tDl1eJNZbDhFvkRzefYmxtoSnH5Y6NN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgGIY2
e0Pm0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDSAAwRQIh
AM8EkjCZIKrAf9sL1d1fThizng+66jmEVlKPbTpimVbiAiAhCJZoeBIJGcgxbCr2
5Rd2IW34zWcPhemkNZvCKv27WA==
-----END CERTIFICATE-----
[36m2019-01-29 10:33:55.399 UTC [msp] Validate -> DEBU 145[0m MSP OrdererMSP validating identity
[36m2019-01-29 10:33:55.399 UTC [msp] Setup -> DEBU 146[0m Setting up the MSP manager (4 msps)
[36m2019-01-29 10:33:55.399 UTC [msp] Setup -> DEBU 147[0m MSP manager setup complete, setup 4 msps
[36m2019-01-29 10:33:55.400 UTC [policies] NewManagerImpl -> DEBU 148[0m Proposed new policy Admins for Channel/Consortiums/HospitalConsortium/Hospital1MSP
[36m2019-01-29 10:33:55.400 UTC [policies] NewManagerImpl -> DEBU 149[0m Proposed new policy Readers for Channel/Consortiums/HospitalConsortium/Hospital1MSP
[36m2019-01-29 10:33:55.400 UTC [policies] NewManagerImpl -> DEBU 14a[0m Proposed new policy Writers for Channel/Consortiums/HospitalConsortium/Hospital1MSP
[36m2019-01-29 10:33:55.400 UTC [policies] NewManagerImpl -> DEBU 14b[0m Proposed new policy Admins for Channel/Consortiums/HospitalConsortium/Hospital2MSP
[36m2019-01-29 10:33:55.400 UTC [policies] NewManagerImpl -> DEBU 14c[0m Proposed new policy Readers for Channel/Consortiums/HospitalConsortium/Hospital2MSP
[36m2019-01-29 10:33:55.400 UTC [policies] NewManagerImpl -> DEBU 14d[0m Proposed new policy Writers for Channel/Consortiums/HospitalConsortium/Hospital2MSP
[36m2019-01-29 10:33:55.400 UTC [policies] NewManagerImpl -> DEBU 14e[0m Proposed new policy Writers for Channel/Consortiums/HospitalConsortium/Hospital3MSP
[36m2019-01-29 10:33:55.400 UTC [policies] NewManagerImpl -> DEBU 14f[0m Proposed new policy Admins for Channel/Consortiums/HospitalConsortium/Hospital3MSP
[36m2019-01-29 10:33:55.401 UTC [policies] NewManagerImpl -> DEBU 150[0m Proposed new policy Readers for Channel/Consortiums/HospitalConsortium/Hospital3MSP
[36m2019-01-29 10:33:55.401 UTC [policies] NewManagerImpl -> DEBU 151[0m Proposed new policy Admins for Channel/Consortiums
[36m2019-01-29 10:33:55.401 UTC [policies] NewManagerImpl -> DEBU 152[0m Proposed new policy Readers for Channel/Orderer/OrdererOrg
[36m2019-01-29 10:33:55.401 UTC [policies] NewManagerImpl -> DEBU 153[0m Proposed new policy Writers for Channel/Orderer/OrdererOrg
[36m2019-01-29 10:33:55.401 UTC [policies] NewManagerImpl -> DEBU 154[0m Proposed new policy Admins for Channel/Orderer/OrdererOrg
[36m2019-01-29 10:33:55.401 UTC [policies] NewManagerImpl -> DEBU 155[0m Proposed new policy Admins for Channel/Orderer
[36m2019-01-29 10:33:55.401 UTC [policies] NewManagerImpl -> DEBU 156[0m Proposed new policy Readers for Channel/Orderer
[36m2019-01-29 10:33:55.404 UTC [policies] NewManagerImpl -> DEBU 157[0m Proposed new policy Writers for Channel/Orderer
[36m2019-01-29 10:33:55.404 UTC [policies] NewManagerImpl -> DEBU 158[0m Proposed new policy BlockValidation for Channel/Orderer
[36m2019-01-29 10:33:55.405 UTC [policies] NewManagerImpl -> DEBU 159[0m Proposed new policy Admins for Channel
[36m2019-01-29 10:33:55.406 UTC [policies] GetPolicy -> DEBU 15a[0m Returning dummy reject all policy because Readers could not be found in Channel/Consortiums/Readers
[36m2019-01-29 10:33:55.406 UTC [policies] NewManagerImpl -> DEBU 15b[0m Proposed new policy Readers for Channel
[36m2019-01-29 10:33:55.406 UTC [policies] GetPolicy -> DEBU 15c[0m Returning dummy reject all policy because Writers could not be found in Channel/Consortiums/Writers
[36m2019-01-29 10:33:55.406 UTC [policies] NewManagerImpl -> DEBU 15d[0m Proposed new policy Writers for Channel
[36m2019-01-29 10:33:55.406 UTC [common/configtx] addToMap -> DEBU 15e[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 10:33:55.407 UTC [common/configtx] addToMap -> DEBU 15f[0m Adding to config map: [Group]  /Channel/Consortiums
[36m2019-01-29 10:33:55.407 UTC [common/configtx] addToMap -> DEBU 160[0m Adding to config map: [Group]  /Channel/Consortiums/HospitalConsortium
[36m2019-01-29 10:33:55.408 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 161[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.410 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 162[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.411 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 163[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.412 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 164[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:55.432 UTC [common/configtx] addToMap -> DEBU 165[0m Adding to config map: [Group]  /Channel/Consortiums/HospitalConsortium/Hospital1MSP
[36m2019-01-29 10:33:55.433 UTC [common/configtx] addToMap -> DEBU 166[0m Adding to config map: [Value]  /Channel/Consortiums/HospitalConsortium/Hospital1MSP/MSP
[36m2019-01-29 10:33:55.434 UTC [common/configtx] addToMap -> DEBU 167[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital1MSP/Admins
[36m2019-01-29 10:33:55.434 UTC [common/configtx] addToMap -> DEBU 168[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital1MSP/Readers
[36m2019-01-29 10:33:55.434 UTC [common/configtx] addToMap -> DEBU 169[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital1MSP/Writers
[36m2019-01-29 10:33:55.434 UTC [common/configtx] addToMap -> DEBU 16a[0m Adding to config map: [Group]  /Channel/Consortiums/HospitalConsortium/Hospital2MSP
[36m2019-01-29 10:33:55.434 UTC [common/configtx] addToMap -> DEBU 16b[0m Adding to config map: [Value]  /Channel/Consortiums/HospitalConsortium/Hospital2MSP/MSP
[36m2019-01-29 10:33:55.435 UTC [common/configtx] addToMap -> DEBU 16c[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital2MSP/Admins
[36m2019-01-29 10:33:55.435 UTC [common/configtx] addToMap -> DEBU 16d[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital2MSP/Readers
[36m2019-01-29 10:33:55.435 UTC [common/configtx] addToMap -> DEBU 16e[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital2MSP/Writers
[36m2019-01-29 10:33:55.435 UTC [common/configtx] addToMap -> DEBU 16f[0m Adding to config map: [Group]  /Channel/Consortiums/HospitalConsortium/Hospital3MSP
[36m2019-01-29 10:33:55.436 UTC [common/configtx] addToMap -> DEBU 170[0m Adding to config map: [Value]  /Channel/Consortiums/HospitalConsortium/Hospital3MSP/MSP
[36m2019-01-29 10:33:55.436 UTC [common/configtx] addToMap -> DEBU 171[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital3MSP/Admins
[36m2019-01-29 10:33:55.436 UTC [common/configtx] addToMap -> DEBU 172[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital3MSP/Readers
[36m2019-01-29 10:33:55.436 UTC [common/configtx] addToMap -> DEBU 173[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital3MSP/Writers
[36m2019-01-29 10:33:55.436 UTC [common/configtx] addToMap -> DEBU 174[0m Adding to config map: [Value]  /Channel/Consortiums/HospitalConsortium/ChannelCreationPolicy
[36m2019-01-29 10:33:55.436 UTC [common/configtx] addToMap -> DEBU 175[0m Adding to config map: [Policy] /Channel/Consortiums/Admins
[36m2019-01-29 10:33:55.437 UTC [common/configtx] addToMap -> DEBU 176[0m Adding to config map: [Group]  /Channel/Orderer
[36m2019-01-29 10:33:55.437 UTC [common/configtx] addToMap -> DEBU 177[0m Adding to config map: [Group]  /Channel/Orderer/OrdererOrg
[36m2019-01-29 10:33:55.437 UTC [common/configtx] addToMap -> DEBU 178[0m Adding to config map: [Value]  /Channel/Orderer/OrdererOrg/MSP
[36m2019-01-29 10:33:55.437 UTC [common/configtx] addToMap -> DEBU 179[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Writers
[36m2019-01-29 10:33:55.437 UTC [common/configtx] addToMap -> DEBU 17a[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Admins
[36m2019-01-29 10:33:55.437 UTC [common/configtx] addToMap -> DEBU 17b[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Readers
[36m2019-01-29 10:33:55.438 UTC [common/configtx] addToMap -> DEBU 17c[0m Adding to config map: [Value]  /Channel/Orderer/ConsensusType
[36m2019-01-29 10:33:55.438 UTC [common/configtx] addToMap -> DEBU 17d[0m Adding to config map: [Value]  /Channel/Orderer/BatchSize
[36m2019-01-29 10:33:55.438 UTC [common/configtx] addToMap -> DEBU 17e[0m Adding to config map: [Value]  /Channel/Orderer/BatchTimeout
[36m2019-01-29 10:33:55.438 UTC [common/configtx] addToMap -> DEBU 17f[0m Adding to config map: [Value]  /Channel/Orderer/ChannelRestrictions
[36m2019-01-29 10:33:55.438 UTC [common/configtx] addToMap -> DEBU 180[0m Adding to config map: [Value]  /Channel/Orderer/Capabilities
[36m2019-01-29 10:33:55.438 UTC [common/configtx] addToMap -> DEBU 181[0m Adding to config map: [Value]  /Channel/Orderer/KafkaBrokers
[36m2019-01-29 10:33:55.438 UTC [common/configtx] addToMap -> DEBU 182[0m Adding to config map: [Policy] /Channel/Orderer/Admins
[36m2019-01-29 10:33:55.439 UTC [common/configtx] addToMap -> DEBU 183[0m Adding to config map: [Policy] /Channel/Orderer/Readers
[36m2019-01-29 10:33:55.439 UTC [common/configtx] addToMap -> DEBU 184[0m Adding to config map: [Policy] /Channel/Orderer/Writers
[36m2019-01-29 10:33:55.439 UTC [common/configtx] addToMap -> DEBU 185[0m Adding to config map: [Policy] /Channel/Orderer/BlockValidation
[36m2019-01-29 10:33:55.439 UTC [common/configtx] addToMap -> DEBU 186[0m Adding to config map: [Value]  /Channel/HashingAlgorithm
[36m2019-01-29 10:33:55.439 UTC [common/configtx] addToMap -> DEBU 187[0m Adding to config map: [Value]  /Channel/BlockDataHashingStructure
[36m2019-01-29 10:33:55.440 UTC [common/configtx] addToMap -> DEBU 188[0m Adding to config map: [Value]  /Channel/OrdererAddresses
[36m2019-01-29 10:33:55.440 UTC [common/configtx] addToMap -> DEBU 189[0m Adding to config map: [Value]  /Channel/Capabilities
[36m2019-01-29 10:33:55.440 UTC [common/configtx] addToMap -> DEBU 18a[0m Adding to config map: [Policy] /Channel/Admins
[36m2019-01-29 10:33:55.440 UTC [common/configtx] addToMap -> DEBU 18b[0m Adding to config map: [Policy] /Channel/Readers
[36m2019-01-29 10:33:55.440 UTC [common/configtx] addToMap -> DEBU 18c[0m Adding to config map: [Policy] /Channel/Writers
[36m2019-01-29 10:33:55.440 UTC [common/channelconfig] LogSanityChecks -> DEBU 18d[0m As expected, current configuration has policy '/Channel/Readers'
[36m2019-01-29 10:33:55.440 UTC [common/channelconfig] LogSanityChecks -> DEBU 18e[0m As expected, current configuration has policy '/Channel/Writers'
[36m2019-01-29 10:33:55.441 UTC [policies] Manager -> DEBU 18f[0m Manager Channel looking up path [Application]
[36m2019-01-29 10:33:55.441 UTC [policies] Manager -> DEBU 190[0m Manager Channel has managers Consortiums
[36m2019-01-29 10:33:55.441 UTC [policies] Manager -> DEBU 191[0m Manager Channel has managers Orderer
[36m2019-01-29 10:33:55.441 UTC [policies] Manager -> DEBU 192[0m Manager Channel looking up path [Orderer]
[36m2019-01-29 10:33:55.441 UTC [policies] Manager -> DEBU 193[0m Manager Channel has managers Consortiums
[36m2019-01-29 10:33:55.441 UTC [policies] Manager -> DEBU 194[0m Manager Channel has managers Orderer
[36m2019-01-29 10:33:55.442 UTC [policies] Manager -> DEBU 195[0m Manager Channel/Orderer looking up path []
[36m2019-01-29 10:33:55.442 UTC [policies] Manager -> DEBU 196[0m Manager Channel/Orderer has managers OrdererOrg
[36m2019-01-29 10:33:55.442 UTC [common/channelconfig] LogSanityChecks -> DEBU 197[0m As expected, current configuration has policy '/Channel/Orderer/BlockValidation'
[36m2019-01-29 10:33:55.442 UTC [common/capabilities] Supported -> DEBU 198[0m Orderer capability V1_1 is supported and is enabled
[36m2019-01-29 10:33:55.442 UTC [common/capabilities] Supported -> DEBU 199[0m Channel capability V1_1 is supported and is enabled
[36m2019-01-29 10:33:55.442 UTC [fsblkstorage] Next -> DEBU 19a[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=1
[36m2019-01-29 10:33:55.442 UTC [fsblkstorage] newBlockfileStream -> DEBU 19b[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[18495]
[36m2019-01-29 10:33:55.443 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 19c[0m Remaining bytes=[24625], Going to peek [8] bytes
[36m2019-01-29 10:33:55.443 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 19d[0m Returning blockbytes - length=[24622], placementInfo={fileNum=[0], startOffset=[18495], bytesOffset=[18498]}
[36m2019-01-29 10:33:55.443 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 19e[0m blockbytes [24622] read from file [0]
[36m2019-01-29 10:33:55.443 UTC [orderer/commmon/multichannel] newBlockWriter -> DEBU 19f[0m [channel: testchainid] Creating block writer for tip of chain (blockNumber=1, lastConfigBlockNum=0, lastConfigSeq=0)
2019-01-29 10:33:55.443 UTC [orderer/consensus/kafka] newChain -> INFO 1a0[0m [channel: testchainid] Starting chain with last persisted offset 5 and last recorded block 1
[36m2019-01-29 10:33:55.443 UTC [orderer/commmon/multichannel] newChainSupport -> DEBU 1a1[0m [channel: testchainid] Done creating channel support resources
[36m2019-01-29 10:33:55.443 UTC [orderer/common/msgprocessor] NewSystemChannel -> DEBU 1a2[0m Creating system channel msg processor for channel testchainid
[36m2019-01-29 10:33:55.444 UTC [fsblkstorage] Next -> DEBU 1a3[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=1
[36m2019-01-29 10:33:55.444 UTC [fsblkstorage] newBlockfileStream -> DEBU 1a4[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[0]
[36m2019-01-29 10:33:55.444 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 1a5[0m Remaining bytes=[43120], Going to peek [8] bytes
[36m2019-01-29 10:33:55.444 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 1a6[0m Returning blockbytes - length=[18492], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 10:33:55.444 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 1a7[0m blockbytes [18492] read from file [0]
2019-01-29 10:33:55.444 UTC [orderer/commmon/multichannel] NewRegistrar -> INFO 1a8[0m Starting system channel 'testchainid' with genesis block hash c84c51e50921c0294405e41d16cb6234273f63b37a240438cc9f32578277d7e3 and orderer type kafka
2019-01-29 10:33:55.444 UTC [orderer/common/server] Start -> INFO 1a9[0m Starting orderer:
 Version: 1.2.0
 Commit SHA: cae2ad4
 Go version: go1.10
 OS/Arch: linux/amd64
 Experimental features: false
2019-01-29 10:33:55.445 UTC [orderer/common/server] Start -> INFO 1ab[0m Beginning to serve requests
2019-01-29 10:33:55.445 UTC [orderer/consensus/kafka] setupProducerForChannel -> INFO 1aa[0m [channel: testchainid] Setting up the producer for this channel...
[36m2019-01-29 10:33:55.445 UTC [orderer/consensus/kafka] try -> DEBU 1ac[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:33:55.446 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 1ad[0m Initializing new client
[36m2019-01-29 10:33:55.446 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 1ae[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.446 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1af[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.446 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1b0[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:55.475 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1b1[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.476 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1b2[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.476 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1b3[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.476 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1b4[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:55.507 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1b5[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.507 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1b6[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.507 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1b7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.508 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1b8[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:55.508 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1b9[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.508 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1ba[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.508 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1bb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.508 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1bc[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:55.543 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1bd[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.543 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1bf[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.543 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1c0[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:55.543 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 1c1[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:55.543 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 1c2[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:33:55.543 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1be[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.544 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1c3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.544 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1c4[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:55.544 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 1c5[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:55.544 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 1c6[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:33:55.794 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1c7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.794 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1c9[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:55.794 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1c8[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.794 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1ca[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:55.897 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1cb[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.897 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1cc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.897 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1cd[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.897 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1ce[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:55.898 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1cf[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.898 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1d0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.898 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1d1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.898 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1d2[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:55.933 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1d3[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.933 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1d4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.933 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1d5[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.933 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1d6[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:55.934 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1d7[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.934 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1d8[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.934 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1d9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:55.934 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1da[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:55.976 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1db[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.976 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1dc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.976 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1dd[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:55.976 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 1de[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:55.976 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 1df[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:33:55.977 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1e0[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.977 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1e1[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:55.977 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1e2[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:55.977 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 1e3[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:55.977 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 1e4[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:33:56.226 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1e5[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:56.226 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1e6[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:56.227 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1e7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:56.227 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1e8[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:56.275 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1e9[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.275 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1ea[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.275 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1eb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:56.275 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1ec[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:56.276 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1ed[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.276 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1ee[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.276 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1ef[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:56.276 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1f0[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:56.280 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1f1[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.280 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1f2[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.280 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1f3[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:56.280 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1f4[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:56.280 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1f5[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.280 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1f6[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.280 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1f7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:56.280 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1f8[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:56.341 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1f9[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.341 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1fa[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.342 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1fb[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:56.342 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 1fc[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:56.342 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 1fd[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:33:56.342 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1fe[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.342 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 1ff[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.342 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 200[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:56.342 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 201[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:56.342 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 202[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:33:56.592 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 203[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:56.592 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 204[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:56.592 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 205[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:56.592 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 206[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:56.656 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 208[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.656 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 209[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.656 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 20a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:56.656 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 20b[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:56.656 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 207[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.657 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 20c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.657 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 20d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:56.657 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 20e[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:56.690 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 20f[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.691 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 210[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.691 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 211[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:56.691 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 212[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:56.691 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 213[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.692 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 214[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.692 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 215[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:56.692 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 216[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:56.726 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 217[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.726 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 218[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.726 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 219[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:56.726 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 21a[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:56.726 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 21b[0m Closing Client
[36m2019-01-29 10:33:56.726 UTC [orderer/consensus/kafka] try -> DEBU 21c[0m [channel: testchainid] Initial attempt failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:33:56.727 UTC [orderer/consensus/kafka] try -> DEBU 21d[0m [channel: testchainid] Retrying every 1s for a total of 30s
[36m2019-01-29 10:33:56.727 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 21e[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.727 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 21f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:56.727 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 220[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:56.727 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 221[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:56.727 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 222[0m Closing Client
[36m2019-01-29 10:33:56.727 UTC [orderer/consensus/kafka] try -> DEBU 223[0m [channel: comunitychannel] Initial attempt failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:33:56.727 UTC [orderer/consensus/kafka] try -> DEBU 224[0m [channel: comunitychannel] Retrying every 1s for a total of 30s
[36m2019-01-29 10:33:57.727 UTC [orderer/consensus/kafka] try -> DEBU 225[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:33:57.727 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 227[0m Initializing new client
[36m2019-01-29 10:33:57.727 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 228[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:57.727 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 229[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:57.727 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 22a[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:57.727 UTC [orderer/consensus/kafka] try -> DEBU 226[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:33:57.727 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 22b[0m Initializing new client
[36m2019-01-29 10:33:57.727 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 22c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:57.728 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 22d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:57.728 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 22e[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:57.766 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 22f[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:57.766 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 230[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:57.766 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 231[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:57.766 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 232[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:57.767 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 233[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:57.767 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 234[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:57.767 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 235[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:57.767 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 236[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:57.768 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 237[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:57.768 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 238[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:57.768 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 239[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:57.768 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 23a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:57.789 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 23b[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:57.790 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 23c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:57.790 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 23d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:57.790 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 23e[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:57.791 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 23f[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:57.791 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 240[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:57.791 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 241[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:57.792 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 242[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:57.792 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 243[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:33:57.815 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 244[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:57.815 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 245[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:57.815 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 246[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:57.815 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 247[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:57.815 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 248[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:33:58.042 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 249[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:58.042 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 24a[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:58.066 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 24b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:58.066 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 24c[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:58.090 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 24d[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:58.090 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 24e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:58.091 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 24f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:58.091 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 250[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:58.112 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 251[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:58.112 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 252[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:58.112 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 253[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:58.112 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 254[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:58.775 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 255[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:58.776 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 256[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:58.776 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 257[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:58.776 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 258[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:58.776 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 259[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:33:58.776 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 25a[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:58.776 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 25b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:58.776 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 25c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:58.776 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 25d[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:58.809 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 25e[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:58.809 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 25f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:58.809 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 260[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:58.809 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 261[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:58.813 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 262[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:58.813 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 263[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:58.813 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 264[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:58.813 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 265[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:58.813 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 266[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:33:59.026 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 267[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.026 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 268[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:59.063 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 269[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.063 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 26a[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:59.103 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 26b[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.103 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 26c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.103 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 26d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.103 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 26e[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:59.108 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 26f[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.108 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 270[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.108 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 271[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.109 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 272[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:59.137 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 273[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.138 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 274[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.138 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 275[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.138 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 277[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:59.138 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 276[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.139 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 278[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.139 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 279[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.139 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 27a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:59.173 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 27b[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.173 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 27c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.173 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 27d[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:59.174 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 27e[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:59.174 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 27f[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:33:59.174 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 280[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.174 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 281[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.174 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 282[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:59.174 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 283[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:59.174 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 284[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:33:59.424 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 285[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.424 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 286[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:59.425 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 287[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.425 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 288[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:59.467 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 289[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.467 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 28a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.468 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 28b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.468 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 28c[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:59.470 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 28d[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.471 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 28e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.471 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 28f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.471 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 290[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:59.502 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 291[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.503 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 292[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.503 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 293[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.503 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 294[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:59.506 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 295[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.507 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 296[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.507 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 297[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.508 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 298[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:59.543 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 299[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.545 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 29b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.547 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 29c[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:59.547 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 29d[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:59.547 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 29e[0m Closing Client
[36m2019-01-29 10:33:59.547 UTC [orderer/consensus/kafka] try -> DEBU 29f[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:33:59.547 UTC [orderer/consensus/kafka] try -> DEBU 2a0[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:33:59.547 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 2a1[0m Initializing new client
[36m2019-01-29 10:33:59.547 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 2a2[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.548 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2a3[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.548 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2a4[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:59.545 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 29a[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.549 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2a5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.549 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2a6[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:59.549 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2a7[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:59.549 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 2a8[0m Closing Client
[36m2019-01-29 10:33:59.549 UTC [orderer/consensus/kafka] try -> DEBU 2a9[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:33:59.549 UTC [orderer/consensus/kafka] try -> DEBU 2aa[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:33:59.549 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 2ab[0m Initializing new client
[36m2019-01-29 10:33:59.549 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 2ac[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.549 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2ad[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.549 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2ae[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:59.577 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2af[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.577 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2b0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.577 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2b1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.577 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2b2[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:59.578 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2b3[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.578 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2b4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.578 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2b5[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.578 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2b6[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:59.611 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2b7[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.611 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2b8[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.611 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2b9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.611 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2ba[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:59.612 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2bb[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.612 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2bc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.613 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2bd[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.613 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2be[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:59.643 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2bf[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.643 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2c0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.643 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2c1[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:59.644 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2c2[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:59.644 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2c3[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:33:59.644 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2c4[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.644 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2c5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.644 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2c6[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:59.644 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2c7[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:59.644 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2c8[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:33:59.894 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2c9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.894 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2ca[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:59.894 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2cb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.894 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2cc[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:33:59.928 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2cd[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.929 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2ce[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.929 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2cf[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.929 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2d0[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:59.930 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2d1[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.930 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2d2[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.930 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2d3[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.931 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2d4[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:33:59.965 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2d5[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.965 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2d6[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.965 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2d7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.965 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2d8[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:59.968 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2d9[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.968 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2da[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.968 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2db[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:33:59.968 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2dc[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:33:59.997 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2dd[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.997 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2df[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.997 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2e0[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:59.997 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2e1[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:59.997 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2e2[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:33:59.997 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2de[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.997 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2e3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:33:59.997 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2e4[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:33:59.997 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2e5[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:33:59.997 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2e6[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:00.247 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2e7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.247 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2e8[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:00.248 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2e9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.248 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2ea[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:00.289 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2eb[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.290 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2ec[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.290 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2ed[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.290 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2ee[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.290 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2ef[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.290 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2f0[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:00.290 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2f1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.290 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2f2[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:00.311 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2f3[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.311 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2f5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.312 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2f6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.311 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2f4[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.312 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2f7[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:00.312 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2f8[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.312 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2f9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.312 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2fa[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:00.347 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2fb[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.347 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2fc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.347 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2fd[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:00.347 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2fe[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:00.347 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2ff[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:00.347 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 300[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.347 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 301[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.347 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 302[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:00.347 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 303[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:00.347 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 304[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:00.597 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 305[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.597 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 306[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:00.597 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 307[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.597 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 308[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:00.635 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 309[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.635 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 30a[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.635 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 30c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.635 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 30d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.635 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 30e[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:00.635 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 30b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.638 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 30f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.640 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 310[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:00.671 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 311[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.672 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 313[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.672 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 314[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.672 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 312[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.672 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 315[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:00.672 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 316[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.673 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 317[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.673 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 318[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:00.702 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 319[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.702 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 31a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.702 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 31b[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:00.702 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 31c[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:00.702 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 31d[0m Closing Client
[36m2019-01-29 10:34:00.702 UTC [orderer/consensus/kafka] try -> DEBU 31e[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:00.702 UTC [orderer/consensus/kafka] try -> DEBU 31f[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:00.702 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 320[0m Initializing new client
[36m2019-01-29 10:34:00.702 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 321[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.702 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 322[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.702 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 323[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:00.703 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 324[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.703 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 325[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.703 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 326[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:00.703 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 327[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:00.703 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 328[0m Closing Client
[36m2019-01-29 10:34:00.703 UTC [orderer/consensus/kafka] try -> DEBU 329[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:00.703 UTC [orderer/consensus/kafka] try -> DEBU 32a[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:00.704 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 32b[0m Initializing new client
[36m2019-01-29 10:34:00.704 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 32c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.704 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 32d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.704 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 32e[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:00.735 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 32f[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.735 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 330[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.736 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 331[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.736 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 332[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:00.736 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 333[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.739 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 334[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.739 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 335[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.739 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 336[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:00.771 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 337[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.771 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 338[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.771 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 339[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.771 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 33a[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:00.772 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 33b[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.772 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 33c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.772 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 33d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:00.772 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 33e[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:00.806 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 33f[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.806 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 340[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.806 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 341[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:00.806 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 342[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:00.806 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 343[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:00.807 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 344[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.807 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 345[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:00.807 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 346[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:00.807 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 347[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:00.807 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 348[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:01.056 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 349[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.056 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 34a[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:01.057 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 34b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.057 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 34c[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:01.079 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 34d[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.079 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 34e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.079 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 34f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.079 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 350[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:01.082 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 351[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.082 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 352[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.082 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 353[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.083 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 354[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:01.083 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 355[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.083 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 356[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.083 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 357[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.083 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 358[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:01.110 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 359[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.110 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 35b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.110 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 35c[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:01.111 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 35d[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:01.111 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 35e[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:01.110 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 35a[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.111 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 35f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.111 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 360[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.111 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 361[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:01.143 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 362[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.143 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 363[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.143 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 364[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:01.143 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 365[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:01.143 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 366[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:01.361 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 367[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.361 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 368[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:01.393 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 369[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.393 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 36a[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:01.411 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 36b[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.411 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 36c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.412 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 36d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.413 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 36e[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:01.424 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 36f[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.424 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 370[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.424 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 371[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.424 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 372[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:01.424 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 373[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.425 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 374[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.425 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 375[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.425 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 376[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:01.428 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 377[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.428 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 378[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.428 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 379[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.428 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 37a[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:01.429 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 37b[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.429 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 37c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.429 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 37d[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:01.429 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 37e[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:01.429 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 37f[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:01.459 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 380[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.459 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 381[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.460 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 382[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:01.460 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 383[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:01.460 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 384[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:01.679 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 385[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.679 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 386[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:01.711 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 387[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.711 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 388[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:01.717 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 389[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.717 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 38a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.717 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 38b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.717 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 38c[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:01.729 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 38d[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.729 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 38e[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.729 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 38f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.729 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 390[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.729 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 391[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.729 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 392[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.729 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 393[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:01.729 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 394[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:01.746 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 395[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 396[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 397[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 398[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 399[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 39a[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 39b[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 39c[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 39d[0m Closing Client
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka] try -> DEBU 39e[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka] try -> DEBU 39f[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 3a0[0m Initializing new client
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 3a1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3a2[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.747 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3a3[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:01.780 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3a4[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.780 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3a6[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.780 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3a7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.781 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3a8[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:01.780 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3a5[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.781 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3a9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.781 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3aa[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:01.781 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 3ab[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:01.781 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 3ac[0m Closing Client
[36m2019-01-29 10:34:01.781 UTC [orderer/consensus/kafka] try -> DEBU 3ad[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:01.782 UTC [orderer/consensus/kafka] try -> DEBU 3ae[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:01.782 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 3af[0m Initializing new client
[36m2019-01-29 10:34:01.782 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 3b0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.782 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3b1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.782 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3b2[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:01.812 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3b3[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.812 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3b4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.812 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3b5[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.813 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3b6[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:01.813 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3b7[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.813 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3b8[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.813 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3b9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.813 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3ba[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.813 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3bb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.813 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3bc[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:01.813 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3be[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:01.813 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3bd[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:01.845 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3bf[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.846 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3c0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.846 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3c1[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:01.847 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 3c2[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:01.847 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 3c3[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:01.848 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3c4[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.848 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3c5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:01.849 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 3c6[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:01.849 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 3c7[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:01.850 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 3c8[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:02.097 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3c9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:02.097 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3ca[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:02.100 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3cb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:02.100 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3cc[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:02.117 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3cd[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.117 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3ce[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.117 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3cf[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:02.117 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3d0[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:02.131 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3d1[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.131 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3d2[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.131 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3d3[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:02.131 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3d4[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:02.145 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3d6[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.146 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3d7[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.146 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3d8[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:02.146 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3d9[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:02.145 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3d5[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.146 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3da[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.146 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3db[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:02.146 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3dc[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:02.167 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3dd[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.167 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3de[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.167 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3df[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:02.167 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 3e0[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:02.167 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 3e1[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:02.179 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3e2[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.179 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3e3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.179 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3e4[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:02.179 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 3e5[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:02.179 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 3e6[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:02.417 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3e7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:02.417 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3e8[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:02.430 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3e9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:02.430 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3ea[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:02.476 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3eb[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.476 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3ec[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.476 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3ed[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:02.476 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3ee[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:02.511 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3ef[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.512 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3f0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:02.512 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3f1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:02.512 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3f2[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:03.273 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3f4[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.273 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3f5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.273 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3f6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.273 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3f7[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:03.273 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3f3[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.274 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3f8[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.274 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3f9[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:03.274 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 3fa[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:03.274 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 3fb[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:03.308 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 3fc[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.308 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3fd[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.308 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 3fe[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.308 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 3ff[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:03.346 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 400[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.346 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 401[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.346 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 402[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:03.346 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 403[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:03.346 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 404[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:03.524 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 405[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.526 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 406[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:03.565 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 407[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.565 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 408[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.565 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 409[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.567 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 40a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:03.597 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 40b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.597 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 40c[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:03.601 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 40d[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.601 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 40e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.601 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 40f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.601 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 410[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:03.602 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 411[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.602 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 412[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.602 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 413[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.602 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 414[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:03.602 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 415[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.602 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 416[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.602 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 417[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.603 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 418[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:03.634 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 419[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.634 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 41a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.634 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 41b[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:03.634 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 41c[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:03.634 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 41d[0m Closing Client
[36m2019-01-29 10:34:03.634 UTC [orderer/consensus/kafka] try -> DEBU 41e[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:03.634 UTC [orderer/consensus/kafka] try -> DEBU 41f[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:03.634 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 420[0m Initializing new client
[36m2019-01-29 10:34:03.634 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 421[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.635 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 422[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.635 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 423[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:03.636 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 424[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.636 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 425[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.636 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 426[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:03.636 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 427[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:03.636 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 428[0m Closing Client
[36m2019-01-29 10:34:03.636 UTC [orderer/consensus/kafka] try -> DEBU 429[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:03.636 UTC [orderer/consensus/kafka] try -> DEBU 42a[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:03.636 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 42b[0m Initializing new client
[36m2019-01-29 10:34:03.636 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 42c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.636 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 42d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.636 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 42e[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:03.675 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 42f[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.675 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 430[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.676 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 431[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.676 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 432[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:03.676 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 433[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.676 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 434[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.677 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 435[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.677 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 436[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.677 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 437[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.677 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 438[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.677 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 439[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:03.677 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 43a[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:03.707 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 43b[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.707 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 43c[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.708 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 43d[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.708 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 43e[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:03.708 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 43f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.708 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 440[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:03.708 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 441[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.708 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 443[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:03.708 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 442[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:03.744 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 444[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.744 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 445[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.744 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 446[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:03.745 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 447[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:03.745 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 448[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:03.958 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 449[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.958 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 44a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:03.982 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 44b[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.982 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 44c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:03.983 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 44d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.983 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 44e[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:03.995 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 44f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:03.995 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 450[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:04.013 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 451[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.013 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 452[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.013 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 453[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.013 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 454[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:04.013 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 455[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.013 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 456[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.013 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 457[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.014 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 458[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:04.050 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 459[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.051 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 45b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.051 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 45c[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:04.051 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 45d[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:04.051 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 45e[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:04.050 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 45a[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.051 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 45f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.051 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 460[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.052 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 461[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:04.076 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 462[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.077 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 463[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.077 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 464[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:04.077 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 465[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:04.077 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 466[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:04.301 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 467[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.301 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 468[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:04.327 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 469[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.327 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 46a[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:04.349 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 46b[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.349 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 46c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.350 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 46d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.350 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 46e[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:04.364 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 46f[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.364 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 470[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.365 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 471[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.365 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 472[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.366 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 474[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.366 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 475[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:04.365 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 473[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.367 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 476[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:04.413 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 477[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.413 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 478[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.413 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 479[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:04.413 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 47a[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:04.414 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 47c[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:04.414 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 47b[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.414 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 47d[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.414 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 47e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.415 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 47f[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:04.462 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 480[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.462 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 481[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.463 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 482[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:04.463 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 483[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:04.463 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 484[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:04.664 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 485[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.664 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 486[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:04.700 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 487[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.701 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 488[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.701 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 489[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.701 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 48a[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:04.714 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 48b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.714 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 48c[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:04.739 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 48d[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.739 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 48e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.739 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 48f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.739 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 490[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:04.739 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 491[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.739 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 492[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.740 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 493[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.740 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 494[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:04.750 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 495[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.750 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 496[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.750 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 497[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:04.750 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 498[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:04.750 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 499[0m Closing Client
[36m2019-01-29 10:34:04.750 UTC [orderer/consensus/kafka] try -> DEBU 49a[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:04.751 UTC [orderer/consensus/kafka] try -> DEBU 49b[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:04.751 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 49c[0m Initializing new client
[36m2019-01-29 10:34:04.751 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 49d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.751 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 49e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.751 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 49f[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:04.751 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4a0[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.751 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4a1[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.751 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4a2[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.751 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4a3[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:04.789 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4a4[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.789 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4a5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.790 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4a6[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:04.790 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 4a7[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:04.790 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 4a8[0m Closing Client
[36m2019-01-29 10:34:04.790 UTC [orderer/consensus/kafka] try -> DEBU 4a9[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:04.790 UTC [orderer/consensus/kafka] try -> DEBU 4aa[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:04.790 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 4ab[0m Initializing new client
[36m2019-01-29 10:34:04.790 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 4ac[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.790 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4ad[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.790 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 4ae[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:04.791 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4af[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.791 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 4b0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.791 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4b1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.791 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 4b2[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:04.819 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4b3[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.819 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 4b4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.819 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4b5[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.819 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 4b6[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:04.822 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4b7[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.822 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4b8[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.822 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 4b9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.822 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 4ba[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.822 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4bb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.822 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 4bd[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:04.822 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 4bc[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:04.822 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 4be[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:04.822 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 4bf[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:04.848 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4c0[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.848 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 4c1[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.848 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4c2[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:04.848 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 4c3[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:04.873 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4c4[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.873 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 4c5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:04.873 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 4c6[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:04.873 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 4c7[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:04.874 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 4c8[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:05.072 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4c9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:05.072 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4ca[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:05.124 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4cb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:05.124 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4cc[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:05.159 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4cd[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.159 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4ce[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.159 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4cf[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:05.159 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4d0[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:05.166 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4d1[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.166 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4d2[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.166 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4d3[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:05.166 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4d4[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:05.206 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4d5[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.206 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4d6[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.206 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4d7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:05.206 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4d8[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:05.207 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4d9[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.207 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4da[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.208 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4db[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:05.208 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4dc[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:05.514 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4dd[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.514 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4de[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.514 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4df[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:05.515 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 4e0[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:05.515 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 4e1[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:05.518 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4e2[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.519 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4e3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.519 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4e4[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:05.519 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 4e5[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:05.519 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 4e6[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:05.765 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4e7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:05.765 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4e8[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:05.769 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4e9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:05.769 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4ea[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:05.875 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4eb[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.875 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4ec[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.875 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4ed[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:05.875 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4ee[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:05.878 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4ef[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.878 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4f0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.878 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4f1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:05.878 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4f2[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:05.914 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4f3[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.914 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4f4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.915 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4f5[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:05.915 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4f6[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:05.917 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4f7[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.917 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4f8[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:05.917 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 4f9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:05.917 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4fa[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:06.235 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 4fb[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:06.236 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4fc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:06.236 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 4fd[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:06.236 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 4fe[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:06.236 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 4ff[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:06.486 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 500[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:06.487 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 501[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:06.585 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 502[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:06.585 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 503[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:06.585 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 504[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:06.585 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 505[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:06.953 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 506[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:06.955 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 508[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:06.955 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 507[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:06.955 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 509[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:06.956 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 50a[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:06.956 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 50b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:06.956 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 50c[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:06.956 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 50d[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:06.956 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 50e[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:06.986 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 50f[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:06.986 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 510[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:06.986 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 511[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:06.986 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 512[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:06.986 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 513[0m Closing Client
[36m2019-01-29 10:34:06.986 UTC [orderer/consensus/kafka] try -> DEBU 514[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:06.986 UTC [orderer/consensus/kafka] try -> DEBU 515[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:06.986 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 516[0m Initializing new client
[36m2019-01-29 10:34:06.987 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 517[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:06.987 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 518[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:06.987 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 519[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:07.018 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 51a[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.018 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 51b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.018 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 51c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.018 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 51d[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:07.050 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 51e[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.050 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 51f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.050 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 520[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.050 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 521[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:07.207 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 522[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.207 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 523[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:07.288 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 524[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.288 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 525[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.288 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 526[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:07.288 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 527[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:07.288 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 528[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:07.325 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 529[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.325 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 52a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.325 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 52b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.326 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 52c[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:07.360 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 52d[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.360 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 52e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.360 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 52f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.360 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 530[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:07.538 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 531[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.538 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 532[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:07.677 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 533[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.677 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 534[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.677 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 535[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:07.677 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 536[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:07.677 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 537[0m Closing Client
[36m2019-01-29 10:34:07.677 UTC [orderer/consensus/kafka] try -> DEBU 538[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:07.677 UTC [orderer/consensus/kafka] try -> DEBU 539[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:07.677 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 53a[0m Initializing new client
[36m2019-01-29 10:34:07.677 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 53b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.677 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 53c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.677 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 53d[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:07.678 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 53e[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.678 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 53f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.678 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 540[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.678 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 541[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:07.678 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 542[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.678 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 543[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.678 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 544[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.678 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 545[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:07.709 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 546[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.709 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 547[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.709 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 548[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.709 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 549[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:07.710 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 54a[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.710 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 54b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.710 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 54c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.710 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 54d[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:07.738 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 54e[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.738 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 54f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.738 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 550[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:07.738 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 551[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:07.738 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 552[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:07.738 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 553[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.739 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 554[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:07.739 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 555[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:07.739 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 556[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:07.739 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 557[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:07.988 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 558[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.988 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 559[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:07.990 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 55a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:07.990 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 55b[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:08.053 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 55c[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.053 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 55d[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.053 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 55e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.053 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 55f[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:08.053 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 560[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.053 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 561[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.053 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 562[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.053 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 563[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:08.088 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 564[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.088 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 565[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.088 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 566[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.088 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 567[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:08.088 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 568[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.089 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 569[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.089 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 56a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.089 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 56b[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:08.122 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 56c[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.123 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 56d[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.123 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 56e[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:08.123 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 56f[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.123 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 570[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:08.123 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 571[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.123 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 573[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:08.123 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 574[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:08.123 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 575[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:08.123 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 572[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:08.373 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 576[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.373 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 578[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:08.373 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 577[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.373 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 579[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:08.433 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 57a[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.433 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 57b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.433 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 57c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.434 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 57d[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:08.434 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 57e[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.434 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 57f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.434 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 580[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.434 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 581[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:08.479 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 582[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.479 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 583[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.479 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 584[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.479 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 585[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.479 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 586[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.479 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 587[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.479 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 588[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:08.479 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 589[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 58a[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 58c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 58d[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 58e[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 58b[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 58f[0m Closing Client
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka] try -> DEBU 590[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka] try -> DEBU 592[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 591[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 593[0m Initializing new client
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 595[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 594[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 596[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 597[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 598[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:08.508 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 599[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:08.758 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 59a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.759 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 59b[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:08.816 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 59c[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.816 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 59d[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.816 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 59e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.816 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 59f[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:08.850 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5a0[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.851 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 5a1[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.851 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5a2[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.851 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 5a3[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:08.851 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5a4[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.851 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5a5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.851 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5a6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.851 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5a7[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:08.883 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5a8[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.883 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5a9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.883 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5aa[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.883 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5ab[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:08.883 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5ac[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.883 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 5ad[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.883 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 5ae[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:08.883 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 5af[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:08.883 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 5b0[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:08.915 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5b1[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.915 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5b2[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.915 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5b3[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:08.915 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 5b4[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:08.915 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 5b5[0m Closing Client
[36m2019-01-29 10:34:08.915 UTC [orderer/consensus/kafka] try -> DEBU 5b6[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:08.915 UTC [orderer/consensus/kafka] try -> DEBU 5b7[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:08.915 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 5b8[0m Initializing new client
[36m2019-01-29 10:34:08.915 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 5b9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.915 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5ba[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.915 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 5bb[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:08.947 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5bc[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.947 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 5bd[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.947 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5be[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.947 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 5bf[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:08.977 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5c0[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.978 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 5c1[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:08.978 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5c2[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:08.978 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 5c3[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:09.010 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5c4[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.010 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 5c5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.010 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 5c6[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:09.010 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 5c7[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:09.010 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 5c8[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:09.134 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5c9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.134 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5ca[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:09.176 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5cb[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.176 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5cc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.176 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5cd[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.176 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5ce[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:09.206 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5cf[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.206 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5d0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.206 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5d1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.206 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5d2[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:09.227 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5d3[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.227 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5d4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.227 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5d5[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:09.227 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 5d6[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:09.227 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 5d7[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:09.260 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5d8[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.260 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5d9[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:09.291 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5da[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.291 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5db[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.291 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5dc[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.291 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5dd[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:09.325 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5de[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.325 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5df[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.325 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5e0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.325 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5e1[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:09.360 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5e2[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.360 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5e3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.360 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5e4[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:09.360 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 5e5[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:09.360 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 5e6[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:09.478 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5e7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.478 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5e8[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:09.551 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5e9[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.551 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5ea[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.551 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5eb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.551 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5ec[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:09.583 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5ed[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.583 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5ee[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.584 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5ef[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.584 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5f0[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:09.610 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5f1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.611 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5f2[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:09.621 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5f3[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.621 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5f4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.621 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5f5[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:09.621 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 5f6[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:09.621 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 5f7[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:09.622 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5f8[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.622 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5f9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.622 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5fa[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.623 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5fb[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:09.655 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5fc[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.656 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5fd[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.656 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5fe[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.656 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 5ff[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:09.688 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 600[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.688 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 601[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.688 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 602[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:09.688 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 603[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:09.688 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 604[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:09.873 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 605[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.873 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 606[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:09.925 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 607[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.925 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 608[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.925 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 609[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.926 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 60a[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:09.938 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 60b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.938 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 60c[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:09.958 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 60d[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.958 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 60e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.958 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 60f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.958 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 610[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:09.959 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 611[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.959 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 612[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.959 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 613[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.959 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 614[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:09.984 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 615[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.984 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 616[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.984 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 617[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:09.984 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 618[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:09.984 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 619[0m Closing Client
[36m2019-01-29 10:34:09.984 UTC [orderer/consensus/kafka] try -> DEBU 61a[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:09.984 UTC [orderer/consensus/kafka] try -> DEBU 61b[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:09.984 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 61c[0m Initializing new client
[36m2019-01-29 10:34:09.984 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 61d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.984 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 61e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.985 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 61f[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:09.985 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 620[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.985 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 621[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:09.985 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 622[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:09.985 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 623[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:10.019 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 624[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.020 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 625[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.020 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 626[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:10.020 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 627[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:10.020 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 628[0m Closing Client
[36m2019-01-29 10:34:10.020 UTC [orderer/consensus/kafka] try -> DEBU 629[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:10.020 UTC [orderer/consensus/kafka] try -> DEBU 62a[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:10.020 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 62b[0m Initializing new client
[36m2019-01-29 10:34:10.020 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 62c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:10.020 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 62d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:10.020 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 62e[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:10.021 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 62f[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.022 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 631[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.022 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 632[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:10.022 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 633[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:10.021 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 630[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.023 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 634[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.023 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 635[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:10.023 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 636[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:10.055 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 637[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.056 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 638[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.056 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 639[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:10.056 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 63a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:10.056 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 63b[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.056 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 63c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.057 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 63d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:10.057 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 63e[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:10.096 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 63f[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.096 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 640[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.096 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 642[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:10.096 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 641[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.096 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 644[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.096 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 643[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:10.096 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 645[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:10.096 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 647[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:10.096 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 648[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:10.096 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 646[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:10.347 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 649[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:10.347 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 64b[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:10.347 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 64a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:10.347 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 64c[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:10.383 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 64d[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.383 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 64e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.383 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 64f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:10.383 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 650[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:10.384 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 651[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.384 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 652[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.384 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 653[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:10.385 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 654[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:10.428 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 655[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.428 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 656[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.428 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 657[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.429 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 659[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:10.428 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 658[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:10.429 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 65a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:10.429 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 65b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:10.429 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 65c[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:11.263 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 65d[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.263 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 65e[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.263 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 65f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.264 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 660[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.264 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 661[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:11.264 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 662[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:11.265 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 663[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:11.265 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 664[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:11.265 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 665[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:11.265 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 666[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:11.515 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 667[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.515 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 668[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.515 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 669[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:11.515 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 66a[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:11.556 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 66b[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.556 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 66c[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.556 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 66d[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.556 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 66f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.556 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 670[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:11.556 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 66e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.556 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 671[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.556 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 672[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:11.582 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 673[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.582 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 675[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.582 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 676[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.582 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 674[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.582 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 677[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:11.582 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 678[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.582 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 679[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.582 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 67a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:11.613 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 67b[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.613 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 67c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.613 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 67d[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:11.613 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 67e[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:11.613 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 67f[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:11.613 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 680[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.613 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 681[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.613 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 682[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:11.614 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 683[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:11.614 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 684[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:11.863 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 685[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.863 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 686[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:11.864 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 687[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.865 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 688[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:11.892 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 689[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.893 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 68a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.893 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 68b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.893 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 68c[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:11.893 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 68d[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.893 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 68e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.893 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 68f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.893 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 690[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:11.925 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 691[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.926 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 692[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.926 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 693[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.926 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 694[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.926 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 695[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.926 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 696[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:11.926 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 697[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.926 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 698[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:11.964 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 69a[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.964 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 699[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.964 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 69c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.964 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 69d[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:11.964 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 69e[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:11.965 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 69f[0m Closing Client
[36m2019-01-29 10:34:11.965 UTC [orderer/consensus/kafka] try -> DEBU 6a0[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:11.965 UTC [orderer/consensus/kafka] try -> DEBU 6a1[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:11.965 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 6a2[0m Initializing new client
[36m2019-01-29 10:34:11.965 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 6a3[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.964 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 69b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.965 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6a5[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:11.965 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 6a6[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:11.965 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 6a7[0m Closing Client
[36m2019-01-29 10:34:11.965 UTC [orderer/consensus/kafka] try -> DEBU 6a8[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:11.965 UTC [orderer/consensus/kafka] try -> DEBU 6a9[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:11.966 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 6aa[0m Initializing new client
[36m2019-01-29 10:34:11.966 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 6ab[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.965 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6a4[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.966 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6ac[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.966 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6ad[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:11.966 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6ae[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:11.991 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6af[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.991 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6b0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:11.991 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6b1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:11.991 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6b2[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:12.773 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6b3[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:12.773 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6b4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:12.774 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6b5[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:12.774 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6b6[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:12.775 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6b7[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:12.776 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6b8[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:12.776 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6b9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:12.776 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6ba[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:12.809 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6bb[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:12.810 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6bc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:12.810 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6bd[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:12.810 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6be[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:12.814 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6bf[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:12.814 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6c0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:12.814 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6c1[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:12.814 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 6c2[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:12.814 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 6c3[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:12.841 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6c4[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:12.841 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6c5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:12.841 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 6c6[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:12.842 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 6c7[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:12.842 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 6c8[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:13.065 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6c9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:13.065 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6ca[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:13.073 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6cb[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:13.073 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6cc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:13.073 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6cd[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:13.073 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6ce[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:13.092 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6cf[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:13.092 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6d0[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:13.106 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6d1[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:13.106 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6d2[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:13.107 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6d3[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:13.107 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6d4[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:13.140 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6d5[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:13.140 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6d6[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:13.140 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6d7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:13.140 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6d8[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:13.764 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6d9[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:13.765 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6da[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:13.765 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6dc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:13.765 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6dd[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:13.765 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6db[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:13.766 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6df[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:13.766 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 6e0[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:13.767 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 6e1[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:13.765 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6de[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:13.799 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6e2[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:13.800 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6e3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:13.800 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6e4[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:13.801 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 6e5[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:13.801 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 6e6[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:14.017 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6e7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:14.017 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6e8[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:14.052 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6e9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:14.052 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6ea[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:16.791 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6eb[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:16.791 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6ec[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:16.791 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6ed[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:16.791 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6ee[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:16.791 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6ef[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:16.791 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6f1[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:16.792 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6f2[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:16.792 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6f3[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:16.791 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6f0[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:16.792 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6f4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:16.792 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6f5[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:16.793 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6f6[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:16.825 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6f7[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:16.825 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6f9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:16.825 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 6fa[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:16.826 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6fb[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:16.825 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 6f8[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:16.826 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6fc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:16.826 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 6fd[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:16.826 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 6fe[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:16.826 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 6ff[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:16.860 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 700[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:16.860 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 701[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:16.860 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 702[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:16.860 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 703[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:16.860 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 704[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:17.076 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 705[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.077 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 706[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:17.111 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 707[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.111 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 708[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:17.156 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 709[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.156 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 70a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.156 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 70b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.157 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 70c[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:17.157 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 70d[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.157 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 70e[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.158 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 70f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.158 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 711[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.158 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 712[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.159 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 713[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:17.158 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 710[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.159 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 714[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:17.199 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 715[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.199 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 716[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.199 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 718[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.199 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 719[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.199 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 71a[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:17.199 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 717[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.199 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 71b[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:17.199 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 71c[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:17.200 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 71d[0m Closing Client
[36m2019-01-29 10:34:17.200 UTC [orderer/consensus/kafka] try -> DEBU 71e[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:17.200 UTC [orderer/consensus/kafka] try -> DEBU 71f[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:17.200 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 720[0m Initializing new client
[36m2019-01-29 10:34:17.200 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 721[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.200 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 722[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.200 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 723[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:17.227 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 725[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.228 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 726[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.228 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 727[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:17.228 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 728[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:17.228 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 729[0m Closing Client
[36m2019-01-29 10:34:17.228 UTC [orderer/consensus/kafka] try -> DEBU 72a[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:17.228 UTC [orderer/consensus/kafka] try -> DEBU 72b[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:17.228 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 72c[0m Initializing new client
[36m2019-01-29 10:34:17.228 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 72d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.228 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 72e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.228 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 72f[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:17.227 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 724[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.229 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 730[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.229 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 731[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.229 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 732[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:17.263 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 733[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.263 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 734[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.263 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 735[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.264 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 736[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:17.264 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 737[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.264 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 739[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.264 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 738[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.264 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 73a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.264 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 73b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.264 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 73d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.264 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 73c[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:17.264 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 73e[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:17.298 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 73f[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.298 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 740[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.299 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 742[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:17.299 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 741[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.299 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 743[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:17.299 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 745[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:17.299 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 744[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.299 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 746[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:17.299 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 747[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:17.299 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 748[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:17.549 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 749[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.550 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 74a[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:17.550 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 74b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.550 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 74c[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:17.575 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 74d[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.575 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 74e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.575 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 74f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.575 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 750[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:17.577 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 751[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.577 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 752[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.577 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 753[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.578 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 754[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:17.608 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 755[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.608 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 756[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.608 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 757[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.608 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 758[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.608 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 759[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.608 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 75a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.608 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 75c[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:17.608 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 75b[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:17.638 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 75d[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.638 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 75e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.638 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 75f[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:17.638 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 760[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:17.638 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 761[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:17.642 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 762[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.642 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 763[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.642 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 764[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:17.642 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 765[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:17.642 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 766[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:17.888 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 767[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.888 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 768[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:17.892 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 769[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.892 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 76a[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:17.907 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 76b[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.908 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 76c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.908 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 76d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.908 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 76e[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:17.913 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 76f[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.914 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 770[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.914 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 771[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.914 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 772[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:17.936 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 773[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.937 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 774[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.937 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 775[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.937 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 776[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:17.937 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 777[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.937 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 778[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.937 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 779[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:17.937 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 77a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:17.965 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 77b[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.965 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 77c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.965 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 77d[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:17.965 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 77e[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:17.965 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 77f[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:17.966 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 780[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.966 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 781[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:17.966 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 782[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:17.966 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 783[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:17.966 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 784[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:18.215 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 785[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.215 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 786[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:18.217 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 787[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.217 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 788[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:18.228 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 789[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.228 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 78a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.228 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 78b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.228 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 78c[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:18.241 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 78d[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.241 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 78e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.241 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 78f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.241 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 790[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:18.255 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 792[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.255 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 793[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.255 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 794[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.256 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 795[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:18.255 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 791[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.256 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 796[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.256 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 797[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.256 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 798[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:18.287 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 799[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.287 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 79a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.287 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 79b[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:18.287 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 79c[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:18.287 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 79d[0m Closing Client
[36m2019-01-29 10:34:18.287 UTC [orderer/consensus/kafka] try -> DEBU 79e[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:18.287 UTC [orderer/consensus/kafka] try -> DEBU 79f[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:18.287 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 7a0[0m Initializing new client
[36m2019-01-29 10:34:18.288 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 7a1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.288 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7a2[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.288 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7a3[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:18.288 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7a4[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.288 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7a5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.288 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7a6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.288 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7a7[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:18.289 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7a8[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.289 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7a9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.289 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7aa[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:18.289 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 7ab[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:18.289 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 7ac[0m Closing Client
[36m2019-01-29 10:34:18.289 UTC [orderer/consensus/kafka] try -> DEBU 7ad[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:18.289 UTC [orderer/consensus/kafka] try -> DEBU 7ae[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:18.289 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 7af[0m Initializing new client
[36m2019-01-29 10:34:18.289 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 7b0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.289 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7b1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.289 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7b2[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:18.320 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7b3[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.320 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7b4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.320 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7b5[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.321 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7b6[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:18.322 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7b7[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.322 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7b9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.322 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7ba[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:18.322 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 7bb[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:18.322 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 7bc[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:18.322 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7b8[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.322 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7bd[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.322 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7be[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.322 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7bf[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:18.355 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7c0[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.355 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7c1[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.355 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7c2[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.355 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7c3[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:18.386 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7c4[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.386 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7c5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.386 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 7c6[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:18.386 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 7c7[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:18.386 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 7c8[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:18.572 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7c9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.572 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7ca[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:18.596 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7cb[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.596 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7cc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.596 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7cd[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.596 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7ce[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:18.624 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7cf[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.624 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7d0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.624 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7d1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.624 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7d2[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:18.629 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7d3[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.629 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7d4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.630 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7d5[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:18.630 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 7d6[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:18.630 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 7d7[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:18.636 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7d8[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.636 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7d9[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:18.665 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7da[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.666 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7db[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.666 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7dc[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.666 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7dd[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:18.690 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7de[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.690 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7df[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.690 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7e0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.690 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7e1[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:18.705 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7e2[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.706 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7e3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.706 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7e4[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:18.706 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 7e5[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:18.706 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 7e6[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:18.880 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7e7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.881 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7e8[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:18.956 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7e9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.956 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7ea[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:18.970 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7eb[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.970 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7ec[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.970 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7ed[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.970 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7ee[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:18.974 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7ef[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.974 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7f0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.975 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7f1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.975 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7f2[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:18.983 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7f3[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.983 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7f4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.983 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7f5[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:18.983 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 7f6[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:18.983 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 7f7[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:18.983 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7f8[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.983 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7f9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:18.983 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7fa[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:18.983 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7fb[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:19.013 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 7fc[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.013 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7fd[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.013 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 7fe[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.013 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 7ff[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:19.041 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 800[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.041 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 801[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.042 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 802[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:19.042 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 803[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:19.042 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 804[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:19.233 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 805[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.234 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 806[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:19.293 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 807[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.293 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 808[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:19.299 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 809[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.299 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 80a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.299 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 80b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.299 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 80c[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:19.320 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 80d[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.321 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 80e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.321 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 80f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.321 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 810[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:19.325 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 811[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.325 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 812[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.325 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 813[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.325 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 814[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.325 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 815[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.325 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 817[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.326 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 818[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:19.325 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 816[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:19.355 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 819[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.356 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 81a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.356 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 81b[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:19.356 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 81c[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:19.356 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 81d[0m Closing Client
[36m2019-01-29 10:34:19.356 UTC [orderer/consensus/kafka] try -> DEBU 81e[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:19.356 UTC [orderer/consensus/kafka] try -> DEBU 81f[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:19.356 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 820[0m Initializing new client
[36m2019-01-29 10:34:19.357 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 821[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.357 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 822[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.357 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 823[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:19.357 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 824[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.357 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 825[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.357 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 826[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:19.357 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 827[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:19.357 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 828[0m Closing Client
[36m2019-01-29 10:34:19.357 UTC [orderer/consensus/kafka] try -> DEBU 829[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:19.357 UTC [orderer/consensus/kafka] try -> DEBU 82a[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:19.358 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 82b[0m Initializing new client
[36m2019-01-29 10:34:19.358 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 82c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.358 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 82d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.358 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 82e[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:19.386 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 82f[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.386 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 830[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.386 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 831[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.386 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 832[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:19.387 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 833[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.387 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 834[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.387 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 835[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.387 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 836[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:19.387 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 837[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.387 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 838[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.387 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 839[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.387 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 83a[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:19.413 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 83b[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.413 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 83d[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.414 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 83e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.413 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 83c[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.414 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 83f[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:19.414 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 840[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.414 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 841[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:19.414 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 842[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:19.414 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 843[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:19.439 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 844[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.439 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 845[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.439 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 846[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:19.439 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 847[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:19.440 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 848[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:19.664 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 849[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.664 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 84a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:19.690 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 84b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.690 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 84c[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:19.694 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 84d[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.694 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 84e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.694 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 84f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.694 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 850[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:19.722 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 851[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.722 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 853[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.722 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 854[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.722 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 852[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.723 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 855[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:19.723 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 856[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.723 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 857[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.723 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 858[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:19.749 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 85a[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.750 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 85b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.750 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 85c[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:19.749 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 859[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.751 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 85d[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:19.751 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 85e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:19.751 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 860[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:19.751 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 85f[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:19.751 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 861[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:20.001 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 862[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:20.002 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 863[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:20.515 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 864[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.516 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 865[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.516 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 866[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:20.516 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 867[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:20.516 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 868[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.516 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 869[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.516 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 86a[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:20.516 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 86b[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:20.516 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 86c[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:20.549 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 86d[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.549 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 86e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.549 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 86f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:20.549 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 870[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:20.579 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 871[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.579 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 872[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.579 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 873[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:20.579 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 874[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:20.579 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 875[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:20.767 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 876[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:20.767 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 877[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:20.816 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 878[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.816 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 879[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.816 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 87a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:20.816 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 87b[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:20.830 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 87c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:20.830 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 87d[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:20.831 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 87e[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.831 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 87f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.831 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 880[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:20.831 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 881[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:20.866 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 882[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.868 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 883[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.868 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 884[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:20.868 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 885[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:20.869 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 886[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.869 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 887[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.869 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 888[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:20.869 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 889[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:20.869 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 88a[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:20.898 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 88b[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.898 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 88c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.899 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 88d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:20.899 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 88e[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:20.928 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 88f[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.928 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 890[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.928 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 891[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:20.928 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 892[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:20.928 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 893[0m Closing Client
[36m2019-01-29 10:34:20.929 UTC [orderer/consensus/kafka] try -> DEBU 894[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:20.929 UTC [orderer/consensus/kafka] try -> DEBU 895[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:20.929 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 896[0m Initializing new client
[36m2019-01-29 10:34:20.929 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 897[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:20.929 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 898[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:20.929 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 899[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:20.956 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 89a[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.956 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 89b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.956 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 89c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:20.956 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 89d[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:20.970 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 89e[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.970 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 89f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:20.970 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8a0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:20.971 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 8a1[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:21.001 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8a2[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.001 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 8a3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.001 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 8a4[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:21.001 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 8a5[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:21.001 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 8a6[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:21.119 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8a7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:21.119 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8a8[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:21.190 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8a9[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.190 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8aa[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.190 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8ab[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:21.190 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8ac[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:21.225 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8ad[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.226 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8ae[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.226 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8af[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:21.226 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8b0[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:21.252 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8b1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:21.252 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8b2[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:21.259 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8b3[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.259 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8b4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.259 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8b5[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:21.259 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 8b6[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:21.259 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 8b7[0m Closing Client
[36m2019-01-29 10:34:21.259 UTC [orderer/consensus/kafka] try -> DEBU 8b8[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:21.259 UTC [orderer/consensus/kafka] try -> DEBU 8b9[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:21.259 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 8ba[0m Initializing new client
[36m2019-01-29 10:34:21.260 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 8bb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:21.260 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8bc[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:21.260 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 8bd[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:21.291 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8be[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.292 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8bf[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.292 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8c0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:21.292 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8c1[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:21.292 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8c2[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.292 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8c3[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.292 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8c4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.293 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 8c5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:21.293 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8c6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:21.293 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8c7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:21.293 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8c8[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:21.293 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 8c9[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:22.062 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8cb[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.062 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8cc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.062 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8cd[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:22.062 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 8ce[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:22.062 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 8cf[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:22.062 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8ca[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.062 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 8d0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.062 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8d1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.063 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 8d2[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:22.089 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8d3[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.089 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 8d4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.089 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 8d5[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:22.090 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 8d6[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:22.090 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 8d7[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:22.312 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8d8[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.313 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8d9[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:22.341 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8da[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.341 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8db[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:22.364 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8dc[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.364 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8dd[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.364 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8de[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.365 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8df[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:22.365 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8e0[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.366 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8e1[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.366 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8e2[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.366 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8e3[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:22.366 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8e4[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.366 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8e5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.366 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8e6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.366 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8e7[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:22.393 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8e8[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.393 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8e9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.393 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8ea[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.393 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8eb[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:22.393 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8ec[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.394 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8ed[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.394 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8ee[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:22.394 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 8ef[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:22.394 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 8f0[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:22.422 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8f1[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.422 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8f2[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.422 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8f3[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:22.422 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 8f4[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:22.422 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 8f5[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:22.644 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8f6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.644 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8f7[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:22.672 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8f8[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.673 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8f9[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:22.716 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8fa[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.716 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8fb[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.716 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 8fc[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.716 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 8fd[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:22.718 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8fe[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.719 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 900[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.719 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 901[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.719 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 902[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:22.718 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 8ff[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.719 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 903[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.719 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 904[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.719 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 905[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:22.729 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 907[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.729 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 908[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.729 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 909[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:22.729 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 90a[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:22.729 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 90b[0m Closing Client
[36m2019-01-29 10:34:22.729 UTC [orderer/consensus/kafka] try -> DEBU 90c[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:22.729 UTC [orderer/consensus/kafka] try -> DEBU 90d[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:22.729 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 90e[0m Initializing new client
[36m2019-01-29 10:34:22.729 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 90f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.729 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 910[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.729 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 911[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:22.729 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 906[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.730 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 912[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.730 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 913[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.730 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 914[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:22.762 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 915[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.762 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 916[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.762 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 917[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.762 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 918[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.762 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 91a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.762 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 919[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:22.762 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 91b[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:22.762 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 91c[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:22.762 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 91d[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:22.793 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 91e[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.793 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 91f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.793 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 920[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:22.793 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 921[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:22.824 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 922[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.824 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 923[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:22.825 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 924[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:22.825 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 925[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:22.825 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 926[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:23.012 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 927[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.013 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 928[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:23.049 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 929[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.049 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 92a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.049 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 92b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.049 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 92c[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:23.075 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 92d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.075 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 92e[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:23.081 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 92f[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.081 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 930[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.081 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 931[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.081 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 932[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:23.112 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 933[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.112 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 934[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.112 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 935[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.112 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 936[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:23.117 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 937[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.117 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 938[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.117 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 939[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.117 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 93a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.117 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 93b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.117 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 93c[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:23.117 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 93d[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:23.117 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 93e[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:23.117 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 93f[0m Closing Client
[36m2019-01-29 10:34:23.117 UTC [orderer/consensus/kafka] try -> DEBU 940[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:23.117 UTC [orderer/consensus/kafka] try -> DEBU 941[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:23.117 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 942[0m Initializing new client
[36m2019-01-29 10:34:23.118 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 943[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.118 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 944[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.118 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 945[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:23.151 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 946[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.151 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 947[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.151 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 948[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.151 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 949[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:23.152 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 94a[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.152 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 94b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.152 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 94c[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:23.152 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 94d[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:23.152 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 94e[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:23.198 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 94f[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.198 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 950[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.198 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 951[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.198 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 952[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:23.225 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 953[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.225 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 954[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.225 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 955[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:23.225 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 956[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:23.225 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 957[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:23.402 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 958[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.402 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 959[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:23.415 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 95a[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.415 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 95b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.415 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 95c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.415 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 95d[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:23.426 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 95e[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.426 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 95f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.429 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 960[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.429 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 961[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:23.441 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 962[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.441 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 963[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.441 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 964[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:23.441 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 965[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:23.441 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 966[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:23.475 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 967[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.476 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 968[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:23.692 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 969[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.692 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 96a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:23.761 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 96b[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.761 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 96c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.761 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 96d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.761 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 96e[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:23.790 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 96f[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.790 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 970[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:23.790 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 971[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:23.790 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 972[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:24.275 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 973[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.276 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 975[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.276 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 974[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.277 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 977[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.277 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 978[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:24.277 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 976[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:24.278 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 97a[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:24.278 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 97b[0m Closing Client
[36m2019-01-29 10:34:24.278 UTC [orderer/consensus/kafka] try -> DEBU 97c[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:24.278 UTC [orderer/consensus/kafka] try -> DEBU 97d[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:24.278 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 97e[0m Initializing new client
[36m2019-01-29 10:34:24.278 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 97f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:24.278 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 980[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:24.278 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 981[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:24.278 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 979[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:24.308 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 982[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.308 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 983[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.308 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 984[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:24.308 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 985[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:24.309 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 986[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.309 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 987[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.309 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 988[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:24.309 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 989[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:24.309 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 98a[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:24.309 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 98b[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.309 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 98c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.309 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 98d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:24.309 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 98e[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:24.337 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 98f[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.338 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 990[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.338 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 991[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:24.338 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 992[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:24.370 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 993[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.371 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 994[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.371 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 995[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:24.371 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 996[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:24.371 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 997[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:24.559 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 998[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:24.560 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 999[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:24.599 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 99a[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.599 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 99b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.599 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 99c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:24.599 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 99d[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:24.622 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 99e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:24.622 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 99f[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:24.633 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9a0[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.634 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9a1[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.634 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9a2[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:24.634 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9a3[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:24.636 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9a4[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.636 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9a5[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.636 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9a6[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.636 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9a8[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:24.636 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 9a9[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:24.636 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 9aa[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:24.636 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9a7[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.636 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9ab[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:24.636 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9ac[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:24.669 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9ad[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.669 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9ae[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:24.669 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9af[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:24.669 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9b0[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:24.886 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9b1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:24.887 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9b2[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:25.525 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9b3[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.525 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9b4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.525 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9b6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:25.525 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9b7[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:25.525 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9b5[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.525 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9b8[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.525 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9b9[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:25.525 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 9ba[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:25.526 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 9bb[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:25.557 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9bc[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.557 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9bd[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.557 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9be[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:25.557 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9bf[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:25.588 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9c0[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.588 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9c1[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.588 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9c2[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:25.588 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 9c3[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:25.588 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 9c4[0m Closing Client
[36m2019-01-29 10:34:25.589 UTC [orderer/consensus/kafka] try -> DEBU 9c5[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:25.589 UTC [orderer/consensus/kafka] try -> DEBU 9c6[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:25.589 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 9c7[0m Initializing new client
[36m2019-01-29 10:34:25.589 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 9c8[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:25.589 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9c9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:25.589 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 9ca[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:25.627 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9cb[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.627 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 9cc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.627 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9cd[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:25.627 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 9ce[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:25.659 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9cf[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.659 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 9d0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.659 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9d1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:25.659 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 9d2[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:25.693 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9d3[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.693 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 9d4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.693 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 9d5[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:25.693 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 9d6[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:25.693 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 9d7[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:25.776 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9d8[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:25.776 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9d9[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:25.817 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9da[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.817 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9db[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.817 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9dc[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:25.817 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9dd[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:25.843 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9de[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.844 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9df[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.844 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9e0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:25.844 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9e1[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:25.877 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9e2[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.877 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9e3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.877 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9e4[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:25.877 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 9e5[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:25.877 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 9e6[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:25.943 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9e7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:25.944 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9e8[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:25.975 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9e9[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.976 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9ea[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:25.976 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9eb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:25.976 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9ec[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:26.004 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9ed[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.004 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9ee[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.004 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9ef[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.004 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9f0[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:26.036 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9f1[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.036 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9f2[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.036 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9f3[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:26.036 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 9f4[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:26.036 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 9f5[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:26.128 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9f6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.128 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9f7[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:26.158 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9f8[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.158 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9f9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.158 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9fa[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.158 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9fb[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:26.188 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 9fc[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.188 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9fd[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.188 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 9fe[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.188 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 9ff[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:26.219 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a00[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.219 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a01[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.219 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a02[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:26.219 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a03[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:26.219 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU a04[0m Closing Client
[36m2019-01-29 10:34:26.219 UTC [orderer/consensus/kafka] try -> DEBU a05[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:26.219 UTC [orderer/consensus/kafka] try -> DEBU a06[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:26.219 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU a07[0m Initializing new client
[36m2019-01-29 10:34:26.219 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU a08[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.219 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a09[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.219 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a0a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:26.252 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a0b[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.252 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a0c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.252 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a0d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.252 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a0e[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:26.280 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a0f[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.280 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a10[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.280 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a11[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.280 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a12[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:26.287 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a13[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.287 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a14[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:26.311 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a15[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.311 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a16[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.311 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a17[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:26.312 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a18[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:26.312 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a19[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:26.313 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a1a[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.313 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a1b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.313 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a1c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.313 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a1d[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:26.345 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a1e[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.345 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a1f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.345 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a20[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.345 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a21[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:26.379 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a22[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.379 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a23[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.379 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a24[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:26.379 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a25[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:26.379 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a26[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:26.562 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a27[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.562 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a28[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:26.584 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a29[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.584 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a2a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.584 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a2b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.585 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a2c[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:26.595 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a2d[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.595 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a2e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.595 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a2f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.596 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a30[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:26.625 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a31[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.625 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a32[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.625 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a33[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:26.625 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a34[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:26.625 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a35[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:26.630 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a36[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.630 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a37[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:26.658 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a38[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.658 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a39[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.658 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a3a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.658 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a3b[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:26.691 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a3c[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.691 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a3d[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.691 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a3e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.692 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a3f[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:26.722 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a40[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.722 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a41[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.722 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a42[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:26.722 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a43[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:26.722 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU a44[0m Closing Client
[36m2019-01-29 10:34:26.723 UTC [orderer/consensus/kafka] try -> DEBU a45[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:26.723 UTC [orderer/consensus/kafka] try -> DEBU a46[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:26.723 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU a47[0m Initializing new client
[36m2019-01-29 10:34:26.723 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU a48[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.723 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a49[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.723 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a4a[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:26.750 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a4b[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.750 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a4c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.750 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a4d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.750 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a4e[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:26.781 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a4f[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.782 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a50[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.782 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a51[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.782 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a52[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:26.815 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a53[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.815 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a54[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.816 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a55[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:26.816 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a56[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:26.816 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a57[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:26.875 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a58[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.875 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a59[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:26.910 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a5a[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.910 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a5b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.910 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a5c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.911 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a5d[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:26.939 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a5e[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.939 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a5f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.939 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a60[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:26.939 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a61[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:26.967 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a62[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.967 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a63[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:26.968 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a64[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:26.968 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a65[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:26.968 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a66[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:27.066 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a67[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:27.066 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a68[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:27.106 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a69[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.106 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a6a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.106 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a6b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:27.106 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a6c[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:27.134 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a6d[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.134 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a6e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.134 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a6f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:27.134 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a70[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:27.218 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a71[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:27.218 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a72[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:27.246 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a73[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.246 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a74[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.246 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a75[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:27.246 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a76[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:27.765 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a78[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.765 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a79[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.765 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a7a[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:27.765 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a7b[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:27.765 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a7c[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:27.765 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a77[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.765 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a7d[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.765 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a7e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:27.766 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a7f[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:27.795 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a80[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.796 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a81[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.796 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a82[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:27.796 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a83[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:27.796 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU a84[0m Closing Client
[36m2019-01-29 10:34:27.798 UTC [orderer/consensus/kafka] try -> DEBU a85[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:27.798 UTC [orderer/consensus/kafka] try -> DEBU a86[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:27.798 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU a87[0m Initializing new client
[36m2019-01-29 10:34:27.798 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU a88[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:27.798 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a89[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:27.798 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a8a[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:27.831 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a8b[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.831 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a8c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.831 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a8d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:27.831 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a8e[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:27.862 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a8f[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.862 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a90[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.862 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a91[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:27.862 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a92[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:27.893 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a93[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.893 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a94[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:27.893 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU a95[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:27.893 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a96[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:27.893 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU a97[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:28.015 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a98[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.016 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a99[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:28.086 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a9a[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.086 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a9b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.086 UTC [orderer/consensus/kafka/sarama] Open -> DEBU a9c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.086 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a9d[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:28.110 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU a9e[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.110 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU a9f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.110 UTC [orderer/consensus/kafka/sarama] Open -> DEBU aa0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.110 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU aa1[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:28.137 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU aa2[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.137 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU aa3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.137 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU aa4[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:28.137 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU aa5[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:28.137 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU aa6[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:28.143 UTC [orderer/consensus/kafka/sarama] Open -> DEBU aa7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.143 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU aa8[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:28.170 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU aa9[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.170 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU aaa[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.170 UTC [orderer/consensus/kafka/sarama] Open -> DEBU aab[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.170 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU aac[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:28.199 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU aad[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.199 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU aae[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.199 UTC [orderer/consensus/kafka/sarama] Open -> DEBU aaf[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.199 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ab0[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:28.221 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU ab1[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.221 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ab2[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.221 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ab3[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:28.221 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU ab4[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:28.222 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU ab5[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:28.387 UTC [orderer/consensus/kafka/sarama] Open -> DEBU ab6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.388 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ab7[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:28.415 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU ab8[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.415 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ab9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.415 UTC [orderer/consensus/kafka/sarama] Open -> DEBU aba[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.416 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU abb[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:28.437 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU abc[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.437 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU abd[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.437 UTC [orderer/consensus/kafka/sarama] Open -> DEBU abe[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.437 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU abf[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:28.462 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU ac0[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.462 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ac1[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.462 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ac2[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:28.462 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU ac3[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:28.462 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU ac4[0m Closing Client
[36m2019-01-29 10:34:28.462 UTC [orderer/consensus/kafka] try -> DEBU ac5[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:28.462 UTC [orderer/consensus/kafka] try -> DEBU ac6[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:28.462 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU ac7[0m Initializing new client
[36m2019-01-29 10:34:28.462 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU ac8[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.462 UTC [orderer/consensus/kafka/sarama] Open -> DEBU ac9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.462 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU aca[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:28.467 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU acb[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.467 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU acc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.467 UTC [orderer/consensus/kafka/sarama] Open -> DEBU acd[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.467 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU ace[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:28.472 UTC [orderer/consensus/kafka/sarama] Open -> DEBU acf[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.472 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ad0[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:28.495 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU ad1[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.495 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU ad2[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.495 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ad3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.495 UTC [orderer/consensus/kafka/sarama] Open -> DEBU ad4[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.495 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ad6[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:28.495 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU ad5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.495 UTC [orderer/consensus/kafka/sarama] Open -> DEBU ad7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.495 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU ad8[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:28.518 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU ad9[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.518 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU ada[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.518 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU adb[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.518 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU adc[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:28.518 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU ade[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:28.518 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU adf[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:28.518 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU ae0[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:28.518 UTC [orderer/consensus/kafka/sarama] Open -> DEBU add[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.518 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ae1[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:28.769 UTC [orderer/consensus/kafka/sarama] Open -> DEBU ae2[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:28.769 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ae3[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:29.386 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU ae4[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.386 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ae5[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.386 UTC [orderer/consensus/kafka/sarama] Open -> DEBU ae6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:29.386 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ae7[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:29.386 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU ae8[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.386 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ae9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.386 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU aea[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:29.386 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU aeb[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:29.386 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU aec[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:29.417 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU aed[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.418 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU aee[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.418 UTC [orderer/consensus/kafka/sarama] Open -> DEBU aef[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:29.418 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU af0[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:29.450 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU af1[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.450 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU af2[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.450 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU af3[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:29.450 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU af4[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:29.450 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU af5[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:29.636 UTC [orderer/consensus/kafka/sarama] Open -> DEBU af6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:29.637 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU af7[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:29.671 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU af8[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.671 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU af9[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.671 UTC [orderer/consensus/kafka/sarama] Open -> DEBU afa[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:29.671 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU afb[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:29.699 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU afc[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.699 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU afd[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.699 UTC [orderer/consensus/kafka/sarama] Open -> DEBU afe[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:29.699 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU aff[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:29.700 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b00[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:29.700 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b01[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:29.729 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b02[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.729 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b03[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.729 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b05[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.729 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b06[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:29.729 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b07[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:29.730 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU b08[0m Closing Client
[36m2019-01-29 10:34:29.730 UTC [orderer/consensus/kafka] try -> DEBU b09[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:29.730 UTC [orderer/consensus/kafka] retry -> DEBU b0a[0m [channel: comunitychannel] Switching to the long retry interval
[36m2019-01-29 10:34:29.730 UTC [orderer/consensus/kafka] try -> DEBU b0b[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:34:29.730 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU b0c[0m Initializing new client
[36m2019-01-29 10:34:29.730 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU b0d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:29.730 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b0e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:29.730 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b0f[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:29.729 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b04[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.730 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b10[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:29.730 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b11[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:29.760 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b12[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.760 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b13[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.760 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b14[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.760 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b15[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.760 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b16[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:29.760 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b17[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:29.760 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b18[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:29.760 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b19[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:29.783 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b1a[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.783 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b1b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.783 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b1c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:29.783 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b1d[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:29.784 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b1e[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.784 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b1f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.784 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b20[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:29.784 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b21[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:29.784 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b22[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:29.813 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b23[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.814 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b24[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:29.814 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b25[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:29.814 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b26[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:29.814 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b27[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:30.034 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b28[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:30.035 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b29[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:30.064 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b2a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:30.065 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b2b[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:30.070 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b2c[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:30.070 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b2d[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:30.071 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b2e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:30.071 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b2f[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:30.097 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b30[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:30.097 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b31[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:30.097 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b32[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:30.097 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b33[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:30.123 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b34[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:30.124 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b35[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:30.124 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b36[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:30.124 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b37[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:31.017 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b38[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.017 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b3a[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.017 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b3b[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:31.017 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b3c[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:31.017 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b3d[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:31.017 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b39[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.018 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b3e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.018 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b3f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.018 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b40[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:31.106 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b41[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.106 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b42[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.106 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b43[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:31.106 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b44[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:31.106 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU b45[0m Closing Client
[36m2019-01-29 10:34:31.107 UTC [orderer/consensus/kafka] try -> DEBU b46[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:31.107 UTC [orderer/consensus/kafka] retry -> DEBU b47[0m [channel: testchainid] Switching to the long retry interval
[36m2019-01-29 10:34:31.107 UTC [orderer/consensus/kafka] try -> DEBU b48[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:34:31.107 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU b49[0m Initializing new client
[36m2019-01-29 10:34:31.107 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU b4a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.107 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b4b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.107 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b4c[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:31.169 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b4d[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.169 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b4e[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.169 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b4f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.169 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b50[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:31.215 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b51[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.215 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b52[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.216 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b53[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.216 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b54[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:31.250 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b55[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.250 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b56[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.250 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU b57[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:31.250 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b58[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:31.250 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b59[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:34:31.268 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b5a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.268 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b5b[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:31.317 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b5c[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.318 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b5d[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.318 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b5e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.318 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b5f[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:31.364 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b60[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.364 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b61[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.364 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b62[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.365 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b63[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:31.395 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b64[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.395 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b65[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.396 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b66[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:31.396 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b67[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:31.396 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b68[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:31.501 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b69[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.501 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b6a[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:31.525 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b6b[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.525 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b6c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.525 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b6d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.525 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b6e[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:31.562 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b6f[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.562 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b70[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.562 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b71[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.563 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b72[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:31.589 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b73[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.589 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b74[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.589 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b75[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:31.590 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b76[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:31.590 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b77[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:34:31.646 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b78[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.646 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b79[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:31.683 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b7a[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.683 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b7b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.683 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b7c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.683 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b7d[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:31.742 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b7e[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.742 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b7f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.742 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b80[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.742 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b81[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:31.774 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b82[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.774 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b83[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.774 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b84[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:31.774 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b85[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:31.775 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU b86[0m Closing Client
[36m2019-01-29 10:34:31.775 UTC [orderer/consensus/kafka] try -> DEBU b87[0m [channel: comunitychannel] Initial attempt failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:31.775 UTC [orderer/consensus/kafka] try -> DEBU b88[0m [channel: comunitychannel] Retrying every 5m0s for a total of 12h0m0s
[36m2019-01-29 10:34:31.840 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b89[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.840 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b8a[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:31.869 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b8b[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.869 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b8c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.869 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b8d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.869 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b8e[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:31.899 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b8f[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.899 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b90[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.900 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b91[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:31.900 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b92[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:31.930 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b93[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.931 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b94[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:31.931 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b95[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:31.931 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b96[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:31.931 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU b97[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:34:32.181 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b98[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:32.182 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b99[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:34:32.210 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b9a[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:32.210 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b9b[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:32.210 UTC [orderer/consensus/kafka/sarama] Open -> DEBU b9c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:32.210 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b9d[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:34:32.245 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU b9e[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:32.245 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU b9f[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:32.245 UTC [orderer/consensus/kafka/sarama] Open -> DEBU ba0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:34:32.245 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ba1[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:34:32.277 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU ba2[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:32.277 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ba3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:34:32.277 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU ba4[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:34:32.277 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU ba5[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:34:32.277 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU ba6[0m Closing Client
[36m2019-01-29 10:34:32.278 UTC [orderer/consensus/kafka] try -> DEBU ba7[0m [channel: testchainid] Initial attempt failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:34:32.278 UTC [orderer/consensus/kafka] try -> DEBU ba8[0m [channel: testchainid] Retrying every 5m0s for a total of 12h0m0s
[36m2019-01-29 10:39:31.885 UTC [orderer/consensus/kafka] try -> DEBU ba9[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:39:31.885 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU baa[0m Initializing new client
[36m2019-01-29 10:39:31.885 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU bab[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:31.885 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bac[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:31.885 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU bad[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:39:31.910 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bae[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:31.910 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU baf[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:31.910 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bb0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:31.911 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU bb1[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:39:31.959 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bb2[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:31.959 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU bb3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:31.959 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bb4[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:31.959 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU bb5[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:39:31.982 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bb6[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:31.982 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU bb7[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:31.982 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU bb8[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:39:31.982 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU bb9[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:39:31.982 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU bba[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:39:32.233 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bbb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.233 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bbc[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:39:32.259 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bbd[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.259 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bbe[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.259 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bbf[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.260 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bc0[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:39:32.302 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bc1[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.302 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bc2[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.302 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bc3[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.302 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bc4[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:39:32.326 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bc5[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.326 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bc6[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.326 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bc7[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:39:32.326 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU bc8[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:39:32.326 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU bc9[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:39:32.387 UTC [orderer/consensus/kafka] try -> DEBU bca[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:39:32.387 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU bcb[0m Initializing new client
[36m2019-01-29 10:39:32.387 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU bcc[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.387 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bcd[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.388 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU bce[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:39:32.419 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bcf[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.419 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU bd0[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.419 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bd1[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.419 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU bd2[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:39:32.447 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bd3[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.448 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU bd4[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.448 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bd5[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.448 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU bd6[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:39:32.474 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bd7[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.474 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU bd8[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.474 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU bd9[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:39:32.474 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU bda[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:39:32.474 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU bdb[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 10:39:32.577 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bdc[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.577 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bdd[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:39:32.605 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bde[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.605 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bdf[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.605 UTC [orderer/consensus/kafka/sarama] Open -> DEBU be0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.605 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU be1[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:39:32.632 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU be2[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.633 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU be3[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.633 UTC [orderer/consensus/kafka/sarama] Open -> DEBU be4[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.633 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU be5[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:39:32.660 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU be6[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.660 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU be7[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.660 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU be8[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:39:32.660 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU be9[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:39:32.660 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU bea[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:39:32.725 UTC [orderer/consensus/kafka/sarama] Open -> DEBU beb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.725 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bec[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:39:32.755 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bed[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.755 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bee[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.755 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bef[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.755 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bf0[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:39:32.791 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bf1[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.791 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bf2[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.791 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bf3[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.791 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bf4[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:39:32.813 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bf5[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.814 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bf6[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.814 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bf7[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:39:32.814 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU bf8[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:39:32.814 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU bf9[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 10:39:32.911 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bfa[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.911 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bfb[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:39:32.942 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU bfc[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.942 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bfd[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.943 UTC [orderer/consensus/kafka/sarama] Open -> DEBU bfe[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.943 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU bff[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:39:32.976 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c00[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.976 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c01[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.976 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c02[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:32.976 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c03[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:39:32.997 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c04[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.997 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c05[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:32.997 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c06[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:39:32.997 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU c07[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:39:32.997 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU c08[0m Closing Client
[36m2019-01-29 10:39:32.997 UTC [orderer/consensus/kafka] try -> DEBU c09[0m [channel: comunitychannel] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:39:33.064 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c0a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:33.064 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c0b[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:39:33.093 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c0c[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:33.093 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c0d[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:33.094 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c0e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:33.094 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c0f[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:39:33.871 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c10[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:33.871 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c11[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:33.871 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c12[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:33.871 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c13[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:39:33.903 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c14[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:33.903 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c15[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:33.903 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c16[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:39:33.903 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU c17[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:39:33.903 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU c18[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 10:39:34.153 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c19[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:34.154 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c1a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:39:34.184 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c1b[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:34.184 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c1c[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka0.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:34.184 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c1d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:34.184 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c1e[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:39:34.208 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c1f[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:34.208 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c20[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka1.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:34.208 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c21[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:39:34.208 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c22[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:39:34.253 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c23[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:34.253 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c24[0m client/metadata got error from broker while fetching metadata: dial tcp: lookup kafka2.switch2logic.co.za on 127.0.0.11:53: no such host
[36m2019-01-29 10:39:34.253 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU c25[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 10:39:34.253 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU c26[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 10:39:34.253 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU c27[0m Closing Client
[36m2019-01-29 10:39:34.253 UTC [orderer/consensus/kafka] try -> DEBU c28[0m [channel: testchainid] Need to retry because process failed = kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[36m2019-01-29 10:43:41.907 UTC [grpc] Printf -> DEBU c29[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.25:41726": tls: first record does not look like a TLS handshake
[36m2019-01-29 10:44:12.412 UTC [grpc] Printf -> DEBU c2a[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.25:41756": tls: first record does not look like a TLS handshake
[36m2019-01-29 10:44:13.415 UTC [grpc] Printf -> DEBU c2b[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.25:41758": tls: first record does not look like a TLS handshake
[36m2019-01-29 10:44:15.120 UTC [grpc] Printf -> DEBU c2c[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.25:41760": tls: first record does not look like a TLS handshake
[36m2019-01-29 10:44:31.885 UTC [orderer/consensus/kafka] try -> DEBU c2d[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:44:31.886 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU c2e[0m Initializing new client
[36m2019-01-29 10:44:31.886 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU c2f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:31.887 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c30[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:31.887 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU c31[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:44:31.890 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c32[0m Connected to broker at kafka0.switch2logic.co.za:9092 (unregistered)
[36m2019-01-29 10:44:31.891 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU c33[0m client/brokers registered new broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 10:44:31.892 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU c34[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 10:44:31.892 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU c35[0m client/brokers registered new broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:44:31.892 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU c36[0m Successfully initialized new client
[36m2019-01-29 10:44:31.892 UTC [orderer/consensus/kafka] try -> DEBU c37[0m [channel: comunitychannel] Error is nil, breaking the retry loop
2019-01-29 10:44:31.892 UTC [orderer/consensus/kafka] startThread -> INFO c38[0m [channel: comunitychannel] Producer set up successfully
2019-01-29 10:44:31.892 UTC [orderer/consensus/kafka] sendConnectMessage -> INFO c39[0m [channel: comunitychannel] About to post the CONNECT message...
[36m2019-01-29 10:44:31.892 UTC [orderer/consensus/kafka] try -> DEBU c3a[0m [channel: comunitychannel] Attempting to post the CONNECT message...
[36m2019-01-29 10:44:31.892 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c3b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:31.892 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU c3c[0m producer/broker/0 starting up
[36m2019-01-29 10:44:31.892 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU c3d[0m producer/broker/0 state change to [open] on comunitychannel/0
[36m2019-01-29 10:44:31.893 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c3e[0m Connected to broker at kafka0.switch2logic.co.za:9092 (registered as #0)
[36m2019-01-29 10:44:31.933 UTC [orderer/consensus/kafka] try -> DEBU c3f[0m [channel: comunitychannel] Error is nil, breaking the retry loop
2019-01-29 10:44:31.933 UTC [orderer/consensus/kafka] startThread -> INFO c40[0m [channel: comunitychannel] CONNECT message posted successfully
2019-01-29 10:44:31.934 UTC [orderer/consensus/kafka] setupParentConsumerForChannel -> INFO c41[0m [channel: comunitychannel] Setting up the parent consumer for this channel...
[36m2019-01-29 10:44:31.934 UTC [orderer/consensus/kafka] try -> DEBU c42[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:44:31.934 UTC [orderer/consensus/kafka/sarama] NewConsumer -> DEBU c43[0m Initializing new client
[36m2019-01-29 10:44:31.934 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU c44[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:31.934 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c45[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:31.934 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU c46[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:44:31.935 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c47[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp 10.0.0.29:10092: connect: connection refused
[36m2019-01-29 10:44:31.935 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU c48[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.29:10092: connect: connection refused
[36m2019-01-29 10:44:31.935 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c49[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:31.935 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU c4a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:44:31.935 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c4b[0m Connected to broker at kafka0.switch2logic.co.za:9092 (unregistered)
[36m2019-01-29 10:44:31.937 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU c4c[0m client/brokers registered new broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 10:44:31.937 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU c4d[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 10:44:31.937 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU c4e[0m client/brokers registered new broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:44:31.937 UTC [orderer/consensus/kafka/sarama] NewConsumer -> DEBU c4f[0m Successfully initialized new client
[36m2019-01-29 10:44:31.937 UTC [orderer/consensus/kafka] try -> DEBU c50[0m [channel: comunitychannel] Error is nil, breaking the retry loop
2019-01-29 10:44:31.937 UTC [orderer/consensus/kafka] startThread -> INFO c51[0m [channel: comunitychannel] Parent consumer set up successfully
2019-01-29 10:44:31.937 UTC [orderer/consensus/kafka] setupChannelConsumerForChannel -> INFO c52[0m [channel: comunitychannel] Setting up the channel consumer for this channel (start offset: -2)...
[36m2019-01-29 10:44:31.937 UTC [orderer/consensus/kafka] try -> DEBU c53[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:44:31.937 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c54[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:31.938 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c55[0m Connected to broker at kafka0.switch2logic.co.za:9092 (registered as #0)
[36m2019-01-29 10:44:31.944 UTC [orderer/consensus/kafka] try -> DEBU c56[0m [channel: comunitychannel] Error is nil, breaking the retry loop
[36m2019-01-29 10:44:31.944 UTC [orderer/consensus/kafka/sarama] subscriptionConsumer -> DEBU c57[0m consumer/broker/0 added subscription to comunitychannel/0
2019-01-29 10:44:31.945 UTC [orderer/consensus/kafka] startThread -> INFO c58[0m [channel: comunitychannel] Channel consumer set up successfully
2019-01-29 10:44:31.945 UTC [orderer/consensus/kafka] startThread -> INFO c59[0m [channel: comunitychannel] Start phase completed successfully
[36m2019-01-29 10:44:31.952 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU c5a[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 0. Inspecting type...
[36m2019-01-29 10:44:31.952 UTC [orderer/consensus/kafka] processConnect -> DEBU c5b[0m [channel: comunitychannel] It's a connect message - ignoring
[36m2019-01-29 10:44:32.387 UTC [orderer/consensus/kafka] try -> DEBU c5c[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:32.388 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU c5d[0m Initializing new client
[36m2019-01-29 10:44:32.388 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU c5e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:32.388 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c5f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:32.388 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU c60[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:44:32.390 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c61[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.28:11092: connect: connection refused
[36m2019-01-29 10:44:32.390 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU c62[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.28:11092: connect: connection refused
[36m2019-01-29 10:44:32.390 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c63[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:32.390 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU c64[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:44:32.391 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c65[0m Connected to broker at kafka0.switch2logic.co.za:9092 (unregistered)
[36m2019-01-29 10:44:32.393 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU c66[0m client/brokers registered new broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 10:44:32.393 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU c67[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 10:44:32.393 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU c68[0m client/brokers registered new broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:44:32.394 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU c69[0m Successfully initialized new client
[36m2019-01-29 10:44:32.394 UTC [orderer/consensus/kafka] try -> DEBU c6a[0m [channel: testchainid] Error is nil, breaking the retry loop
2019-01-29 10:44:32.394 UTC [orderer/consensus/kafka] startThread -> INFO c6b[0m [channel: testchainid] Producer set up successfully
2019-01-29 10:44:32.394 UTC [orderer/consensus/kafka] sendConnectMessage -> INFO c6c[0m [channel: testchainid] About to post the CONNECT message...
[36m2019-01-29 10:44:32.394 UTC [orderer/consensus/kafka] try -> DEBU c6d[0m [channel: testchainid] Attempting to post the CONNECT message...
[36m2019-01-29 10:44:32.394 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c6e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:32.394 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU c6f[0m producer/broker/1 starting up
[36m2019-01-29 10:44:32.395 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU c70[0m producer/broker/1 state change to [open] on testchainid/0
[36m2019-01-29 10:44:32.395 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c71[0m Connected to broker at kafka1.switch2logic.co.za:9092 (registered as #1)
[36m2019-01-29 10:44:32.401 UTC [orderer/consensus/kafka] try -> DEBU c72[0m [channel: testchainid] Error is nil, breaking the retry loop
2019-01-29 10:44:32.402 UTC [orderer/consensus/kafka] startThread -> INFO c73[0m [channel: testchainid] CONNECT message posted successfully
2019-01-29 10:44:32.402 UTC [orderer/consensus/kafka] setupParentConsumerForChannel -> INFO c74[0m [channel: testchainid] Setting up the parent consumer for this channel...
[36m2019-01-29 10:44:32.402 UTC [orderer/consensus/kafka] try -> DEBU c75[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:32.402 UTC [orderer/consensus/kafka/sarama] NewConsumer -> DEBU c76[0m Initializing new client
[36m2019-01-29 10:44:32.402 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU c77[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:32.402 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c78[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:32.402 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU c79[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:44:32.402 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c7a[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.28:11092: connect: connection refused
[36m2019-01-29 10:44:32.402 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU c7b[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.28:11092: connect: connection refused
[36m2019-01-29 10:44:32.402 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c7c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:32.402 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU c7d[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:44:32.406 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c7e[0m Connected to broker at kafka0.switch2logic.co.za:9092 (unregistered)
[36m2019-01-29 10:44:32.408 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU c7f[0m client/brokers registered new broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 10:44:32.408 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU c80[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 10:44:32.408 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU c81[0m client/brokers registered new broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:44:32.408 UTC [orderer/consensus/kafka/sarama] NewConsumer -> DEBU c82[0m Successfully initialized new client
[36m2019-01-29 10:44:32.408 UTC [orderer/consensus/kafka] try -> DEBU c83[0m [channel: testchainid] Error is nil, breaking the retry loop
2019-01-29 10:44:32.408 UTC [orderer/consensus/kafka] startThread -> INFO c84[0m [channel: testchainid] Parent consumer set up successfully
2019-01-29 10:44:32.408 UTC [orderer/consensus/kafka] setupChannelConsumerForChannel -> INFO c85[0m [channel: testchainid] Setting up the channel consumer for this channel (start offset: 6)...
[36m2019-01-29 10:44:32.408 UTC [orderer/consensus/kafka] try -> DEBU c86[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:32.408 UTC [orderer/consensus/kafka/sarama] Open -> DEBU c87[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:44:32.409 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU c88[0m Connected to broker at kafka1.switch2logic.co.za:9092 (registered as #1)
[36m2019-01-29 10:44:32.411 UTC [orderer/consensus/kafka] try -> DEBU c89[0m [channel: testchainid] Initial attempt failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:32.411 UTC [orderer/consensus/kafka] try -> DEBU c8a[0m [channel: testchainid] Retrying every 1s for a total of 30s
[36m2019-01-29 10:44:32.677 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU c8b[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 1. Inspecting type...
[36m2019-01-29 10:44:32.677 UTC [orderer/consensus/kafka] processConnect -> DEBU c8c[0m [channel: comunitychannel] It's a connect message - ignoring
[36m2019-01-29 10:44:32.744 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU c8d[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 2. Inspecting type...
[36m2019-01-29 10:44:32.745 UTC [orderer/consensus/kafka] processConnect -> DEBU c8e[0m [channel: comunitychannel] It's a connect message - ignoring
[36m2019-01-29 10:44:33.411 UTC [orderer/consensus/kafka] try -> DEBU c8f[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:33.414 UTC [orderer/consensus/kafka] try -> DEBU c90[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:34.411 UTC [orderer/consensus/kafka] try -> DEBU c91[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:34.415 UTC [orderer/consensus/kafka] try -> DEBU c92[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:35.411 UTC [orderer/consensus/kafka] try -> DEBU c93[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:35.415 UTC [orderer/consensus/kafka] try -> DEBU c94[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:36.411 UTC [orderer/consensus/kafka] try -> DEBU c95[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:36.414 UTC [orderer/consensus/kafka] try -> DEBU c96[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:37.411 UTC [orderer/consensus/kafka] try -> DEBU c97[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:37.414 UTC [orderer/consensus/kafka] try -> DEBU c98[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:38.411 UTC [orderer/consensus/kafka] try -> DEBU c99[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:38.414 UTC [orderer/consensus/kafka] try -> DEBU c9a[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:38.661 UTC [grpc] Printf -> DEBU c9b[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.25:41872": tls: first record does not look like a TLS handshake
[36m2019-01-29 10:44:39.411 UTC [orderer/consensus/kafka] try -> DEBU c9c[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:39.414 UTC [orderer/consensus/kafka] try -> DEBU c9d[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:40.411 UTC [orderer/consensus/kafka] try -> DEBU c9e[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:40.414 UTC [orderer/consensus/kafka] try -> DEBU c9f[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:41.411 UTC [orderer/consensus/kafka] try -> DEBU ca0[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:41.414 UTC [orderer/consensus/kafka] try -> DEBU ca1[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:42.411 UTC [orderer/consensus/kafka] try -> DEBU ca2[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:42.415 UTC [orderer/consensus/kafka] try -> DEBU ca3[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:43.411 UTC [orderer/consensus/kafka] try -> DEBU ca4[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:43.413 UTC [orderer/consensus/kafka] try -> DEBU ca5[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:44.411 UTC [orderer/consensus/kafka] try -> DEBU ca6[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:44.414 UTC [orderer/consensus/kafka] try -> DEBU ca7[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:45.411 UTC [orderer/consensus/kafka] try -> DEBU ca8[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:45.413 UTC [orderer/consensus/kafka] try -> DEBU ca9[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:46.411 UTC [orderer/consensus/kafka] try -> DEBU caa[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:46.413 UTC [orderer/consensus/kafka] try -> DEBU cab[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:47.411 UTC [orderer/consensus/kafka] try -> DEBU cac[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:47.414 UTC [orderer/consensus/kafka] try -> DEBU cad[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:48.411 UTC [orderer/consensus/kafka] try -> DEBU cae[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:48.415 UTC [orderer/consensus/kafka] try -> DEBU caf[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:49.411 UTC [orderer/consensus/kafka] try -> DEBU cb0[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:49.416 UTC [orderer/consensus/kafka] try -> DEBU cb1[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:50.411 UTC [orderer/consensus/kafka] try -> DEBU cb2[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:50.413 UTC [orderer/consensus/kafka] try -> DEBU cb3[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:51.411 UTC [orderer/consensus/kafka] try -> DEBU cb4[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:51.416 UTC [orderer/consensus/kafka] try -> DEBU cb5[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:52.411 UTC [orderer/consensus/kafka] try -> DEBU cb6[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:52.413 UTC [orderer/consensus/kafka] try -> DEBU cb7[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:53.411 UTC [orderer/consensus/kafka] try -> DEBU cb8[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:53.413 UTC [orderer/consensus/kafka] try -> DEBU cb9[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:54.411 UTC [orderer/consensus/kafka] try -> DEBU cba[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:54.414 UTC [orderer/consensus/kafka] try -> DEBU cbb[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:55.411 UTC [orderer/consensus/kafka] try -> DEBU cbc[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:55.414 UTC [orderer/consensus/kafka] try -> DEBU cbd[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:56.411 UTC [orderer/consensus/kafka] try -> DEBU cbe[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:56.414 UTC [orderer/consensus/kafka] try -> DEBU cbf[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:57.411 UTC [orderer/consensus/kafka] try -> DEBU cc0[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:57.415 UTC [orderer/consensus/kafka] try -> DEBU cc1[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:58.411 UTC [orderer/consensus/kafka] try -> DEBU cc2[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:58.414 UTC [orderer/consensus/kafka] try -> DEBU cc3[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:44:59.411 UTC [orderer/consensus/kafka] try -> DEBU cc4[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:44:59.413 UTC [orderer/consensus/kafka] try -> DEBU cc5[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:45:00.411 UTC [orderer/consensus/kafka] try -> DEBU cc6[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:45:00.415 UTC [orderer/consensus/kafka] try -> DEBU cc7[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:45:01.411 UTC [orderer/consensus/kafka] try -> DEBU cc8[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:45:01.414 UTC [orderer/consensus/kafka] try -> DEBU cc9[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:45:02.411 UTC [orderer/consensus/kafka] try -> DEBU cca[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:45:02.414 UTC [orderer/consensus/kafka] try -> DEBU ccb[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:45:02.414 UTC [orderer/consensus/kafka] retry -> DEBU ccc[0m [channel: testchainid] Switching to the long retry interval
[36m2019-01-29 10:45:02.414 UTC [orderer/consensus/kafka] try -> DEBU ccd[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:45:02.416 UTC [orderer/consensus/kafka] try -> DEBU cce[0m [channel: testchainid] Initial attempt failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:45:02.416 UTC [orderer/consensus/kafka] try -> DEBU ccf[0m [channel: testchainid] Retrying every 5m0s for a total of 12h0m0s
[36m2019-01-29 10:47:22.934 UTC [grpc] Printf -> DEBU cd0[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.25:42032": tls: first record does not look like a TLS handshake
[36m2019-01-29 10:47:52.593 UTC [grpc] Printf -> DEBU cd1[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.25:42100": tls: first record does not look like a TLS handshake
[36m2019-01-29 10:50:02.417 UTC [orderer/consensus/kafka] try -> DEBU cd2[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:50:02.419 UTC [orderer/consensus/kafka] try -> DEBU cd3[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:51:32.138 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU cd4[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 3. Inspecting type...
[36m2019-01-29 10:51:32.138 UTC [orderer/consensus/kafka] processConnect -> DEBU cd5[0m [channel: comunitychannel] It's a connect message - ignoring
2019-01-29 10:51:52.009 UTC [localconfig] completeInitialization -> INFO 001[0m Kafka.Version unset, setting to 0.10.2.0
[36m2019-01-29 10:51:52.009 UTC [bccsp_sw] openKeyStore -> DEBU 002[0m KeyStore opened at [/etc/hyperledger/fabric/orderer/msp/keystore]...done
[36m2019-01-29 10:51:52.009 UTC [bccsp] initBCCSP -> DEBU 003[0m Initialize BCCSP [SW]
[36m2019-01-29 10:51:52.009 UTC [msp] getPemMaterialFromDir -> DEBU 004[0m Reading directory /etc/hyperledger/fabric/orderer/msp/signcerts
[36m2019-01-29 10:51:52.009 UTC [msp] getPemMaterialFromDir -> DEBU 005[0m Inspecting file /etc/hyperledger/fabric/orderer/msp/signcerts/orderer0.hospital2.switch2logic.co.za-cert.pem
[36m2019-01-29 10:51:52.009 UTC [msp] getPemMaterialFromDir -> DEBU 006[0m Reading directory /etc/hyperledger/fabric/orderer/msp/cacerts
[36m2019-01-29 10:51:52.009 UTC [msp] getPemMaterialFromDir -> DEBU 007[0m Inspecting file /etc/hyperledger/fabric/orderer/msp/cacerts/ca.switch2logic.co.za-cert.pem
[36m2019-01-29 10:51:52.009 UTC [msp] getPemMaterialFromDir -> DEBU 008[0m Reading directory /etc/hyperledger/fabric/orderer/msp/admincerts
[36m2019-01-29 10:51:52.009 UTC [msp] getPemMaterialFromDir -> DEBU 009[0m Inspecting file /etc/hyperledger/fabric/orderer/msp/admincerts/Admin@switch2logic.co.za-cert.pem
[36m2019-01-29 10:51:52.009 UTC [msp] getPemMaterialFromDir -> DEBU 00a[0m Reading directory /etc/hyperledger/fabric/orderer/msp/intermediatecerts
[36m2019-01-29 10:51:52.009 UTC [msp] getMspConfig -> DEBU 00b[0m Intermediate certs folder not found at [/etc/hyperledger/fabric/orderer/msp/intermediatecerts]. Skipping. [stat /etc/hyperledger/fabric/orderer/msp/intermediatecerts: no such file or directory]
[36m2019-01-29 10:51:52.009 UTC [msp] getPemMaterialFromDir -> DEBU 00c[0m Reading directory /etc/hyperledger/fabric/orderer/msp/tlscacerts
[36m2019-01-29 10:51:52.010 UTC [msp] getPemMaterialFromDir -> DEBU 00d[0m Inspecting file /etc/hyperledger/fabric/orderer/msp/tlscacerts/tlsca.switch2logic.co.za-cert.pem
[36m2019-01-29 10:51:52.010 UTC [msp] getPemMaterialFromDir -> DEBU 00e[0m Reading directory /etc/hyperledger/fabric/orderer/msp/tlsintermediatecerts
[36m2019-01-29 10:51:52.010 UTC [msp] getMspConfig -> DEBU 00f[0m TLS intermediate certs folder not found at [/etc/hyperledger/fabric/orderer/msp/tlsintermediatecerts]. Skipping. [stat /etc/hyperledger/fabric/orderer/msp/tlsintermediatecerts: no such file or directory]
[36m2019-01-29 10:51:52.010 UTC [msp] getPemMaterialFromDir -> DEBU 010[0m Reading directory /etc/hyperledger/fabric/orderer/msp/crls
[36m2019-01-29 10:51:52.010 UTC [msp] getMspConfig -> DEBU 011[0m crls folder not found at [/etc/hyperledger/fabric/orderer/msp/crls]. Skipping. [stat /etc/hyperledger/fabric/orderer/msp/crls: no such file or directory]
[36m2019-01-29 10:51:52.010 UTC [msp] getMspConfig -> DEBU 012[0m MSP configuration file not found at [/etc/hyperledger/fabric/orderer/msp/config.yaml]: [stat /etc/hyperledger/fabric/orderer/msp/config.yaml: no such file or directory]
[36m2019-01-29 10:51:52.010 UTC [msp] newBccspMsp -> DEBU 013[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:51:52.010 UTC [msp] New -> DEBU 014[0m Creating Cache-MSP instance
[36m2019-01-29 10:51:52.010 UTC [msp] loadLocaMSP -> DEBU 015[0m Created new local MSP
[36m2019-01-29 10:51:52.010 UTC [msp] Setup -> DEBU 016[0m Setting up MSP instance OrdererMSP
[36m2019-01-29 10:51:52.010 UTC [msp/identity] newIdentity -> DEBU 017[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICSzCCAfKgAwIBAgIRAO7EFp+tGDrZX/4Yn1ExG4IwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowdzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEe
MBwGA1UEAxMVY2Euc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZI
zj0DAQcDQgAE+ci0VrQQEnBN2VlYMEvGL0RvqwQ9zVhgyxdKDi9AB8iyQ0dhyWzJ
CZ9MnAWGk29pw9b+9HdNkbalpJKWkcctJ6NfMF0wDgYDVR0PAQH/BAQDAgGmMA8G
A1UdJQQIMAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgGIY2e0Pm
0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDRwAwRAIgcoBa
RHN5r57Qu7sd8TwCzfyJI+uozczAYI2SsN06iKgCIAeAP4FbTHxjqSLcNZMNGbTZ
YWA1h+rDBMa99duId/0D
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.010 UTC [msp/identity] newIdentity -> DEBU 018[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICHzCCAcWgAwIBAgIQRo5Qm6m11gCv1i2SXwRJAjAKBggqhkjOPQQDAjB3MQsw
CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy
YW5jaXNjbzEbMBkGA1UEChMSc3dpdGNoMmxvZ2ljLmNvLnphMR4wHAYDVQQDExVj
YS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkwMTI5MDc0MTU0WhcNMjkwMTI2MDc0
MTU0WjBdMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UE
BxMNU2FuIEZyYW5jaXNjbzEhMB8GA1UEAwwYQWRtaW5Ac3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE0QeSwnrMZdy7TKSYF/JzQ12C
vfINZcjx7xyeUuj/96gj42fjc1ctn7oo/tDl1eJNZbDhFvkRzefYmxtoSnH5Y6NN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgGIY2
e0Pm0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDSAAwRQIh
AM8EkjCZIKrAf9sL1d1fThizng+66jmEVlKPbTpimVbiAiAhCJZoeBIJGcgxbCr2
5Rd2IW34zWcPhemkNZvCKv27WA==
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.035 UTC [msp/identity] newIdentity -> DEBU 019[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICLDCCAdOgAwIBAgIRALSnb5cS69ZjMJpS1JIoZEkwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowajELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xLjAsBgNVBAMTJW9yZGVyZXIwLmhvc3BpdGFsMi5z
d2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAAS6h69N
Iqb4d5ts04E2IRVEEawOWRIUoNntvpfHT6SnxVjSZi7exzn/YOTi0QQd6NGQa5iu
PFOZElkdCuGbgkyHo00wSzAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH/BAIwADAr
BgNVHSMEJDAigCAYhjZ7Q+bQZRvQvEDbHV3XtyLU0UWvqf/t8icEQrGycTAKBggq
hkjOPQQDAgNHADBEAiAqTM16gxhM8p3qA85cIM2a/xQXiZG35c3etBeP0/9uGAIg
FY2RcB+w2BjTJYTMYwIWQj/N9KTuAHugDITJ8afv1IU=
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.035 UTC [bccsp_sw] loadPrivateKey -> DEBU 01a[0m Loading private key [6cc0af06e32c6be74c9cb70b0bbf8dc9b0729ca7c2db8fba1fcd4ed4a9dfedd6] at [/etc/hyperledger/fabric/orderer/msp/keystore/6cc0af06e32c6be74c9cb70b0bbf8dc9b0729ca7c2db8fba1fcd4ed4a9dfedd6_sk]...
[36m2019-01-29 10:51:52.035 UTC [msp/identity] newIdentity -> DEBU 01b[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICLDCCAdOgAwIBAgIRALSnb5cS69ZjMJpS1JIoZEkwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowajELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xLjAsBgNVBAMTJW9yZGVyZXIwLmhvc3BpdGFsMi5z
d2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAAS6h69N
Iqb4d5ts04E2IRVEEawOWRIUoNntvpfHT6SnxVjSZi7exzn/YOTi0QQd6NGQa5iu
PFOZElkdCuGbgkyHo00wSzAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH/BAIwADAr
BgNVHSMEJDAigCAYhjZ7Q+bQZRvQvEDbHV3XtyLU0UWvqf/t8icEQrGycTAKBggq
hkjOPQQDAgNHADBEAiAqTM16gxhM8p3qA85cIM2a/xQXiZG35c3etBeP0/9uGAIg
FY2RcB+w2BjTJYTMYwIWQj/N9KTuAHugDITJ8afv1IU=
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.035 UTC [msp] setupSigningIdentity -> DEBU 01c[0m Signing identity expires at 2029-01-26 07:41:54 +0000 UTC
[36m2019-01-29 10:51:52.036 UTC [msp] Validate -> DEBU 01d[0m MSP OrdererMSP validating identity
2019-01-29 10:51:52.036 UTC [orderer/common/server] prettyPrintStruct -> INFO 01e[0m Orderer config values:
	General.LedgerType = "file"
	General.ListenAddress = "0.0.0.0"
	General.ListenPort = 7050
	General.TLS.Enabled = true
	General.TLS.PrivateKey = "/etc/hyperledger/fabric/orderer/tls/server.key"
	General.TLS.Certificate = "/etc/hyperledger/fabric/orderer/tls/server.crt"
	General.TLS.RootCAs = [/etc/hyperledger/fabric/orderer/tls/ca.crt]
	General.TLS.ClientAuthRequired = false
	General.TLS.ClientRootCAs = []
	General.Keepalive.ServerMinInterval = 1m0s
	General.Keepalive.ServerInterval = 2h0m0s
	General.Keepalive.ServerTimeout = 20s
	General.GenesisMethod = "file"
	General.GenesisProfile = "SampleInsecureSolo"
	General.SystemChannel = "test-system-channel-name"
	General.GenesisFile = "/etc/hyperledger/fabric/orderer/channel-artifacts/genesis.block"
	General.Profile.Enabled = false
	General.Profile.Address = "0.0.0.0:6060"
	General.LogLevel = "debug"
	General.LogFormat = "%{color}%{time:2006-01-02 15:04:05.000 MST} [%{module}] %{shortfunc} -> %{level:.4s} %{id:03x}%{color:reset} %{message}"
	General.LocalMSPDir = "/etc/hyperledger/fabric/orderer/msp"
	General.LocalMSPID = "OrdererMSP"
	General.BCCSP.ProviderName = "SW"
	General.BCCSP.SwOpts.SecLevel = 256
	General.BCCSP.SwOpts.HashFamily = "SHA2"
	General.BCCSP.SwOpts.Ephemeral = false
	General.BCCSP.SwOpts.FileKeystore.KeyStorePath = "/etc/hyperledger/fabric/orderer/msp/keystore"
	General.BCCSP.SwOpts.DummyKeystore =
	General.BCCSP.PluginOpts =
	General.Authentication.TimeWindow = 15m0s
	FileLedger.Location = "/var/hyperledger/production/orderer"
	FileLedger.Prefix = "hyperledger-fabric-ordererledger"
	RAMLedger.HistorySize = 1000
	Kafka.Retry.ShortInterval = 1s
	Kafka.Retry.ShortTotal = 30s
	Kafka.Retry.LongInterval = 5m0s
	Kafka.Retry.LongTotal = 12h0m0s
	Kafka.Retry.NetworkTimeouts.DialTimeout = 10s
	Kafka.Retry.NetworkTimeouts.ReadTimeout = 10s
	Kafka.Retry.NetworkTimeouts.WriteTimeout = 10s
	Kafka.Retry.Metadata.RetryMax = 3
	Kafka.Retry.Metadata.RetryBackoff = 250ms
	Kafka.Retry.Producer.RetryMax = 3
	Kafka.Retry.Producer.RetryBackoff = 100ms
	Kafka.Retry.Consumer.RetryBackoff = 2s
	Kafka.Verbose = true
	Kafka.Version = 0.10.2.0
	Kafka.TLS.Enabled = false
	Kafka.TLS.PrivateKey = ""
	Kafka.TLS.Certificate = ""
	Kafka.TLS.RootCAs = []
	Kafka.TLS.ClientAuthRequired = false
	Kafka.TLS.ClientRootCAs = []
	Debug.BroadcastTraceDir = ""
	Debug.DeliverTraceDir = ""
2019-01-29 10:51:52.036 UTC [orderer/common/server] initializeServerConfig -> INFO 01f[0m Starting orderer with TLS enabled
[36m2019-01-29 10:51:52.036 UTC [orderer/common/server] createLedgerFactory -> DEBU 020[0m Ledger dir: /var/hyperledger/production/orderer
[36m2019-01-29 10:51:52.036 UTC [kvledger.util] CreateDirIfMissing -> DEBU 021[0m CreateDirIfMissing [/var/hyperledger/production/orderer/index/]
[36m2019-01-29 10:51:52.037 UTC [kvledger.util] logDirStatus -> DEBU 022[0m Before creating dir - [/var/hyperledger/production/orderer/index/] exists
[36m2019-01-29 10:51:52.037 UTC [kvledger.util] logDirStatus -> DEBU 023[0m After creating dir - [/var/hyperledger/production/orderer/index/] exists
[36m2019-01-29 10:51:52.059 UTC [orderer/common/server] createSubDir -> DEBU 024[0m Found chains sub-dir and using it
2019-01-29 10:51:52.059 UTC [orderer/common/server] initializeMultichannelRegistrar -> INFO 025[0m Not bootstrapping because of existing chains
[36m2019-01-29 10:51:52.059 UTC [fsblkstorage] newBlockfileMgr -> DEBU 026[0m newBlockfileMgr() initializing file-based block storage for ledger: comunitychannel 
[36m2019-01-29 10:51:52.059 UTC [kvledger.util] CreateDirIfMissing -> DEBU 027[0m CreateDirIfMissing [/var/hyperledger/production/orderer/chains/comunitychannel/]
[36m2019-01-29 10:51:52.059 UTC [kvledger.util] logDirStatus -> DEBU 028[0m Before creating dir - [/var/hyperledger/production/orderer/chains/comunitychannel/] exists
[36m2019-01-29 10:51:52.059 UTC [kvledger.util] logDirStatus -> DEBU 029[0m After creating dir - [/var/hyperledger/production/orderer/chains/comunitychannel/] exists
[36m2019-01-29 10:51:52.060 UTC [fsblkstorage] loadCurrentInfo -> DEBU 02a[0m loaded checkpointInfo:latestFileChunkSuffixNum=[0], latestFileChunksize=[21745], isChainEmpty=[false], lastBlockNumber=[0]
[36m2019-01-29 10:51:52.060 UTC [fsblkstorage] newBlockfileMgr -> DEBU 02b[0m Synching block information from block storage (if needed)
[36m2019-01-29 10:51:52.060 UTC [fsblkstorage] syncCPInfoFromFS -> DEBU 02c[0m Starting checkpoint=latestFileChunkSuffixNum=[0], latestFileChunksize=[21745], isChainEmpty=[false], lastBlockNumber=[0]
[36m2019-01-29 10:51:52.060 UTC [fsblkstorage] syncCPInfoFromFS -> DEBU 02d[0m status of file [/var/hyperledger/production/orderer/chains/comunitychannel/blockfile_000000]: exists=[true], size=[21745]
[36m2019-01-29 10:51:52.062 UTC [fsblkstorage] newBlockIndex -> DEBU 02e[0m newBlockIndex() - indexItems:[[BlockNum]]
[36m2019-01-29 10:51:52.062 UTC [fsblkstorage] syncIndex -> DEBU 02f[0m Both the block files and indices are in sync.
[36m2019-01-29 10:51:52.062 UTC [fsblkstorage] retrieveBlockHeaderByNumber -> DEBU 030[0m retrieveBlockHeaderByNumber() - blockNum = [0]
[36m2019-01-29 10:51:52.062 UTC [fsblkstorage] newBlockfileStream -> DEBU 031[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/comunitychannel/blockfile_000000], startOffset=[0]
[36m2019-01-29 10:51:52.062 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 032[0m Remaining bytes=[21745], Going to peek [8] bytes
[36m2019-01-29 10:51:52.062 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 033[0m Returning blockbytes - length=[21742], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 10:51:52.062 UTC [fsblkstorage] Next -> DEBU 034[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=0
[36m2019-01-29 10:51:52.062 UTC [fsblkstorage] newBlockfileStream -> DEBU 035[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/comunitychannel/blockfile_000000], startOffset=[0]
[36m2019-01-29 10:51:52.062 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 036[0m Remaining bytes=[21745], Going to peek [8] bytes
[36m2019-01-29 10:51:52.062 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 037[0m Returning blockbytes - length=[21742], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 10:51:52.062 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 038[0m blockbytes [21742] read from file [0]
[36m2019-01-29 10:51:52.062 UTC [fsblkstorage] Next -> DEBU 039[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=0
[36m2019-01-29 10:51:52.063 UTC [fsblkstorage] newBlockfileStream -> DEBU 03a[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/comunitychannel/blockfile_000000], startOffset=[0]
[36m2019-01-29 10:51:52.063 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 03b[0m Remaining bytes=[21745], Going to peek [8] bytes
[36m2019-01-29 10:51:52.063 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 03c[0m Returning blockbytes - length=[21742], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 10:51:52.063 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 03d[0m blockbytes [21742] read from file [0]
[36m2019-01-29 10:51:52.063 UTC [common/channelconfig] NewStandardValues -> DEBU 03e[0m Initializing protos for *channelconfig.ChannelProtos
[36m2019-01-29 10:51:52.063 UTC [common/channelconfig] initializeProtosStruct -> DEBU 03f[0m Processing field: HashingAlgorithm
[36m2019-01-29 10:51:52.063 UTC [common/channelconfig] initializeProtosStruct -> DEBU 040[0m Processing field: BlockDataHashingStructure
[36m2019-01-29 10:51:52.063 UTC [common/channelconfig] initializeProtosStruct -> DEBU 041[0m Processing field: OrdererAddresses
[36m2019-01-29 10:51:52.063 UTC [common/channelconfig] initializeProtosStruct -> DEBU 042[0m Processing field: Consortium
[36m2019-01-29 10:51:52.063 UTC [common/channelconfig] initializeProtosStruct -> DEBU 043[0m Processing field: Capabilities
[36m2019-01-29 10:51:52.063 UTC [common/channelconfig] NewStandardValues -> DEBU 044[0m Initializing protos for *channelconfig.OrdererProtos
[36m2019-01-29 10:51:52.063 UTC [common/channelconfig] initializeProtosStruct -> DEBU 045[0m Processing field: ConsensusType
[36m2019-01-29 10:51:52.063 UTC [common/channelconfig] initializeProtosStruct -> DEBU 046[0m Processing field: BatchSize
[36m2019-01-29 10:51:52.063 UTC [common/channelconfig] initializeProtosStruct -> DEBU 047[0m Processing field: BatchTimeout
[36m2019-01-29 10:51:52.063 UTC [common/channelconfig] initializeProtosStruct -> DEBU 048[0m Processing field: KafkaBrokers
[36m2019-01-29 10:51:52.063 UTC [common/channelconfig] initializeProtosStruct -> DEBU 049[0m Processing field: ChannelRestrictions
[36m2019-01-29 10:51:52.063 UTC [common/channelconfig] initializeProtosStruct -> DEBU 04a[0m Processing field: Capabilities
[36m2019-01-29 10:51:52.064 UTC [common/channelconfig] NewStandardValues -> DEBU 04b[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:51:52.064 UTC [common/channelconfig] initializeProtosStruct -> DEBU 04c[0m Processing field: MSP
[36m2019-01-29 10:51:52.064 UTC [common/channelconfig] validateMSP -> DEBU 04d[0m Setting up MSP for org OrdererOrg
[36m2019-01-29 10:51:52.064 UTC [msp] newBccspMsp -> DEBU 04e[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:51:52.064 UTC [msp] New -> DEBU 04f[0m Creating Cache-MSP instance
[36m2019-01-29 10:51:52.064 UTC [msp] Setup -> DEBU 050[0m Setting up MSP instance OrdererMSP
[36m2019-01-29 10:51:52.064 UTC [msp/identity] newIdentity -> DEBU 051[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICSzCCAfKgAwIBAgIRAO7EFp+tGDrZX/4Yn1ExG4IwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowdzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEe
MBwGA1UEAxMVY2Euc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZI
zj0DAQcDQgAE+ci0VrQQEnBN2VlYMEvGL0RvqwQ9zVhgyxdKDi9AB8iyQ0dhyWzJ
CZ9MnAWGk29pw9b+9HdNkbalpJKWkcctJ6NfMF0wDgYDVR0PAQH/BAQDAgGmMA8G
A1UdJQQIMAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgGIY2e0Pm
0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDRwAwRAIgcoBa
RHN5r57Qu7sd8TwCzfyJI+uozczAYI2SsN06iKgCIAeAP4FbTHxjqSLcNZMNGbTZ
YWA1h+rDBMa99duId/0D
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.064 UTC [msp/identity] newIdentity -> DEBU 052[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICHzCCAcWgAwIBAgIQRo5Qm6m11gCv1i2SXwRJAjAKBggqhkjOPQQDAjB3MQsw
CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy
YW5jaXNjbzEbMBkGA1UEChMSc3dpdGNoMmxvZ2ljLmNvLnphMR4wHAYDVQQDExVj
YS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkwMTI5MDc0MTU0WhcNMjkwMTI2MDc0
MTU0WjBdMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UE
BxMNU2FuIEZyYW5jaXNjbzEhMB8GA1UEAwwYQWRtaW5Ac3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE0QeSwnrMZdy7TKSYF/JzQ12C
vfINZcjx7xyeUuj/96gj42fjc1ctn7oo/tDl1eJNZbDhFvkRzefYmxtoSnH5Y6NN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgGIY2
e0Pm0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDSAAwRQIh
AM8EkjCZIKrAf9sL1d1fThizng+66jmEVlKPbTpimVbiAiAhCJZoeBIJGcgxbCr2
5Rd2IW34zWcPhemkNZvCKv27WA==
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.065 UTC [msp] Validate -> DEBU 053[0m MSP OrdererMSP validating identity
[36m2019-01-29 10:51:52.065 UTC [common/channelconfig] NewStandardValues -> DEBU 054[0m Initializing protos for *channelconfig.ApplicationProtos
[36m2019-01-29 10:51:52.065 UTC [common/channelconfig] initializeProtosStruct -> DEBU 055[0m Processing field: ACLs
[36m2019-01-29 10:51:52.065 UTC [common/channelconfig] initializeProtosStruct -> DEBU 056[0m Processing field: Capabilities
[36m2019-01-29 10:51:52.065 UTC [common/channelconfig] NewStandardValues -> DEBU 057[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 10:51:52.065 UTC [common/channelconfig] initializeProtosStruct -> DEBU 058[0m Processing field: AnchorPeers
[36m2019-01-29 10:51:52.065 UTC [common/channelconfig] NewStandardValues -> DEBU 059[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:51:52.065 UTC [common/channelconfig] initializeProtosStruct -> DEBU 05a[0m Processing field: MSP
[36m2019-01-29 10:51:52.065 UTC [common/channelconfig] Validate -> DEBU 05b[0m Anchor peers for org Hospital2MSP are 
[36m2019-01-29 10:51:52.066 UTC [common/channelconfig] validateMSP -> DEBU 05c[0m Setting up MSP for org Hospital2MSP
[36m2019-01-29 10:51:52.066 UTC [msp] newBccspMsp -> DEBU 05d[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:51:52.066 UTC [msp] New -> DEBU 05e[0m Creating Cache-MSP instance
[36m2019-01-29 10:51:52.066 UTC [msp] Setup -> DEBU 05f[0m Setting up MSP instance Hospital2MSP
[36m2019-01-29 10:51:52.067 UTC [msp/identity] newIdentity -> DEBU 060[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdjCCAhygAwIBAgIRALZ3Pffn/xWUtUWPSK6CYVAwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFowgYsxCzAJBgNVBAYTAlVTMRMwEQYD
VQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4gRnJhbmNpc2NvMSUwIwYDVQQK
Exxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMSgwJgYDVQQDEx9jYS5ob3Nw
aXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcD
QgAESzVpiz6P4mIb+KwvrttcXJKZR5i137Is4298E7OrkYdAg0tB4rpfKTXzUMwW
vI12cTDujpyaZSiqQ3/zP4fOQqNfMF0wDgYDVR0PAQH/BAQDAgGmMA8GA1UdJQQI
MAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQg8QJqWKPaX24HINwR
S6sINFSwRD+440/ccSnvFVaGF24wCgYIKoZIzj0EAwIDSAAwRQIhAPO2Nng3/nqb
cKPliUqVPVjBMu+D55M90+jexWSOpkjcAiADPx8qv9exZ4BfP3+G49Qzpx0Meblj
53vzUgYFa/0EXw==
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.067 UTC [msp/identity] newIdentity -> DEBU 061[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAJ6XtHMTTW1JzdpD54qCc3wwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwyLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABA+z1rb9aA1HwHfNLi9V9VZe
bdwT4MXak445zGz4DXzRUsmNeBngzntKb6qpgHQpeFtzbzLx+zwiynRDvfdzORGj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIPEC
alij2l9uByDcEUurCDRUsEQ/uONP3HEp7xVWhhduMAoGCCqGSM49BAMCA0cAMEQC
IA8A3CCJeCasyy7gYd/M1aHYmwWsecY7UY7cVUGy4XOxAiB0rrmfnGW6JA11PDCu
+5c5Rpn0jF5ddsFn+UIpzBFvmg==
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.068 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 062[0m Checking if identity satisfies role [CLIENT] for Hospital2MSP
[36m2019-01-29 10:51:52.068 UTC [msp] Validate -> DEBU 063[0m MSP Hospital2MSP validating identity
[36m2019-01-29 10:51:52.068 UTC [msp] getCertificationChain -> DEBU 064[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 10:51:52.069 UTC [msp] hasOURole -> DEBU 065[0m MSP Hospital2MSP checking if the identity is a client
[36m2019-01-29 10:51:52.069 UTC [msp] getCertificationChain -> DEBU 066[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 10:51:52.069 UTC [common/channelconfig] NewStandardValues -> DEBU 067[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 10:51:52.069 UTC [common/channelconfig] initializeProtosStruct -> DEBU 068[0m Processing field: AnchorPeers
[36m2019-01-29 10:51:52.069 UTC [common/channelconfig] NewStandardValues -> DEBU 069[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:51:52.069 UTC [common/channelconfig] initializeProtosStruct -> DEBU 06a[0m Processing field: MSP
[36m2019-01-29 10:51:52.069 UTC [common/channelconfig] Validate -> DEBU 06b[0m Anchor peers for org Hospital3MSP are 
[36m2019-01-29 10:51:52.069 UTC [common/channelconfig] validateMSP -> DEBU 06c[0m Setting up MSP for org Hospital3MSP
[36m2019-01-29 10:51:52.069 UTC [msp] newBccspMsp -> DEBU 06d[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:51:52.069 UTC [msp] New -> DEBU 06e[0m Creating Cache-MSP instance
[36m2019-01-29 10:51:52.069 UTC [msp] Setup -> DEBU 06f[0m Setting up MSP instance Hospital3MSP
[36m2019-01-29 10:51:52.070 UTC [msp/identity] newIdentity -> DEBU 070[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdTCCAhugAwIBAgIQCCXeHGgObIJo8aq4AdvgVjAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMy5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQm1Oo/AEu7ZZToE15Y5ntlaN128Hs/exX3jNH5nO6r4tvyFtBBNEn1ecXxxPtm
dmQ+nPHONorLwDC42SMAKwfro18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCA7vVWFXWpgZBojQ1ZL
xUvgBLeia59MivIRcjxmYanpyTAKBggqhkjOPQQDAgNIADBFAiEAlOUoPtpfO8V7
vFRCanjU5zZWGO5ajFlPDJjjDTy3UrwCICrUYV32JrR/m3dslCl15dSThHrKtYCC
Ehvyw1+lNqiG
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.070 UTC [msp/identity] newIdentity -> DEBU 071[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAI8BA/5Jf+5m8ncI+D7aSiMwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwzLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABF1IehIKIjh8tXYZ7rw4QOuc
g/tpBAkJeOt44zr/LepbjhyFW8vIRnkw75i6Wcg+LOoAS+2NFNg2oNjqg//yCHWj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIDu9
VYVdamBkGiNDVkvFS+AEt6Jrn0yK8hFyPGZhqenJMAoGCCqGSM49BAMCA0cAMEQC
IFyc85pwbCAxGNdw4fflsX2I3HrP3h93YAB2zSDC8HtkAiAQxblAZfEnXUiQKrqE
8I10bYJqD6pJz1jb3Pv+4xplTA==
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.071 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 072[0m Checking if identity satisfies role [CLIENT] for Hospital3MSP
[36m2019-01-29 10:51:52.071 UTC [msp] Validate -> DEBU 073[0m MSP Hospital3MSP validating identity
[36m2019-01-29 10:51:52.071 UTC [msp] getCertificationChain -> DEBU 074[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 10:51:52.071 UTC [msp] hasOURole -> DEBU 075[0m MSP Hospital3MSP checking if the identity is a client
[36m2019-01-29 10:51:52.071 UTC [msp] getCertificationChain -> DEBU 076[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 10:51:52.071 UTC [common/channelconfig] NewStandardValues -> DEBU 077[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 10:51:52.071 UTC [common/channelconfig] initializeProtosStruct -> DEBU 078[0m Processing field: AnchorPeers
[36m2019-01-29 10:51:52.072 UTC [common/channelconfig] NewStandardValues -> DEBU 079[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:51:52.072 UTC [common/channelconfig] initializeProtosStruct -> DEBU 07a[0m Processing field: MSP
[36m2019-01-29 10:51:52.072 UTC [common/channelconfig] Validate -> DEBU 07b[0m Anchor peers for org Hospital1MSP are 
[36m2019-01-29 10:51:52.072 UTC [common/channelconfig] validateMSP -> DEBU 07c[0m Setting up MSP for org Hospital1MSP
[36m2019-01-29 10:51:52.072 UTC [msp] newBccspMsp -> DEBU 07d[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:51:52.072 UTC [msp] New -> DEBU 07e[0m Creating Cache-MSP instance
[36m2019-01-29 10:51:52.072 UTC [msp] Setup -> DEBU 07f[0m Setting up MSP instance Hospital1MSP
[36m2019-01-29 10:51:52.072 UTC [msp/identity] newIdentity -> DEBU 080[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdDCCAhugAwIBAgIQZxH8VsnceZxXgKxlURLgVTAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMS5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQX9V4k/h/3pFxByKDscjgQrC0YS/bSbKvzSG2Z2PvltEWp40qB9OaKUN0GQYzo
yK2Etdvyjfd1OFwaTjpGSvv9o18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCBVU7DoP9Msf/nNTNl6
5FxwAXZ82eaGBT7zWYdyh4QbBjAKBggqhkjOPQQDAgNHADBEAiBmXGWQbxCGRp0c
5/y9qJyciB1CDHsknRZDjNzt5f563wIgMy7VPi1R8DpIIIRN9B3mfhDpRa+J+8PA
S4DOJy7rjp4=
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.072 UTC [msp/identity] newIdentity -> DEBU 081[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfWgAwIBAgIQbzxpSKiuJCzDiDlZp+XbWDAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjB4MQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZyYW5jaXNjbzEPMA0GA1UECxMG
Y2xpZW50MSswKQYDVQQDDCJBZG1pbkBob3NwaXRhbDEuc3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEnpADl8+aUBcVWv6q3IgMQ4yg
ISawQ0wamHmpSv+/b1B5hf4V2HyoPrawIr45+o4/Qz++WazZlyY7PkoT27r7KaNN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgVVOw
6D/TLH/5zUzZeuRccAF2fNnmhgU+81mHcoeEGwYwCgYIKoZIzj0EAwIDSAAwRQIh
ALavdMm9i6xSsnWdlliMh10s6dmGBaXO0CxaCowLJIMtAiBEduudGJymDDE1zbiX
YwX83cYWZHUcYV8IXeZPFymC+w==
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.073 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 082[0m Checking if identity satisfies role [CLIENT] for Hospital1MSP
[36m2019-01-29 10:51:52.073 UTC [msp] Validate -> DEBU 083[0m MSP Hospital1MSP validating identity
[36m2019-01-29 10:51:52.073 UTC [msp] getCertificationChain -> DEBU 084[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 10:51:52.073 UTC [msp] hasOURole -> DEBU 085[0m MSP Hospital1MSP checking if the identity is a client
[36m2019-01-29 10:51:52.073 UTC [msp] getCertificationChain -> DEBU 086[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 10:51:52.073 UTC [msp] Setup -> DEBU 087[0m Setting up the MSP manager (4 msps)
[36m2019-01-29 10:51:52.073 UTC [msp] Setup -> DEBU 088[0m MSP manager setup complete, setup 4 msps
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 089[0m Proposed new policy Admins for Channel/Application/Hospital1MSP
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 08a[0m Proposed new policy Readers for Channel/Application/Hospital1MSP
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 08b[0m Proposed new policy Writers for Channel/Application/Hospital1MSP
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 08c[0m Proposed new policy Readers for Channel/Application/Hospital2MSP
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 08d[0m Proposed new policy Writers for Channel/Application/Hospital2MSP
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 08e[0m Proposed new policy Admins for Channel/Application/Hospital2MSP
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 08f[0m Proposed new policy Admins for Channel/Application/Hospital3MSP
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 090[0m Proposed new policy Readers for Channel/Application/Hospital3MSP
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 091[0m Proposed new policy Writers for Channel/Application/Hospital3MSP
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 092[0m Proposed new policy Writers for Channel/Application
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 093[0m Proposed new policy Admins for Channel/Application
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 094[0m Proposed new policy Readers for Channel/Application
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 095[0m Proposed new policy Readers for Channel/Orderer/OrdererOrg
[36m2019-01-29 10:51:52.073 UTC [policies] NewManagerImpl -> DEBU 096[0m Proposed new policy Writers for Channel/Orderer/OrdererOrg
[36m2019-01-29 10:51:52.074 UTC [policies] NewManagerImpl -> DEBU 097[0m Proposed new policy Admins for Channel/Orderer/OrdererOrg
[36m2019-01-29 10:51:52.074 UTC [policies] NewManagerImpl -> DEBU 098[0m Proposed new policy Writers for Channel/Orderer
[36m2019-01-29 10:51:52.074 UTC [policies] NewManagerImpl -> DEBU 099[0m Proposed new policy BlockValidation for Channel/Orderer
[36m2019-01-29 10:51:52.074 UTC [policies] NewManagerImpl -> DEBU 09a[0m Proposed new policy Admins for Channel/Orderer
[36m2019-01-29 10:51:52.074 UTC [policies] NewManagerImpl -> DEBU 09b[0m Proposed new policy Readers for Channel/Orderer
[36m2019-01-29 10:51:52.074 UTC [policies] NewManagerImpl -> DEBU 09c[0m Proposed new policy Readers for Channel
[36m2019-01-29 10:51:52.074 UTC [policies] NewManagerImpl -> DEBU 09d[0m Proposed new policy Writers for Channel
[36m2019-01-29 10:51:52.074 UTC [policies] NewManagerImpl -> DEBU 09e[0m Proposed new policy Admins for Channel
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 09f[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0a0[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0a1[0m Adding to config map: [Group]  /Channel/Application/Hospital1MSP
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0a2[0m Adding to config map: [Value]  /Channel/Application/Hospital1MSP/MSP
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0a3[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Admins
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0a4[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Readers
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0a5[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Writers
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0a6[0m Adding to config map: [Group]  /Channel/Application/Hospital2MSP
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0a7[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/MSP
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0a8[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0a9[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0aa[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0ab[0m Adding to config map: [Group]  /Channel/Application/Hospital3MSP
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0ac[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/MSP
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0ad[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Admins
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0ae[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Readers
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0af[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Writers
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0b0[0m Adding to config map: [Value]  /Channel/Application/Capabilities
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0b1[0m Adding to config map: [Policy] /Channel/Application/Writers
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0b2[0m Adding to config map: [Policy] /Channel/Application/Admins
[36m2019-01-29 10:51:52.074 UTC [common/configtx] addToMap -> DEBU 0b3[0m Adding to config map: [Policy] /Channel/Application/Readers
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0b4[0m Adding to config map: [Group]  /Channel/Orderer
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0b5[0m Adding to config map: [Group]  /Channel/Orderer/OrdererOrg
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0b6[0m Adding to config map: [Value]  /Channel/Orderer/OrdererOrg/MSP
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0b7[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Writers
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0b8[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Admins
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0b9[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Readers
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0ba[0m Adding to config map: [Value]  /Channel/Orderer/BatchTimeout
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0bb[0m Adding to config map: [Value]  /Channel/Orderer/ChannelRestrictions
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0bc[0m Adding to config map: [Value]  /Channel/Orderer/Capabilities
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0bd[0m Adding to config map: [Value]  /Channel/Orderer/KafkaBrokers
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0be[0m Adding to config map: [Value]  /Channel/Orderer/ConsensusType
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0bf[0m Adding to config map: [Value]  /Channel/Orderer/BatchSize
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0c0[0m Adding to config map: [Policy] /Channel/Orderer/Writers
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0c1[0m Adding to config map: [Policy] /Channel/Orderer/BlockValidation
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0c2[0m Adding to config map: [Policy] /Channel/Orderer/Admins
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0c3[0m Adding to config map: [Policy] /Channel/Orderer/Readers
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0c4[0m Adding to config map: [Value]  /Channel/Consortium
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0c5[0m Adding to config map: [Value]  /Channel/HashingAlgorithm
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0c6[0m Adding to config map: [Value]  /Channel/BlockDataHashingStructure
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0c7[0m Adding to config map: [Value]  /Channel/OrdererAddresses
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0c8[0m Adding to config map: [Value]  /Channel/Capabilities
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0c9[0m Adding to config map: [Policy] /Channel/Writers
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0ca[0m Adding to config map: [Policy] /Channel/Admins
[36m2019-01-29 10:51:52.075 UTC [common/configtx] addToMap -> DEBU 0cb[0m Adding to config map: [Policy] /Channel/Readers
[36m2019-01-29 10:51:52.075 UTC [common/channelconfig] LogSanityChecks -> DEBU 0cc[0m As expected, current configuration has policy '/Channel/Readers'
[36m2019-01-29 10:51:52.075 UTC [common/channelconfig] LogSanityChecks -> DEBU 0cd[0m As expected, current configuration has policy '/Channel/Writers'
[36m2019-01-29 10:51:52.075 UTC [policies] Manager -> DEBU 0ce[0m Manager Channel looking up path [Application]
[36m2019-01-29 10:51:52.075 UTC [policies] Manager -> DEBU 0cf[0m Manager Channel has managers Application
[36m2019-01-29 10:51:52.075 UTC [policies] Manager -> DEBU 0d0[0m Manager Channel has managers Orderer
[36m2019-01-29 10:51:52.076 UTC [policies] Manager -> DEBU 0d1[0m Manager Channel/Application looking up path []
[36m2019-01-29 10:51:52.076 UTC [policies] Manager -> DEBU 0d2[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 10:51:52.076 UTC [policies] Manager -> DEBU 0d3[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 10:51:52.076 UTC [policies] Manager -> DEBU 0d4[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 10:51:52.076 UTC [common/channelconfig] LogSanityChecks -> DEBU 0d5[0m As expected, current configuration has policy '/Channel/Application/Readers'
[36m2019-01-29 10:51:52.076 UTC [common/channelconfig] LogSanityChecks -> DEBU 0d6[0m As expected, current configuration has policy '/Channel/Application/Writers'
[36m2019-01-29 10:51:52.076 UTC [common/channelconfig] LogSanityChecks -> DEBU 0d7[0m As expected, current configuration has policy '/Channel/Application/Admins'
[36m2019-01-29 10:51:52.076 UTC [policies] Manager -> DEBU 0d8[0m Manager Channel looking up path [Orderer]
[36m2019-01-29 10:51:52.076 UTC [policies] Manager -> DEBU 0d9[0m Manager Channel has managers Application
[36m2019-01-29 10:51:52.076 UTC [policies] Manager -> DEBU 0da[0m Manager Channel has managers Orderer
[36m2019-01-29 10:51:52.076 UTC [policies] Manager -> DEBU 0db[0m Manager Channel/Orderer looking up path []
[36m2019-01-29 10:51:52.076 UTC [policies] Manager -> DEBU 0dc[0m Manager Channel/Orderer has managers OrdererOrg
[36m2019-01-29 10:51:52.076 UTC [common/channelconfig] LogSanityChecks -> DEBU 0dd[0m As expected, current configuration has policy '/Channel/Orderer/BlockValidation'
[36m2019-01-29 10:51:52.076 UTC [common/capabilities] Supported -> DEBU 0de[0m Orderer capability V1_1 is supported and is enabled
[36m2019-01-29 10:51:52.076 UTC [common/capabilities] Supported -> DEBU 0df[0m Channel capability V1_1 is supported and is enabled
[36m2019-01-29 10:51:52.076 UTC [orderer/commmon/multichannel] NewRegistrar -> DEBU 0e0[0m Starting chain: comunitychannel
[36m2019-01-29 10:51:52.076 UTC [fsblkstorage] Next -> DEBU 0e1[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=0
[36m2019-01-29 10:51:52.076 UTC [fsblkstorage] newBlockfileStream -> DEBU 0e2[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/comunitychannel/blockfile_000000], startOffset=[0]
[36m2019-01-29 10:51:52.076 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0e3[0m Remaining bytes=[21745], Going to peek [8] bytes
[36m2019-01-29 10:51:52.076 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0e4[0m Returning blockbytes - length=[21742], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 10:51:52.076 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0e5[0m blockbytes [21742] read from file [0]
[36m2019-01-29 10:51:52.076 UTC [orderer/commmon/multichannel] newBlockWriter -> DEBU 0e6[0m [channel: comunitychannel] Creating block writer for tip of chain (blockNumber=0, lastConfigBlockNum=0, lastConfigSeq=1)
2019-01-29 10:51:52.076 UTC [orderer/consensus/kafka] newChain -> INFO 0e7[0m [channel: comunitychannel] Starting chain with last persisted offset -3 and last recorded block 0
[36m2019-01-29 10:51:52.076 UTC [orderer/commmon/multichannel] newChainSupport -> DEBU 0e8[0m [channel: comunitychannel] Done creating channel support resources
[36m2019-01-29 10:51:52.076 UTC [fsblkstorage] newBlockfileMgr -> DEBU 0e9[0m newBlockfileMgr() initializing file-based block storage for ledger: testchainid 
[36m2019-01-29 10:51:52.076 UTC [kvledger.util] CreateDirIfMissing -> DEBU 0ea[0m CreateDirIfMissing [/var/hyperledger/production/orderer/chains/testchainid/]
[36m2019-01-29 10:51:52.076 UTC [kvledger.util] logDirStatus -> DEBU 0ec[0m Before creating dir - [/var/hyperledger/production/orderer/chains/testchainid/] exists
2019-01-29 10:51:52.076 UTC [orderer/consensus/kafka] setupProducerForChannel -> INFO 0eb[0m [channel: comunitychannel] Setting up the producer for this channel...
[36m2019-01-29 10:51:52.076 UTC [kvledger.util] logDirStatus -> DEBU 0ed[0m After creating dir - [/var/hyperledger/production/orderer/chains/testchainid/] exists
[36m2019-01-29 10:51:52.076 UTC [orderer/consensus/kafka] try -> DEBU 0ee[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:51:52.076 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 0ef[0m Initializing new client
[36m2019-01-29 10:51:52.076 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 0f0[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.076 UTC [fsblkstorage] loadCurrentInfo -> DEBU 0f1[0m loaded checkpointInfo:latestFileChunkSuffixNum=[0], latestFileChunksize=[43120], isChainEmpty=[false], lastBlockNumber=[1]
[36m2019-01-29 10:51:52.076 UTC [fsblkstorage] newBlockfileMgr -> DEBU 0f2[0m Synching block information from block storage (if needed)
[36m2019-01-29 10:51:52.076 UTC [fsblkstorage] syncCPInfoFromFS -> DEBU 0f4[0m Starting checkpoint=latestFileChunkSuffixNum=[0], latestFileChunksize=[43120], isChainEmpty=[false], lastBlockNumber=[1]
[36m2019-01-29 10:51:52.076 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 0f3[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.076 UTC [fsblkstorage] syncCPInfoFromFS -> DEBU 0f5[0m status of file [/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000]: exists=[true], size=[43120]
[36m2019-01-29 10:51:52.076 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 0f6[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:51:52.078 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 0f7[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp 10.0.0.29:10092: connect: connection refused
[36m2019-01-29 10:51:52.078 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 0f8[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.29:10092: connect: connection refused
[36m2019-01-29 10:51:52.078 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 0f9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.078 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 0fa[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.078 UTC [fsblkstorage] newBlockIndex -> DEBU 0fb[0m newBlockIndex() - indexItems:[[BlockNum]]
[36m2019-01-29 10:51:52.078 UTC [fsblkstorage] syncIndex -> DEBU 0fc[0m Both the block files and indices are in sync.
[36m2019-01-29 10:51:52.078 UTC [fsblkstorage] retrieveBlockHeaderByNumber -> DEBU 0fd[0m retrieveBlockHeaderByNumber() - blockNum = [1]
[36m2019-01-29 10:51:52.078 UTC [fsblkstorage] newBlockfileStream -> DEBU 0fe[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[18495]
[36m2019-01-29 10:51:52.078 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 0ff[0m Remaining bytes=[24625], Going to peek [8] bytes
[36m2019-01-29 10:51:52.078 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 100[0m Returning blockbytes - length=[24622], placementInfo={fileNum=[0], startOffset=[18495], bytesOffset=[18498]}
[36m2019-01-29 10:51:52.078 UTC [fsblkstorage] Next -> DEBU 101[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=1
[36m2019-01-29 10:51:52.078 UTC [fsblkstorage] newBlockfileStream -> DEBU 102[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[18495]
[36m2019-01-29 10:51:52.079 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 103[0m Remaining bytes=[24625], Going to peek [8] bytes
[36m2019-01-29 10:51:52.079 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 104[0m Returning blockbytes - length=[24622], placementInfo={fileNum=[0], startOffset=[18495], bytesOffset=[18498]}
[36m2019-01-29 10:51:52.079 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 105[0m blockbytes [24622] read from file [0]
[36m2019-01-29 10:51:52.079 UTC [fsblkstorage] Next -> DEBU 106[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=1
[36m2019-01-29 10:51:52.079 UTC [fsblkstorage] newBlockfileStream -> DEBU 107[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[0]
[36m2019-01-29 10:51:52.079 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 108[0m Connected to broker at kafka0.switch2logic.co.za:9092 (unregistered)
[36m2019-01-29 10:51:52.079 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 109[0m Remaining bytes=[43120], Going to peek [8] bytes
[36m2019-01-29 10:51:52.079 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 10a[0m Returning blockbytes - length=[18492], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 10:51:52.079 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 10b[0m blockbytes [18492] read from file [0]
[36m2019-01-29 10:51:52.079 UTC [common/channelconfig] NewStandardValues -> DEBU 10c[0m Initializing protos for *channelconfig.ChannelProtos
[36m2019-01-29 10:51:52.079 UTC [common/channelconfig] initializeProtosStruct -> DEBU 10d[0m Processing field: HashingAlgorithm
[36m2019-01-29 10:51:52.079 UTC [common/channelconfig] initializeProtosStruct -> DEBU 10e[0m Processing field: BlockDataHashingStructure
[36m2019-01-29 10:51:52.079 UTC [common/channelconfig] initializeProtosStruct -> DEBU 10f[0m Processing field: OrdererAddresses
[36m2019-01-29 10:51:52.079 UTC [common/channelconfig] initializeProtosStruct -> DEBU 110[0m Processing field: Consortium
[36m2019-01-29 10:51:52.079 UTC [common/channelconfig] initializeProtosStruct -> DEBU 111[0m Processing field: Capabilities
[36m2019-01-29 10:51:52.079 UTC [common/channelconfig] NewStandardValues -> DEBU 112[0m Initializing protos for *channelconfig.ConsortiumProtos
[36m2019-01-29 10:51:52.079 UTC [common/channelconfig] initializeProtosStruct -> DEBU 113[0m Processing field: ChannelCreationPolicy
[36m2019-01-29 10:51:52.079 UTC [common/channelconfig] NewStandardValues -> DEBU 114[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:51:52.079 UTC [common/channelconfig] initializeProtosStruct -> DEBU 115[0m Processing field: MSP
[36m2019-01-29 10:51:52.079 UTC [common/channelconfig] validateMSP -> DEBU 116[0m Setting up MSP for org Hospital1MSP
[36m2019-01-29 10:51:52.079 UTC [msp] newBccspMsp -> DEBU 117[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:51:52.079 UTC [msp] New -> DEBU 118[0m Creating Cache-MSP instance
[36m2019-01-29 10:51:52.079 UTC [msp] Setup -> DEBU 119[0m Setting up MSP instance Hospital1MSP
[36m2019-01-29 10:51:52.080 UTC [msp/identity] newIdentity -> DEBU 11a[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdDCCAhugAwIBAgIQZxH8VsnceZxXgKxlURLgVTAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMS5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQX9V4k/h/3pFxByKDscjgQrC0YS/bSbKvzSG2Z2PvltEWp40qB9OaKUN0GQYzo
yK2Etdvyjfd1OFwaTjpGSvv9o18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCBVU7DoP9Msf/nNTNl6
5FxwAXZ82eaGBT7zWYdyh4QbBjAKBggqhkjOPQQDAgNHADBEAiBmXGWQbxCGRp0c
5/y9qJyciB1CDHsknRZDjNzt5f563wIgMy7VPi1R8DpIIIRN9B3mfhDpRa+J+8PA
S4DOJy7rjp4=
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.080 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 11b[0m client/brokers registered new broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.080 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 11c[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.080 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 11d[0m client/brokers registered new broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.080 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 11e[0m Successfully initialized new client
[36m2019-01-29 10:51:52.080 UTC [orderer/consensus/kafka] try -> DEBU 11f[0m [channel: comunitychannel] Error is nil, breaking the retry loop
2019-01-29 10:51:52.080 UTC [orderer/consensus/kafka] startThread -> INFO 120[0m [channel: comunitychannel] Producer set up successfully
2019-01-29 10:51:52.080 UTC [orderer/consensus/kafka] sendConnectMessage -> INFO 121[0m [channel: comunitychannel] About to post the CONNECT message...
[36m2019-01-29 10:51:52.080 UTC [msp/identity] newIdentity -> DEBU 122[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfWgAwIBAgIQbzxpSKiuJCzDiDlZp+XbWDAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjB4MQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZyYW5jaXNjbzEPMA0GA1UECxMG
Y2xpZW50MSswKQYDVQQDDCJBZG1pbkBob3NwaXRhbDEuc3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEnpADl8+aUBcVWv6q3IgMQ4yg
ISawQ0wamHmpSv+/b1B5hf4V2HyoPrawIr45+o4/Qz++WazZlyY7PkoT27r7KaNN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgVVOw
6D/TLH/5zUzZeuRccAF2fNnmhgU+81mHcoeEGwYwCgYIKoZIzj0EAwIDSAAwRQIh
ALavdMm9i6xSsnWdlliMh10s6dmGBaXO0CxaCowLJIMtAiBEduudGJymDDE1zbiX
YwX83cYWZHUcYV8IXeZPFymC+w==
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.080 UTC [orderer/consensus/kafka] try -> DEBU 123[0m [channel: comunitychannel] Attempting to post the CONNECT message...
[36m2019-01-29 10:51:52.080 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 124[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.080 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU 125[0m producer/broker/0 starting up
[36m2019-01-29 10:51:52.080 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU 126[0m producer/broker/0 state change to [open] on comunitychannel/0
[36m2019-01-29 10:51:52.081 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 127[0m Connected to broker at kafka0.switch2logic.co.za:9092 (registered as #0)
[36m2019-01-29 10:51:52.081 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 128[0m Checking if identity satisfies role [CLIENT] for Hospital1MSP
[36m2019-01-29 10:51:52.081 UTC [msp] Validate -> DEBU 129[0m MSP Hospital1MSP validating identity
[36m2019-01-29 10:51:52.081 UTC [msp] getCertificationChain -> DEBU 12a[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 10:51:52.081 UTC [msp] hasOURole -> DEBU 12b[0m MSP Hospital1MSP checking if the identity is a client
[36m2019-01-29 10:51:52.081 UTC [msp] getCertificationChain -> DEBU 12c[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 10:51:52.082 UTC [common/channelconfig] NewStandardValues -> DEBU 12d[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:51:52.082 UTC [common/channelconfig] initializeProtosStruct -> DEBU 12e[0m Processing field: MSP
[36m2019-01-29 10:51:52.082 UTC [common/channelconfig] validateMSP -> DEBU 12f[0m Setting up MSP for org Hospital2MSP
[36m2019-01-29 10:51:52.082 UTC [msp] newBccspMsp -> DEBU 130[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:51:52.082 UTC [msp] New -> DEBU 131[0m Creating Cache-MSP instance
[36m2019-01-29 10:51:52.082 UTC [msp] Setup -> DEBU 132[0m Setting up MSP instance Hospital2MSP
[36m2019-01-29 10:51:52.083 UTC [msp/identity] newIdentity -> DEBU 133[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdjCCAhygAwIBAgIRALZ3Pffn/xWUtUWPSK6CYVAwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFowgYsxCzAJBgNVBAYTAlVTMRMwEQYD
VQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4gRnJhbmNpc2NvMSUwIwYDVQQK
Exxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMSgwJgYDVQQDEx9jYS5ob3Nw
aXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcD
QgAESzVpiz6P4mIb+KwvrttcXJKZR5i137Is4298E7OrkYdAg0tB4rpfKTXzUMwW
vI12cTDujpyaZSiqQ3/zP4fOQqNfMF0wDgYDVR0PAQH/BAQDAgGmMA8GA1UdJQQI
MAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQg8QJqWKPaX24HINwR
S6sINFSwRD+440/ccSnvFVaGF24wCgYIKoZIzj0EAwIDSAAwRQIhAPO2Nng3/nqb
cKPliUqVPVjBMu+D55M90+jexWSOpkjcAiADPx8qv9exZ4BfP3+G49Qzpx0Meblj
53vzUgYFa/0EXw==
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.084 UTC [msp/identity] newIdentity -> DEBU 134[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAJ6XtHMTTW1JzdpD54qCc3wwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwyLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABA+z1rb9aA1HwHfNLi9V9VZe
bdwT4MXak445zGz4DXzRUsmNeBngzntKb6qpgHQpeFtzbzLx+zwiynRDvfdzORGj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIPEC
alij2l9uByDcEUurCDRUsEQ/uONP3HEp7xVWhhduMAoGCCqGSM49BAMCA0cAMEQC
IA8A3CCJeCasyy7gYd/M1aHYmwWsecY7UY7cVUGy4XOxAiB0rrmfnGW6JA11PDCu
+5c5Rpn0jF5ddsFn+UIpzBFvmg==
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.084 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 135[0m Checking if identity satisfies role [CLIENT] for Hospital2MSP
[36m2019-01-29 10:51:52.084 UTC [msp] Validate -> DEBU 136[0m MSP Hospital2MSP validating identity
[36m2019-01-29 10:51:52.085 UTC [msp] getCertificationChain -> DEBU 137[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 10:51:52.085 UTC [msp] hasOURole -> DEBU 138[0m MSP Hospital2MSP checking if the identity is a client
[36m2019-01-29 10:51:52.085 UTC [msp] getCertificationChain -> DEBU 139[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 10:51:52.086 UTC [orderer/consensus/kafka] try -> DEBU 13a[0m [channel: comunitychannel] Error is nil, breaking the retry loop
2019-01-29 10:51:52.086 UTC [orderer/consensus/kafka] startThread -> INFO 13c[0m [channel: comunitychannel] CONNECT message posted successfully
2019-01-29 10:51:52.086 UTC [orderer/consensus/kafka] setupParentConsumerForChannel -> INFO 13d[0m [channel: comunitychannel] Setting up the parent consumer for this channel...
[36m2019-01-29 10:51:52.086 UTC [common/channelconfig] NewStandardValues -> DEBU 13b[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:51:52.086 UTC [orderer/consensus/kafka] try -> DEBU 13e[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:51:52.086 UTC [orderer/consensus/kafka/sarama] NewConsumer -> DEBU 140[0m Initializing new client
[36m2019-01-29 10:51:52.086 UTC [common/channelconfig] initializeProtosStruct -> DEBU 13f[0m Processing field: MSP
[36m2019-01-29 10:51:52.086 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 141[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.086 UTC [common/channelconfig] validateMSP -> DEBU 142[0m Setting up MSP for org Hospital3MSP
[36m2019-01-29 10:51:52.086 UTC [msp] newBccspMsp -> DEBU 143[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:51:52.086 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 144[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.086 UTC [msp] New -> DEBU 145[0m Creating Cache-MSP instance
[36m2019-01-29 10:51:52.086 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 146[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:51:52.086 UTC [msp] Setup -> DEBU 147[0m Setting up MSP instance Hospital3MSP
[36m2019-01-29 10:51:52.086 UTC [msp/identity] newIdentity -> DEBU 148[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdTCCAhugAwIBAgIQCCXeHGgObIJo8aq4AdvgVjAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMy5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQm1Oo/AEu7ZZToE15Y5ntlaN128Hs/exX3jNH5nO6r4tvyFtBBNEn1ecXxxPtm
dmQ+nPHONorLwDC42SMAKwfro18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCA7vVWFXWpgZBojQ1ZL
xUvgBLeia59MivIRcjxmYanpyTAKBggqhkjOPQQDAgNIADBFAiEAlOUoPtpfO8V7
vFRCanjU5zZWGO5ajFlPDJjjDTy3UrwCICrUYV32JrR/m3dslCl15dSThHrKtYCC
Ehvyw1+lNqiG
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.087 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 149[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp 10.0.0.29:10092: connect: connection refused
[36m2019-01-29 10:51:52.087 UTC [msp/identity] newIdentity -> DEBU 14a[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAI8BA/5Jf+5m8ncI+D7aSiMwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwzLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABF1IehIKIjh8tXYZ7rw4QOuc
g/tpBAkJeOt44zr/LepbjhyFW8vIRnkw75i6Wcg+LOoAS+2NFNg2oNjqg//yCHWj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIDu9
VYVdamBkGiNDVkvFS+AEt6Jrn0yK8hFyPGZhqenJMAoGCCqGSM49BAMCA0cAMEQC
IFyc85pwbCAxGNdw4fflsX2I3HrP3h93YAB2zSDC8HtkAiAQxblAZfEnXUiQKrqE
8I10bYJqD6pJz1jb3Pv+4xplTA==
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.087 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 14b[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.29:10092: connect: connection refused
[36m2019-01-29 10:51:52.087 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 14c[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.087 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 14d[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:51:52.087 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 14e[0m Checking if identity satisfies role [CLIENT] for Hospital3MSP
[36m2019-01-29 10:51:52.087 UTC [msp] Validate -> DEBU 14f[0m MSP Hospital3MSP validating identity
[36m2019-01-29 10:51:52.087 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 150[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.28:11092: connect: connection refused
[36m2019-01-29 10:51:52.087 UTC [msp] getCertificationChain -> DEBU 151[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 10:51:52.087 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 152[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.28:11092: connect: connection refused
[36m2019-01-29 10:51:52.087 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 153[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.087 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 154[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.088 UTC [msp] hasOURole -> DEBU 155[0m MSP Hospital3MSP checking if the identity is a client
[36m2019-01-29 10:51:52.088 UTC [msp] getCertificationChain -> DEBU 156[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 10:51:52.088 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 157[0m Connected to broker at kafka0.switch2logic.co.za:9092 (unregistered)
[36m2019-01-29 10:51:52.088 UTC [common/channelconfig] NewStandardValues -> DEBU 158[0m Initializing protos for *channelconfig.OrdererProtos
[36m2019-01-29 10:51:52.088 UTC [common/channelconfig] initializeProtosStruct -> DEBU 159[0m Processing field: ConsensusType
[36m2019-01-29 10:51:52.088 UTC [common/channelconfig] initializeProtosStruct -> DEBU 15a[0m Processing field: BatchSize
[36m2019-01-29 10:51:52.088 UTC [common/channelconfig] initializeProtosStruct -> DEBU 15b[0m Processing field: BatchTimeout
[36m2019-01-29 10:51:52.088 UTC [common/channelconfig] initializeProtosStruct -> DEBU 15c[0m Processing field: KafkaBrokers
[36m2019-01-29 10:51:52.088 UTC [common/channelconfig] initializeProtosStruct -> DEBU 15d[0m Processing field: ChannelRestrictions
[36m2019-01-29 10:51:52.088 UTC [common/channelconfig] initializeProtosStruct -> DEBU 15e[0m Processing field: Capabilities
[36m2019-01-29 10:51:52.088 UTC [common/channelconfig] NewStandardValues -> DEBU 15f[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 10:51:52.088 UTC [common/channelconfig] initializeProtosStruct -> DEBU 160[0m Processing field: MSP
[36m2019-01-29 10:51:52.088 UTC [common/channelconfig] validateMSP -> DEBU 161[0m Setting up MSP for org OrdererOrg
[36m2019-01-29 10:51:52.088 UTC [msp] newBccspMsp -> DEBU 162[0m Creating BCCSP-based MSP instance
[36m2019-01-29 10:51:52.088 UTC [msp] New -> DEBU 163[0m Creating Cache-MSP instance
[36m2019-01-29 10:51:52.088 UTC [msp] Setup -> DEBU 164[0m Setting up MSP instance OrdererMSP
[36m2019-01-29 10:51:52.089 UTC [msp/identity] newIdentity -> DEBU 165[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICSzCCAfKgAwIBAgIRAO7EFp+tGDrZX/4Yn1ExG4IwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowdzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEe
MBwGA1UEAxMVY2Euc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZI
zj0DAQcDQgAE+ci0VrQQEnBN2VlYMEvGL0RvqwQ9zVhgyxdKDi9AB8iyQ0dhyWzJ
CZ9MnAWGk29pw9b+9HdNkbalpJKWkcctJ6NfMF0wDgYDVR0PAQH/BAQDAgGmMA8G
A1UdJQQIMAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgGIY2e0Pm
0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDRwAwRAIgcoBa
RHN5r57Qu7sd8TwCzfyJI+uozczAYI2SsN06iKgCIAeAP4FbTHxjqSLcNZMNGbTZ
YWA1h+rDBMa99duId/0D
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.089 UTC [msp/identity] newIdentity -> DEBU 166[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICHzCCAcWgAwIBAgIQRo5Qm6m11gCv1i2SXwRJAjAKBggqhkjOPQQDAjB3MQsw
CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy
YW5jaXNjbzEbMBkGA1UEChMSc3dpdGNoMmxvZ2ljLmNvLnphMR4wHAYDVQQDExVj
YS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkwMTI5MDc0MTU0WhcNMjkwMTI2MDc0
MTU0WjBdMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UE
BxMNU2FuIEZyYW5jaXNjbzEhMB8GA1UEAwwYQWRtaW5Ac3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE0QeSwnrMZdy7TKSYF/JzQ12C
vfINZcjx7xyeUuj/96gj42fjc1ctn7oo/tDl1eJNZbDhFvkRzefYmxtoSnH5Y6NN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgGIY2
e0Pm0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDSAAwRQIh
AM8EkjCZIKrAf9sL1d1fThizng+66jmEVlKPbTpimVbiAiAhCJZoeBIJGcgxbCr2
5Rd2IW34zWcPhemkNZvCKv27WA==
-----END CERTIFICATE-----
[36m2019-01-29 10:51:52.089 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 167[0m client/brokers registered new broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.089 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 168[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.089 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 169[0m client/brokers registered new broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.089 UTC [msp] Validate -> DEBU 16a[0m MSP OrdererMSP validating identity
[36m2019-01-29 10:51:52.089 UTC [orderer/consensus/kafka/sarama] NewConsumer -> DEBU 16b[0m Successfully initialized new client
[36m2019-01-29 10:51:52.089 UTC [orderer/consensus/kafka] try -> DEBU 16c[0m [channel: comunitychannel] Error is nil, breaking the retry loop
2019-01-29 10:51:52.089 UTC [orderer/consensus/kafka] startThread -> INFO 16d[0m [channel: comunitychannel] Parent consumer set up successfully
2019-01-29 10:51:52.089 UTC [orderer/consensus/kafka] setupChannelConsumerForChannel -> INFO 16e[0m [channel: comunitychannel] Setting up the channel consumer for this channel (start offset: -2)...
[36m2019-01-29 10:51:52.089 UTC [orderer/consensus/kafka] try -> DEBU 16f[0m [channel: comunitychannel] Connecting to the Kafka cluster
[36m2019-01-29 10:51:52.089 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 170[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.089 UTC [msp] Setup -> DEBU 171[0m Setting up the MSP manager (4 msps)
[36m2019-01-29 10:51:52.089 UTC [msp] Setup -> DEBU 172[0m MSP manager setup complete, setup 4 msps
[36m2019-01-29 10:51:52.089 UTC [policies] NewManagerImpl -> DEBU 173[0m Proposed new policy Admins for Channel/Consortiums/HospitalConsortium/Hospital1MSP
[36m2019-01-29 10:51:52.089 UTC [policies] NewManagerImpl -> DEBU 174[0m Proposed new policy Readers for Channel/Consortiums/HospitalConsortium/Hospital1MSP
[36m2019-01-29 10:51:52.089 UTC [policies] NewManagerImpl -> DEBU 175[0m Proposed new policy Writers for Channel/Consortiums/HospitalConsortium/Hospital1MSP
[36m2019-01-29 10:51:52.089 UTC [policies] NewManagerImpl -> DEBU 176[0m Proposed new policy Admins for Channel/Consortiums/HospitalConsortium/Hospital2MSP
[36m2019-01-29 10:51:52.089 UTC [policies] NewManagerImpl -> DEBU 177[0m Proposed new policy Readers for Channel/Consortiums/HospitalConsortium/Hospital2MSP
[36m2019-01-29 10:51:52.089 UTC [policies] NewManagerImpl -> DEBU 178[0m Proposed new policy Writers for Channel/Consortiums/HospitalConsortium/Hospital2MSP
[36m2019-01-29 10:51:52.089 UTC [policies] NewManagerImpl -> DEBU 179[0m Proposed new policy Admins for Channel/Consortiums/HospitalConsortium/Hospital3MSP
[36m2019-01-29 10:51:52.090 UTC [policies] NewManagerImpl -> DEBU 17a[0m Proposed new policy Readers for Channel/Consortiums/HospitalConsortium/Hospital3MSP
[36m2019-01-29 10:51:52.090 UTC [policies] NewManagerImpl -> DEBU 17b[0m Proposed new policy Writers for Channel/Consortiums/HospitalConsortium/Hospital3MSP
[36m2019-01-29 10:51:52.090 UTC [policies] NewManagerImpl -> DEBU 17c[0m Proposed new policy Admins for Channel/Consortiums
[36m2019-01-29 10:51:52.090 UTC [policies] NewManagerImpl -> DEBU 17d[0m Proposed new policy Readers for Channel/Orderer/OrdererOrg
[36m2019-01-29 10:51:52.090 UTC [policies] NewManagerImpl -> DEBU 17e[0m Proposed new policy Writers for Channel/Orderer/OrdererOrg
[36m2019-01-29 10:51:52.090 UTC [policies] NewManagerImpl -> DEBU 17f[0m Proposed new policy Admins for Channel/Orderer/OrdererOrg
[36m2019-01-29 10:51:52.090 UTC [policies] NewManagerImpl -> DEBU 180[0m Proposed new policy Readers for Channel/Orderer
[36m2019-01-29 10:51:52.090 UTC [policies] NewManagerImpl -> DEBU 181[0m Proposed new policy Writers for Channel/Orderer
[36m2019-01-29 10:51:52.090 UTC [policies] NewManagerImpl -> DEBU 182[0m Proposed new policy BlockValidation for Channel/Orderer
[36m2019-01-29 10:51:52.090 UTC [policies] NewManagerImpl -> DEBU 183[0m Proposed new policy Admins for Channel/Orderer
[36m2019-01-29 10:51:52.090 UTC [policies] GetPolicy -> DEBU 184[0m Returning dummy reject all policy because Readers could not be found in Channel/Consortiums/Readers
[36m2019-01-29 10:51:52.090 UTC [policies] NewManagerImpl -> DEBU 185[0m Proposed new policy Readers for Channel
[36m2019-01-29 10:51:52.090 UTC [policies] GetPolicy -> DEBU 186[0m Returning dummy reject all policy because Writers could not be found in Channel/Consortiums/Writers
[36m2019-01-29 10:51:52.090 UTC [policies] NewManagerImpl -> DEBU 187[0m Proposed new policy Writers for Channel
[36m2019-01-29 10:51:52.090 UTC [policies] NewManagerImpl -> DEBU 188[0m Proposed new policy Admins for Channel
[36m2019-01-29 10:51:52.090 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 189[0m Connected to broker at kafka0.switch2logic.co.za:9092 (registered as #0)
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 18a[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 18b[0m Adding to config map: [Group]  /Channel/Consortiums
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 18c[0m Adding to config map: [Group]  /Channel/Consortiums/HospitalConsortium
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 18d[0m Adding to config map: [Group]  /Channel/Consortiums/HospitalConsortium/Hospital1MSP
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 18e[0m Adding to config map: [Value]  /Channel/Consortiums/HospitalConsortium/Hospital1MSP/MSP
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 18f[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital1MSP/Admins
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 190[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital1MSP/Readers
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 191[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital1MSP/Writers
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 192[0m Adding to config map: [Group]  /Channel/Consortiums/HospitalConsortium/Hospital2MSP
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 193[0m Adding to config map: [Value]  /Channel/Consortiums/HospitalConsortium/Hospital2MSP/MSP
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 194[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital2MSP/Admins
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 195[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital2MSP/Readers
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 196[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital2MSP/Writers
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 197[0m Adding to config map: [Group]  /Channel/Consortiums/HospitalConsortium/Hospital3MSP
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 198[0m Adding to config map: [Value]  /Channel/Consortiums/HospitalConsortium/Hospital3MSP/MSP
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 199[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital3MSP/Admins
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 19a[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital3MSP/Readers
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 19b[0m Adding to config map: [Policy] /Channel/Consortiums/HospitalConsortium/Hospital3MSP/Writers
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 19c[0m Adding to config map: [Value]  /Channel/Consortiums/HospitalConsortium/ChannelCreationPolicy
[36m2019-01-29 10:51:52.090 UTC [common/configtx] addToMap -> DEBU 19d[0m Adding to config map: [Policy] /Channel/Consortiums/Admins
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 19e[0m Adding to config map: [Group]  /Channel/Orderer
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 19f[0m Adding to config map: [Group]  /Channel/Orderer/OrdererOrg
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1a0[0m Adding to config map: [Value]  /Channel/Orderer/OrdererOrg/MSP
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1a1[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Admins
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1a2[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Readers
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1a3[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Writers
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1a4[0m Adding to config map: [Value]  /Channel/Orderer/Capabilities
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1a5[0m Adding to config map: [Value]  /Channel/Orderer/KafkaBrokers
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1a6[0m Adding to config map: [Value]  /Channel/Orderer/ConsensusType
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1a7[0m Adding to config map: [Value]  /Channel/Orderer/BatchSize
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1a8[0m Adding to config map: [Value]  /Channel/Orderer/BatchTimeout
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1a9[0m Adding to config map: [Value]  /Channel/Orderer/ChannelRestrictions
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1aa[0m Adding to config map: [Policy] /Channel/Orderer/BlockValidation
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1ab[0m Adding to config map: [Policy] /Channel/Orderer/Admins
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1ac[0m Adding to config map: [Policy] /Channel/Orderer/Readers
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1ad[0m Adding to config map: [Policy] /Channel/Orderer/Writers
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1ae[0m Adding to config map: [Value]  /Channel/BlockDataHashingStructure
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1af[0m Adding to config map: [Value]  /Channel/OrdererAddresses
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1b0[0m Adding to config map: [Value]  /Channel/Capabilities
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1b1[0m Adding to config map: [Value]  /Channel/HashingAlgorithm
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1b2[0m Adding to config map: [Policy] /Channel/Readers
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1b3[0m Adding to config map: [Policy] /Channel/Writers
[36m2019-01-29 10:51:52.091 UTC [common/configtx] addToMap -> DEBU 1b4[0m Adding to config map: [Policy] /Channel/Admins
[36m2019-01-29 10:51:52.091 UTC [common/channelconfig] LogSanityChecks -> DEBU 1b5[0m As expected, current configuration has policy '/Channel/Readers'
[36m2019-01-29 10:51:52.092 UTC [common/channelconfig] LogSanityChecks -> DEBU 1b6[0m As expected, current configuration has policy '/Channel/Writers'
[36m2019-01-29 10:51:52.092 UTC [policies] Manager -> DEBU 1b7[0m Manager Channel looking up path [Application]
[36m2019-01-29 10:51:52.092 UTC [policies] Manager -> DEBU 1b8[0m Manager Channel has managers Consortiums
[36m2019-01-29 10:51:52.092 UTC [policies] Manager -> DEBU 1b9[0m Manager Channel has managers Orderer
[36m2019-01-29 10:51:52.092 UTC [policies] Manager -> DEBU 1ba[0m Manager Channel looking up path [Orderer]
[36m2019-01-29 10:51:52.092 UTC [policies] Manager -> DEBU 1bb[0m Manager Channel has managers Consortiums
[36m2019-01-29 10:51:52.092 UTC [policies] Manager -> DEBU 1bc[0m Manager Channel has managers Orderer
[36m2019-01-29 10:51:52.092 UTC [policies] Manager -> DEBU 1bd[0m Manager Channel/Orderer looking up path []
[36m2019-01-29 10:51:52.092 UTC [policies] Manager -> DEBU 1be[0m Manager Channel/Orderer has managers OrdererOrg
[36m2019-01-29 10:51:52.092 UTC [common/channelconfig] LogSanityChecks -> DEBU 1bf[0m As expected, current configuration has policy '/Channel/Orderer/BlockValidation'
[36m2019-01-29 10:51:52.092 UTC [common/capabilities] Supported -> DEBU 1c0[0m Orderer capability V1_1 is supported and is enabled
[36m2019-01-29 10:51:52.092 UTC [common/capabilities] Supported -> DEBU 1c1[0m Channel capability V1_1 is supported and is enabled
[36m2019-01-29 10:51:52.092 UTC [fsblkstorage] Next -> DEBU 1c2[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=1
[36m2019-01-29 10:51:52.092 UTC [fsblkstorage] newBlockfileStream -> DEBU 1c3[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[18495]
[36m2019-01-29 10:51:52.092 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 1c4[0m Remaining bytes=[24625], Going to peek [8] bytes
[36m2019-01-29 10:51:52.092 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 1c5[0m Returning blockbytes - length=[24622], placementInfo={fileNum=[0], startOffset=[18495], bytesOffset=[18498]}
[36m2019-01-29 10:51:52.092 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 1c6[0m blockbytes [24622] read from file [0]
[36m2019-01-29 10:51:52.092 UTC [orderer/commmon/multichannel] newBlockWriter -> DEBU 1c7[0m [channel: testchainid] Creating block writer for tip of chain (blockNumber=1, lastConfigBlockNum=0, lastConfigSeq=0)
2019-01-29 10:51:52.092 UTC [orderer/consensus/kafka] newChain -> INFO 1c8[0m [channel: testchainid] Starting chain with last persisted offset 5 and last recorded block 1
[36m2019-01-29 10:51:52.092 UTC [orderer/commmon/multichannel] newChainSupport -> DEBU 1ca[0m [channel: testchainid] Done creating channel support resources
[36m2019-01-29 10:51:52.092 UTC [orderer/consensus/kafka/sarama] subscriptionConsumer -> DEBU 1c9[0m consumer/broker/0 added subscription to comunitychannel/0
[36m2019-01-29 10:51:52.092 UTC [orderer/common/msgprocessor] NewSystemChannel -> DEBU 1cb[0m Creating system channel msg processor for channel testchainid
[36m2019-01-29 10:51:52.092 UTC [fsblkstorage] Next -> DEBU 1cc[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=1
[36m2019-01-29 10:51:52.092 UTC [fsblkstorage] newBlockfileStream -> DEBU 1ce[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/testchainid/blockfile_000000], startOffset=[0]
[36m2019-01-29 10:51:52.092 UTC [orderer/consensus/kafka] try -> DEBU 1cd[0m [channel: comunitychannel] Error is nil, breaking the retry loop
[36m2019-01-29 10:51:52.092 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 1cf[0m Remaining bytes=[43120], Going to peek [8] bytes
2019-01-29 10:51:52.093 UTC [orderer/consensus/kafka] startThread -> INFO 1d0[0m [channel: comunitychannel] Channel consumer set up successfully
2019-01-29 10:51:52.093 UTC [orderer/consensus/kafka] startThread -> INFO 1d1[0m [channel: comunitychannel] Start phase completed successfully
[36m2019-01-29 10:51:52.093 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 1d2[0m Returning blockbytes - length=[18492], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 10:51:52.093 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 1d3[0m blockbytes [18492] read from file [0]
2019-01-29 10:51:52.093 UTC [orderer/commmon/multichannel] NewRegistrar -> INFO 1d4[0m Starting system channel 'testchainid' with genesis block hash c84c51e50921c0294405e41d16cb6234273f63b37a240438cc9f32578277d7e3 and orderer type kafka
2019-01-29 10:51:52.093 UTC [orderer/common/server] Start -> INFO 1d5[0m Starting orderer:
 Version: 1.2.0
 Commit SHA: cae2ad4
 Go version: go1.10
 OS/Arch: linux/amd64
 Experimental features: false
2019-01-29 10:51:52.093 UTC [orderer/consensus/kafka] setupProducerForChannel -> INFO 1d6[0m [channel: testchainid] Setting up the producer for this channel...
2019-01-29 10:51:52.093 UTC [orderer/common/server] Start -> INFO 1d7[0m Beginning to serve requests
[36m2019-01-29 10:51:52.093 UTC [orderer/consensus/kafka] try -> DEBU 1d8[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:51:52.093 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 1d9[0m Initializing new client
[36m2019-01-29 10:51:52.093 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 1da[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.093 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1db[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.093 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1dc[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 1dd[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 0. Inspecting type...
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka] processConnect -> DEBU 1de[0m [channel: comunitychannel] It's a connect message - ignoring
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 1df[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 1. Inspecting type...
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka] processConnect -> DEBU 1e0[0m [channel: comunitychannel] It's a connect message - ignoring
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 1e1[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 2. Inspecting type...
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka] processConnect -> DEBU 1e2[0m [channel: comunitychannel] It's a connect message - ignoring
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 1e3[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 3. Inspecting type...
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka] processConnect -> DEBU 1e4[0m [channel: comunitychannel] It's a connect message - ignoring
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 1e5[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 4. Inspecting type...
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka] processConnect -> DEBU 1e6[0m [channel: comunitychannel] It's a connect message - ignoring
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1e7[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.28:11092: connect: connection refused
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1e8[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.28:11092: connect: connection refused
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1e9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.094 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1ea[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.095 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1eb[0m Connected to broker at kafka0.switch2logic.co.za:9092 (unregistered)
[36m2019-01-29 10:51:52.096 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 1ec[0m client/brokers registered new broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.099 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 1ed[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.099 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 1ee[0m client/brokers registered new broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.099 UTC [orderer/consensus/kafka/sarama] NewAsyncProducer -> DEBU 1ef[0m Successfully initialized new client
[36m2019-01-29 10:51:52.099 UTC [orderer/consensus/kafka] try -> DEBU 1f0[0m [channel: testchainid] Error is nil, breaking the retry loop
2019-01-29 10:51:52.099 UTC [orderer/consensus/kafka] startThread -> INFO 1f1[0m [channel: testchainid] Producer set up successfully
2019-01-29 10:51:52.099 UTC [orderer/consensus/kafka] sendConnectMessage -> INFO 1f2[0m [channel: testchainid] About to post the CONNECT message...
[36m2019-01-29 10:51:52.099 UTC [orderer/consensus/kafka] try -> DEBU 1f3[0m [channel: testchainid] Attempting to post the CONNECT message...
[36m2019-01-29 10:51:52.099 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1f4[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.099 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU 1f5[0m producer/broker/1 starting up
[36m2019-01-29 10:51:52.099 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU 1f6[0m producer/broker/1 state change to [open] on testchainid/0
[36m2019-01-29 10:51:52.100 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 1f7[0m Connected to broker at kafka1.switch2logic.co.za:9092 (registered as #1)
[36m2019-01-29 10:51:52.104 UTC [orderer/consensus/kafka] try -> DEBU 1f8[0m [channel: testchainid] Error is nil, breaking the retry loop
2019-01-29 10:51:52.104 UTC [orderer/consensus/kafka] startThread -> INFO 1f9[0m [channel: testchainid] CONNECT message posted successfully
2019-01-29 10:51:52.104 UTC [orderer/consensus/kafka] setupParentConsumerForChannel -> INFO 1fa[0m [channel: testchainid] Setting up the parent consumer for this channel...
[36m2019-01-29 10:51:52.104 UTC [orderer/consensus/kafka] try -> DEBU 1fb[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:51:52.104 UTC [orderer/consensus/kafka/sarama] NewConsumer -> DEBU 1fc[0m Initializing new client
[36m2019-01-29 10:51:52.104 UTC [orderer/consensus/kafka/sarama] NewClient -> DEBU 1fd[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.105 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 1fe[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.105 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 1ff[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 10:51:52.105 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 200[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp 10.0.0.29:10092: connect: connection refused
[36m2019-01-29 10:51:52.105 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 201[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.29:10092: connect: connection refused
[36m2019-01-29 10:51:52.105 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 202[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.105 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 203[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 10:51:52.105 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 204[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.28:11092: connect: connection refused
[36m2019-01-29 10:51:52.106 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 205[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.28:11092: connect: connection refused
[36m2019-01-29 10:51:52.106 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 206[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.106 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 207[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.106 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 208[0m Connected to broker at kafka0.switch2logic.co.za:9092 (unregistered)
[36m2019-01-29 10:51:52.107 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 209[0m client/brokers registered new broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.107 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 20a[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.107 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 20b[0m client/brokers registered new broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 10:51:52.107 UTC [orderer/consensus/kafka/sarama] NewConsumer -> DEBU 20c[0m Successfully initialized new client
[36m2019-01-29 10:51:52.107 UTC [orderer/consensus/kafka] try -> DEBU 20d[0m [channel: testchainid] Error is nil, breaking the retry loop
2019-01-29 10:51:52.107 UTC [orderer/consensus/kafka] startThread -> INFO 20e[0m [channel: testchainid] Parent consumer set up successfully
2019-01-29 10:51:52.107 UTC [orderer/consensus/kafka] setupChannelConsumerForChannel -> INFO 20f[0m [channel: testchainid] Setting up the channel consumer for this channel (start offset: 6)...
[36m2019-01-29 10:51:52.107 UTC [orderer/consensus/kafka] try -> DEBU 210[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:51:52.107 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 211[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 10:51:52.108 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 212[0m Connected to broker at kafka1.switch2logic.co.za:9092 (registered as #1)
[36m2019-01-29 10:51:52.110 UTC [orderer/consensus/kafka] try -> DEBU 213[0m [channel: testchainid] Initial attempt failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:51:52.110 UTC [orderer/consensus/kafka] try -> DEBU 214[0m [channel: testchainid] Retrying every 1s for a total of 30s
[36m2019-01-29 10:51:53.110 UTC [orderer/consensus/kafka] try -> DEBU 215[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:51:53.114 UTC [orderer/consensus/kafka] try -> DEBU 216[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:51:54.110 UTC [orderer/consensus/kafka] try -> DEBU 217[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:51:54.113 UTC [orderer/consensus/kafka] try -> DEBU 218[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:51:55.110 UTC [orderer/consensus/kafka] try -> DEBU 219[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:51:55.113 UTC [orderer/consensus/kafka] try -> DEBU 21a[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:51:56.110 UTC [orderer/consensus/kafka] try -> DEBU 21b[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:51:56.113 UTC [orderer/consensus/kafka] try -> DEBU 21c[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:51:57.110 UTC [orderer/consensus/kafka] try -> DEBU 21d[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:51:57.111 UTC [orderer/consensus/kafka] try -> DEBU 21e[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:51:58.110 UTC [orderer/consensus/kafka] try -> DEBU 21f[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:51:58.112 UTC [orderer/consensus/kafka] try -> DEBU 220[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:51:59.110 UTC [orderer/consensus/kafka] try -> DEBU 221[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:51:59.111 UTC [orderer/consensus/kafka] try -> DEBU 222[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:00.110 UTC [orderer/consensus/kafka] try -> DEBU 223[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:00.112 UTC [orderer/consensus/kafka] try -> DEBU 224[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:01.110 UTC [orderer/consensus/kafka] try -> DEBU 225[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:01.112 UTC [orderer/consensus/kafka] try -> DEBU 226[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:02.110 UTC [orderer/consensus/kafka] try -> DEBU 227[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:02.113 UTC [orderer/consensus/kafka] try -> DEBU 228[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:03.110 UTC [orderer/consensus/kafka] try -> DEBU 229[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:03.113 UTC [orderer/consensus/kafka] try -> DEBU 22a[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:04.110 UTC [orderer/consensus/kafka] try -> DEBU 22b[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:04.113 UTC [orderer/consensus/kafka] try -> DEBU 22c[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:05.110 UTC [orderer/consensus/kafka] try -> DEBU 22d[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:05.112 UTC [orderer/consensus/kafka] try -> DEBU 22e[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:06.110 UTC [orderer/consensus/kafka] try -> DEBU 22f[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:06.113 UTC [orderer/consensus/kafka] try -> DEBU 230[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:07.110 UTC [orderer/consensus/kafka] try -> DEBU 231[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:07.113 UTC [orderer/consensus/kafka] try -> DEBU 232[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:08.110 UTC [orderer/consensus/kafka] try -> DEBU 233[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:08.111 UTC [orderer/consensus/kafka] try -> DEBU 234[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:09.110 UTC [orderer/consensus/kafka] try -> DEBU 235[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:09.112 UTC [orderer/consensus/kafka] try -> DEBU 236[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:10.110 UTC [orderer/consensus/kafka] try -> DEBU 237[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:10.112 UTC [orderer/consensus/kafka] try -> DEBU 238[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:11.110 UTC [orderer/consensus/kafka] try -> DEBU 239[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:11.111 UTC [orderer/consensus/kafka] try -> DEBU 23a[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:12.110 UTC [orderer/consensus/kafka] try -> DEBU 23b[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:12.113 UTC [orderer/consensus/kafka] try -> DEBU 23c[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:13.110 UTC [orderer/consensus/kafka] try -> DEBU 23d[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:13.112 UTC [orderer/consensus/kafka] try -> DEBU 23e[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:14.110 UTC [orderer/consensus/kafka] try -> DEBU 23f[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:14.112 UTC [orderer/consensus/kafka] try -> DEBU 240[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:15.110 UTC [orderer/consensus/kafka] try -> DEBU 241[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:15.113 UTC [orderer/consensus/kafka] try -> DEBU 242[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:16.110 UTC [orderer/consensus/kafka] try -> DEBU 243[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:16.113 UTC [orderer/consensus/kafka] try -> DEBU 244[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:17.110 UTC [orderer/consensus/kafka] try -> DEBU 245[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:17.113 UTC [orderer/consensus/kafka] try -> DEBU 246[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:18.110 UTC [orderer/consensus/kafka] try -> DEBU 247[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:18.113 UTC [orderer/consensus/kafka] try -> DEBU 248[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:19.110 UTC [orderer/consensus/kafka] try -> DEBU 249[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:19.113 UTC [orderer/consensus/kafka] try -> DEBU 24a[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:20.110 UTC [orderer/consensus/kafka] try -> DEBU 24b[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:20.113 UTC [orderer/consensus/kafka] try -> DEBU 24c[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:21.110 UTC [orderer/consensus/kafka] try -> DEBU 24d[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:21.114 UTC [orderer/consensus/kafka] try -> DEBU 24e[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:22.110 UTC [orderer/consensus/kafka] try -> DEBU 24f[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:22.113 UTC [orderer/consensus/kafka] try -> DEBU 250[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:22.113 UTC [orderer/consensus/kafka] retry -> DEBU 251[0m [channel: testchainid] Switching to the long retry interval
[36m2019-01-29 10:52:22.113 UTC [orderer/consensus/kafka] try -> DEBU 252[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:52:22.115 UTC [orderer/consensus/kafka] try -> DEBU 253[0m [channel: testchainid] Initial attempt failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 10:52:22.115 UTC [orderer/consensus/kafka] try -> DEBU 254[0m [channel: testchainid] Retrying every 5m0s for a total of 12h0m0s
[36m2019-01-29 10:57:22.115 UTC [orderer/consensus/kafka] try -> DEBU 255[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 10:57:22.117 UTC [orderer/consensus/kafka] try -> DEBU 256[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 11:01:52.080 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 257[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:01:52.090 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 258[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:01:52.099 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 259[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:01:52.108 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 25a[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:22.115 UTC [orderer/consensus/kafka] try -> DEBU 25b[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 11:02:22.117 UTC [orderer/consensus/kafka] try -> DEBU 25c[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 11:02:42.559 UTC [orderer/consensus/kafka/sarama] subscriptionConsumer)-fm -> DEBU 25d[0m consumer/broker/0 disconnecting due to error processing FetchRequest: EOF
[36m2019-01-29 11:02:42.559 UTC [orderer/consensus/kafka/sarama] abort -> DEBU 25e[0m Closed connection to broker kafka0.switch2logic.co.za:9092
[31m2019-01-29 11:02:42.559 UTC [orderer/consensus/kafka] processMessagesToBlocks -> ERRO 25f[0m [channel: comunitychannel] Error during consumption: kafka: error while consuming comunitychannel/0: EOF
[33m2019-01-29 11:02:42.559 UTC [orderer/consensus/kafka] processMessagesToBlocks -> WARN 260[0m [channel: comunitychannel] Deliver sessions will be dropped if consumption errors continue.
[36m2019-01-29 11:02:44.559 UTC [orderer/consensus/kafka/sarama] dispatcher)-fm -> DEBU 261[0m consumer/comunitychannel/0 finding new broker
[36m2019-01-29 11:02:44.559 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 262[0m client/metadata fetching metadata for [comunitychannel] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:44.559 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 263[0m client/metadata got error from broker while fetching metadata: EOF
[36m2019-01-29 11:02:44.560 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 264[0m Closed connection to broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:44.560 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 265[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:44.560 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 266[0m client/metadata fetching metadata for [comunitychannel] from broker kafka2.switch2logic.co.za:9092
[36m2019-01-29 11:02:44.560 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 267[0m Failed to connect to broker kafka2.switch2logic.co.za:9092: dial tcp 10.0.0.43:9092: connect: connection refused
[36m2019-01-29 11:02:44.560 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 268[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.43:9092: connect: connection refused
[36m2019-01-29 11:02:44.560 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 269[0m client/brokers deregistered broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 11:02:44.560 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 26a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:44.560 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 26b[0m client/metadata fetching metadata for [comunitychannel] from broker kafka1.switch2logic.co.za:9092
[36m2019-01-29 11:02:45.563 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 26c[0m Failed to connect to broker kafka1.switch2logic.co.za:9092: dial tcp 10.0.0.44:9092: connect: connection refused
[36m2019-01-29 11:02:45.563 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 26d[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.44:9092: connect: connection refused
[36m2019-01-29 11:02:45.563 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 26e[0m client/brokers deregistered broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 11:02:45.563 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 26f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:45.564 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 270[0m client/metadata fetching metadata for [comunitychannel] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:45.568 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 271[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:45.568 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 272[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:45.568 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 273[0m client/brokers deregistered broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:45.568 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 274[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 11:02:45.568 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 275[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 11:02:45.568 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 276[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 11:02:45.818 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 277[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:45.818 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 278[0m client/metadata fetching metadata for [comunitychannel] from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 11:02:45.819 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 279[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:45.819 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 27a[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:45.819 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 27b[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:45.819 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 27c[0m client/metadata fetching metadata for [comunitychannel] from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 11:02:45.823 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 27d[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:45.828 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 27e[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:45.828 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 27f[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:45.828 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 280[0m client/metadata fetching metadata for [comunitychannel] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:45.835 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 281[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:45.835 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 282[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:45.835 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 283[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 11:02:45.835 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 284[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 11:02:45.835 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 285[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 11:02:46.085 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 286[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:46.085 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 287[0m client/metadata fetching metadata for [comunitychannel] from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 11:02:46.086 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 288[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:46.086 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 289[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:46.086 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 28a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:46.086 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 28b[0m client/metadata fetching metadata for [comunitychannel] from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 11:02:46.087 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 28c[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:46.087 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 28d[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:46.087 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 28e[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:46.087 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 28f[0m client/metadata fetching metadata for [comunitychannel] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:46.088 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 290[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:46.089 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 291[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:46.089 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 292[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 11:02:46.089 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 293[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 11:02:46.089 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 294[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 11:02:46.339 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 295[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:46.339 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 296[0m client/metadata fetching metadata for [comunitychannel] from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 11:02:46.340 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 297[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:46.340 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 298[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:46.340 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 299[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:46.340 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 29a[0m client/metadata fetching metadata for [comunitychannel] from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 11:02:46.341 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 29b[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:46.342 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 29c[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:46.342 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 29d[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:46.342 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 29e[0m client/metadata fetching metadata for [comunitychannel] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:46.343 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 29f[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:46.343 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2a0[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:46.343 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2a1[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 11:02:46.343 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2a2[0m client/brokers resurrecting 3 dead seed brokers
[31m2019-01-29 11:02:46.344 UTC [orderer/consensus/kafka] processMessagesToBlocks -> ERRO 2a3[0m [channel: comunitychannel] Error during consumption: kafka: error while consuming comunitychannel/0: kafka: client has run out of available brokers to talk to (Is your cluster reachable?)
[33m2019-01-29 11:02:46.344 UTC [orderer/consensus/kafka] processMessagesToBlocks -> WARN 2a4[0m [channel: comunitychannel] Deliver sessions will be dropped if consumption errors continue.
[36m2019-01-29 11:02:48.344 UTC [orderer/consensus/kafka/sarama] dispatcher)-fm -> DEBU 2a5[0m consumer/comunitychannel/0 finding new broker
[36m2019-01-29 11:02:48.344 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2a6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:48.344 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2a7[0m client/metadata fetching metadata for [comunitychannel] from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 11:02:48.345 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2a8[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:48.345 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2a9[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:48.345 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2aa[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:48.345 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2ab[0m client/metadata fetching metadata for [comunitychannel] from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 11:02:48.346 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2ac[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:48.346 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2ad[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:48.346 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2ae[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:48.346 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2af[0m client/metadata fetching metadata for [comunitychannel] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:48.347 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2b0[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:48.347 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2b1[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:48.347 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2b2[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 11:02:48.347 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2b3[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 11:02:48.347 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2b4[0m client/metadata retrying after 250ms... (3 attempts remaining)
[36m2019-01-29 11:02:48.597 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2b5[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:48.598 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2b6[0m client/metadata fetching metadata for [comunitychannel] from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 11:02:48.598 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2b7[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:48.599 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2b8[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:48.599 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2b9[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:48.599 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2ba[0m client/metadata fetching metadata for [comunitychannel] from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 11:02:48.600 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2bb[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:48.600 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2bc[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:48.600 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2bd[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:48.600 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2be[0m client/metadata fetching metadata for [comunitychannel] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:48.601 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2bf[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:48.601 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2c0[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:48.601 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2c1[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 11:02:48.601 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2c2[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 11:02:48.601 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2c3[0m client/metadata retrying after 250ms... (2 attempts remaining)
[36m2019-01-29 11:02:48.851 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2c4[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:48.851 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2c5[0m client/metadata fetching metadata for [comunitychannel] from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 11:02:48.852 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2c6[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:48.852 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2c7[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:48.852 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2c8[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:48.852 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2c9[0m client/metadata fetching metadata for [comunitychannel] from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 11:02:48.853 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2ca[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:48.853 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2cb[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:48.853 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2cc[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:48.853 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2cd[0m client/metadata fetching metadata for [comunitychannel] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:48.854 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2ce[0m Failed to connect to broker kafka0.switch2logic.co.za:9092: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:48.857 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2cf[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.45:9092: connect: connection refused
[36m2019-01-29 11:02:48.857 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2d0[0m client/metadata no available broker to send metadata request to
[36m2019-01-29 11:02:48.857 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2d1[0m client/brokers resurrecting 3 dead seed brokers
[36m2019-01-29 11:02:48.857 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2d2[0m client/metadata retrying after 250ms... (1 attempts remaining)
[36m2019-01-29 11:02:49.107 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2d3[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:49.108 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2d4[0m client/metadata fetching metadata for [comunitychannel] from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 11:02:49.109 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2d5[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:49.109 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2d6[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:02:49.109 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2d7[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:49.109 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2d8[0m client/metadata fetching metadata for [comunitychannel] from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 11:02:49.110 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2d9[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:49.110 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2da[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:02:49.110 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2db[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:49.111 UTC [orderer/consensus/kafka/sarama] func1 -> DEBU 2dc[0m client/metadata fetching metadata for [comunitychannel] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:49.112 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2dd[0m Connected to broker at kafka0.switch2logic.co.za:9092 (unregistered)
[36m2019-01-29 11:02:49.595 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2de[0m Unexpected topic-level metadata error: kafka server: Replication-factor is invalid.
[31m2019-01-29 11:02:49.595 UTC [orderer/consensus/kafka] processMessagesToBlocks -> ERRO 2df[0m [channel: comunitychannel] Error during consumption: kafka: error while consuming comunitychannel/0: kafka server: Replication-factor is invalid.
[33m2019-01-29 11:02:49.596 UTC [orderer/consensus/kafka] processMessagesToBlocks -> WARN 2e0[0m [channel: comunitychannel] Deliver sessions will be dropped if consumption errors continue.
[36m2019-01-29 11:02:51.596 UTC [orderer/consensus/kafka/sarama] dispatcher)-fm -> DEBU 2e1[0m consumer/comunitychannel/0 finding new broker
[36m2019-01-29 11:02:51.596 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2e2[0m client/metadata fetching metadata for [comunitychannel] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:51.627 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 2e3[0m client/brokers registered new broker #2 at kafka2.switch2logic.co.za:9092
[36m2019-01-29 11:02:51.627 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 2e4[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 11:02:51.628 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 2e5[0m client/brokers registered new broker #0 at kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:51.628 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2e6[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:51.629 UTC [orderer/consensus/kafka/sarama] subscriptionConsumer -> DEBU 2e7[0m consumer/broker/2 added subscription to comunitychannel/0
[33m2019-01-29 11:02:51.629 UTC [orderer/consensus/kafka] processMessagesToBlocks -> WARN 2e8[0m [channel: comunitychannel] Consumption will resume.
[36m2019-01-29 11:02:51.630 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2e9[0m Connected to broker at kafka2.switch2logic.co.za:9092 (registered as #2)
[36m2019-01-29 11:02:53.909 UTC [orderer/consensus/kafka/sarama] subscriptionConsumer -> DEBU 2ea[0m consumer/broker/2 abandoned subscription to comunitychannel/0 because kafka server: Tried to send a message to a replica that is not the leader for some partition. Your metadata is out of date.
[36m2019-01-29 11:02:55.909 UTC [orderer/consensus/kafka/sarama] dispatcher)-fm -> DEBU 2eb[0m consumer/comunitychannel/0 finding new broker
[36m2019-01-29 11:02:55.910 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2ec[0m client/metadata fetching metadata for [comunitychannel] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:02:55.915 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2ed[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:02:55.915 UTC [orderer/consensus/kafka/sarama] subscriptionConsumer -> DEBU 2ee[0m consumer/broker/0 added subscription to comunitychannel/0
[36m2019-01-29 11:02:55.916 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2ef[0m Connected to broker at kafka0.switch2logic.co.za:9092 (registered as #0)
[36m2019-01-29 11:03:53.290 UTC [grpc] Printf -> DEBU 2f0[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.38:39978": tls: first record does not look like a TLS handshake
[36m2019-01-29 11:03:58.838 UTC [grpc] Printf -> DEBU 2f1[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.38:39980": tls: first record does not look like a TLS handshake
[36m2019-01-29 11:05:27.678 UTC [grpc] Printf -> DEBU 2f2[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.38:39998": tls: first record does not look like a TLS handshake
[36m2019-01-29 11:05:32.712 UTC [grpc] Printf -> DEBU 2f3[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.38:40000": tls: first record does not look like a TLS handshake
[36m2019-01-29 11:06:14.203 UTC [grpc] Printf -> DEBU 2f4[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.38:40006": tls: first record does not look like a TLS handshake
[36m2019-01-29 11:06:27.650 UTC [grpc] Printf -> DEBU 2f5[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.38:40008": tls: first record does not look like a TLS handshake
[36m2019-01-29 11:07:22.115 UTC [orderer/consensus/kafka] try -> DEBU 2f6[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 11:07:22.116 UTC [orderer/consensus/kafka/sarama] getOffset -> DEBU 2f7[0m Closed connection to broker kafka1.switch2logic.co.za:9092
[36m2019-01-29 11:07:22.116 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2f8[0m client/metadata fetching metadata for [testchainid] from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:07:22.116 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2f9[0m client/metadata got error from broker while fetching metadata: EOF
[36m2019-01-29 11:07:22.116 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 2fa[0m Closed connection to broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:07:22.116 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2fb[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:07:22.116 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 2fc[0m client/metadata fetching metadata for [testchainid] from broker kafka2.switch2logic.co.za:9092
[36m2019-01-29 11:07:22.118 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2fd[0m Connected to broker at kafka2.switch2logic.co.za:9092 (registered as #2)
[36m2019-01-29 11:07:22.122 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 2fe[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:07:22.123 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 2ff[0m Connected to broker at kafka1.switch2logic.co.za:9092 (registered as #1)
[36m2019-01-29 11:07:22.125 UTC [orderer/consensus/kafka] try -> DEBU 300[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 11:07:58.390 UTC [grpc] Printf -> DEBU 301[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.38:40030": tls: first record does not look like a TLS handshake
[36m2019-01-29 11:08:16.424 UTC [grpc] Printf -> DEBU 302[0m grpc: Server.Serve failed to complete security handshake from "10.0.0.38:40036": tls: first record does not look like a TLS handshake
[36m2019-01-29 11:11:52.080 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 303[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:11:52.081 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 304[0m client/metadata got error from broker while fetching metadata: EOF
[36m2019-01-29 11:11:52.081 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 305[0m Closed connection to broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:11:52.081 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 306[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:11:52.081 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 307[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:11092
[36m2019-01-29 11:11:52.083 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 308[0m Failed to connect to broker kafka2.switch2logic.co.za:11092: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:11:52.083 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 309[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.43:11092: connect: connection refused
[36m2019-01-29 11:11:52.083 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 30a[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:11:52.083 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 30b[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:9092
[36m2019-01-29 11:11:52.084 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 30c[0m Connected to broker at kafka2.switch2logic.co.za:9092 (registered as #2)
[36m2019-01-29 11:11:52.089 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 30d[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:11:52.099 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 30e[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:11:52.099 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 30f[0m client/metadata got error from broker while fetching metadata: EOF
[36m2019-01-29 11:11:52.099 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 310[0m Closed connection to broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:11:52.099 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 311[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:11:52.099 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 312[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:10092
[36m2019-01-29 11:11:52.100 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 313[0m Failed to connect to broker kafka1.switch2logic.co.za:10092: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:11:52.100 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 314[0m client/metadata got error from broker while fetching metadata: dial tcp 10.0.0.44:10092: connect: connection refused
[36m2019-01-29 11:11:52.100 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 315[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:11:52.100 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 316[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:11:52.100 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 317[0m Connected to broker at kafka0.switch2logic.co.za:9092 (registered as #0)
[36m2019-01-29 11:11:52.108 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 318[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:11:52.108 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 319[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:11:52.109 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 31a[0m Connected to broker at kafka0.switch2logic.co.za:9092 (registered as #0)
[36m2019-01-29 11:12:22.115 UTC [orderer/consensus/kafka] try -> DEBU 31b[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 11:12:22.117 UTC [orderer/consensus/kafka] try -> DEBU 31c[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 11:12:44.015 UTC [orderer/common/server] Deliver -> DEBU 31d[0m Starting new Deliver handler
[36m2019-01-29 11:12:44.015 UTC [common/deliver] Handle -> DEBU 31e[0m Starting new deliver loop for 10.0.0.38:40066
[36m2019-01-29 11:12:44.015 UTC [common/deliver] Handle -> DEBU 31f[0m Attempting to read seek info message from 10.0.0.38:40066
[36m2019-01-29 11:12:44.016 UTC [policies] Evaluate -> DEBU 320[0m == Evaluating *policies.implicitMetaPolicy Policy /Channel/Readers ==
[36m2019-01-29 11:12:44.016 UTC [policies] Evaluate -> DEBU 321[0m This is an implicit meta policy, it will trigger other policy evaluations, whose failures may be benign
[36m2019-01-29 11:12:44.016 UTC [policies] Evaluate -> DEBU 322[0m == Evaluating *policies.implicitMetaPolicy Policy /Channel/Application/Readers ==
[36m2019-01-29 11:12:44.016 UTC [policies] Evaluate -> DEBU 323[0m This is an implicit meta policy, it will trigger other policy evaluations, whose failures may be benign
[36m2019-01-29 11:12:44.016 UTC [policies] Evaluate -> DEBU 324[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital1MSP/Readers ==
2019-01-29 11:12:44.016 UTC [msp] DeserializeIdentity -> INFO 325[0m Obtaining identity
[36m2019-01-29 11:12:44.016 UTC [msp/identity] newIdentity -> DEBU 326[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAJ6XtHMTTW1JzdpD54qCc3wwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwyLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABA+z1rb9aA1HwHfNLi9V9VZe
bdwT4MXak445zGz4DXzRUsmNeBngzntKb6qpgHQpeFtzbzLx+zwiynRDvfdzORGj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIPEC
alij2l9uByDcEUurCDRUsEQ/uONP3HEp7xVWhhduMAoGCCqGSM49BAMCA0cAMEQC
IA8A3CCJeCasyy7gYd/M1aHYmwWsecY7UY7cVUGy4XOxAiB0rrmfnGW6JA11PDCu
+5c5Rpn0jF5ddsFn+UIpzBFvmg==
-----END CERTIFICATE-----
[36m2019-01-29 11:12:44.016 UTC [cauthdsl] func1 -> DEBU 327[0m 0xc42000e030 gate 1548760364016917004 evaluation starts
[36m2019-01-29 11:12:44.016 UTC [cauthdsl] func2 -> DEBU 328[0m 0xc42000e030 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:12:44.016 UTC [cauthdsl] func2 -> DEBU 329[0m 0xc42000e030 processing identity 0 with bytes of 0a0c486f73706974616c324d535012df062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d494943547a4343416661674177494241674952414a365874484d545457314a7a6470443534714363337777436759494b6f5a497a6a304541774977675973780a437a414a42674e5642415954416c56544d524d77455159445651514945777044595778705a6d3979626d6c684d525977464159445651514845773154595734670a526e4a68626d4e7063324e764d535577497759445651514b4578786f62334e7761585268624449756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70680a4d5367774a675944565151444578396a5953356f62334e7761585268624449756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445350a4d4445794f5441334e4445314e466f58445449354d4445794e6a41334e4445314e466f776544454c4d416b474131554542684d4356564d78457a415242674e560a42416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e6862694247636d467559326c7a59323878447a414e42674e56424173540a426d4e7361575675644445724d436b47413155454177776951575274615735416147397a63476c30595777794c6e4e336158526a61444a73623264705979356a0a627935365954425a4d424d4742797147534d34394167454743437147534d3439417745484130494142412b7a31726239614131487748664e4c69395639565a650a62647754344d58616b3434357a477a3444587a5255736d4e65426e677a6e744b62367170674851706546747a627a4c782b7a7769796e52447666647a4f52476a0a5454424c4d41344741315564447745422f775145417749486744414d42674e5648524d4241663845416a41414d437347413155644977516b4d434b41495045430a616c696a326c39754279446345557572434452557345512f754f4e503348457037785657686864754d416f4743437147534d343942414d43413063414d4551430a494138413343434a654361737979376759642f4d316148596d77577365635937555937635655477934584f784169423072726d666e4757364a413131504443750a2b35633552706e306a4635646473466e2b5549707a4246766d673d3d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:12:44.017 UTC [cauthdsl] func2 -> DEBU 32a[0m 0xc42000e030 identity 0 does not satisfy principal: the identity is a member of a different MSP (expected Hospital1MSP, got Hospital2MSP)
[36m2019-01-29 11:12:44.017 UTC [cauthdsl] func2 -> DEBU 32b[0m 0xc42000e030 principal evaluation fails
[36m2019-01-29 11:12:44.017 UTC [cauthdsl] func1 -> DEBU 32c[0m 0xc42000e030 gate 1548760364016917004 evaluation fails
[36m2019-01-29 11:12:44.017 UTC [policies] Evaluate -> DEBU 32d[0m Signature set did not satisfy policy /Channel/Application/Hospital1MSP/Readers
[36m2019-01-29 11:12:44.017 UTC [policies] Evaluate -> DEBU 32e[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital1MSP/Readers
[36m2019-01-29 11:12:44.017 UTC [policies] Evaluate -> DEBU 32f[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital2MSP/Readers ==
[36m2019-01-29 11:12:44.017 UTC [cauthdsl] func1 -> DEBU 330[0m 0xc42000e058 gate 1548760364017145208 evaluation starts
[36m2019-01-29 11:12:44.017 UTC [cauthdsl] func2 -> DEBU 331[0m 0xc42000e058 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:12:44.017 UTC [cauthdsl] func2 -> DEBU 332[0m 0xc42000e058 processing identity 0 with bytes of 0a0c486f73706974616c324d535012df062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d494943547a4343416661674177494241674952414a365874484d545457314a7a6470443534714363337777436759494b6f5a497a6a304541774977675973780a437a414a42674e5642415954416c56544d524d77455159445651514945777044595778705a6d3979626d6c684d525977464159445651514845773154595734670a526e4a68626d4e7063324e764d535577497759445651514b4578786f62334e7761585268624449756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70680a4d5367774a675944565151444578396a5953356f62334e7761585268624449756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445350a4d4445794f5441334e4445314e466f58445449354d4445794e6a41334e4445314e466f776544454c4d416b474131554542684d4356564d78457a415242674e560a42416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e6862694247636d467559326c7a59323878447a414e42674e56424173540a426d4e7361575675644445724d436b47413155454177776951575274615735416147397a63476c30595777794c6e4e336158526a61444a73623264705979356a0a627935365954425a4d424d4742797147534d34394167454743437147534d3439417745484130494142412b7a31726239614131487748664e4c69395639565a650a62647754344d58616b3434357a477a3444587a5255736d4e65426e677a6e744b62367170674851706546747a627a4c782b7a7769796e52447666647a4f52476a0a5454424c4d41344741315564447745422f775145417749486744414d42674e5648524d4241663845416a41414d437347413155644977516b4d434b41495045430a616c696a326c39754279446345557572434452557345512f754f4e503348457037785657686864754d416f4743437147534d343942414d43413063414d4551430a494138413343434a654361737979376759642f4d316148596d77577365635937555937635655477934584f784169423072726d666e4757364a413131504443750a2b35633552706e306a4635646473466e2b5549707a4246766d673d3d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:12:44.017 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 333[0m Checking if identity satisfies MEMBER role for Hospital2MSP
[36m2019-01-29 11:12:44.017 UTC [msp] Validate -> DEBU 334[0m MSP Hospital2MSP validating identity
[36m2019-01-29 11:12:44.017 UTC [msp] getCertificationChain -> DEBU 335[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 11:12:44.017 UTC [cauthdsl] func2 -> DEBU 336[0m 0xc42000e058 principal matched by identity 0
[36m2019-01-29 11:12:44.017 UTC [msp/identity] Verify -> DEBU 337[0m Verify: digest = 00000000  48 10 4f 0f e3 90 58 42  3e 01 02 3b 88 5d 7d a8  |H.O...XB>..;.]}.|
00000010  5b b1 64 8e ca 53 48 1d  c8 e4 6c 81 8b b9 46 27  |[.d..SH...l...F'|
[36m2019-01-29 11:12:44.017 UTC [msp/identity] Verify -> DEBU 338[0m Verify: sig = 00000000  30 44 02 20 66 0e d6 57  59 a9 83 d7 80 b3 60 cf  |0D. f..WY.....`.|
00000010  60 5a e2 20 13 91 a3 40  f8 c9 27 de 38 8b 5f b8  |`Z. ...@..'.8._.|
00000020  56 61 65 92 02 20 6d 25  09 3c ba bf b8 f8 56 ee  |Vae.. m%.<....V.|
00000030  4b 05 19 4c 94 21 55 1b  ee 79 78 ae 4d ed 89 56  |K..L.!U..yx.M..V|
00000040  95 3c 9f 71 50 55                                 |.<.qPU|
[36m2019-01-29 11:12:44.017 UTC [cauthdsl] func2 -> DEBU 339[0m 0xc42000e058 principal evaluation succeeds for identity 0
[36m2019-01-29 11:12:44.017 UTC [cauthdsl] func1 -> DEBU 33a[0m 0xc42000e058 gate 1548760364017145208 evaluation succeeds
[36m2019-01-29 11:12:44.017 UTC [policies] Evaluate -> DEBU 33b[0m Signature set satisfies policy /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 11:12:44.017 UTC [policies] Evaluate -> DEBU 33c[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 11:12:44.018 UTC [policies] Evaluate -> DEBU 33d[0m Signature set satisfies policy /Channel/Application/Readers
[36m2019-01-29 11:12:44.018 UTC [policies] Evaluate -> DEBU 33e[0m == Done Evaluating *policies.implicitMetaPolicy Policy /Channel/Application/Readers
[36m2019-01-29 11:12:44.018 UTC [policies] Evaluate -> DEBU 33f[0m Signature set satisfies policy /Channel/Readers
[36m2019-01-29 11:12:44.018 UTC [policies] Evaluate -> DEBU 340[0m == Done Evaluating *policies.implicitMetaPolicy Policy /Channel/Readers
[36m2019-01-29 11:12:44.018 UTC [common/deliver] deliverBlocks -> DEBU 341[0m [channel: comunitychannel] Received seekInfo (0xc42012f0c0) start:<specified:<> > stop:<specified:<> >  from 10.0.0.38:40066
[36m2019-01-29 11:12:44.018 UTC [fsblkstorage] Next -> DEBU 342[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=0
[36m2019-01-29 11:12:44.018 UTC [fsblkstorage] newBlockfileStream -> DEBU 343[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/comunitychannel/blockfile_000000], startOffset=[0]
[36m2019-01-29 11:12:44.018 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 344[0m Remaining bytes=[21745], Going to peek [8] bytes
[36m2019-01-29 11:12:44.018 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 345[0m Returning blockbytes - length=[21742], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 11:12:44.018 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 346[0m blockbytes [21742] read from file [0]
[36m2019-01-29 11:12:44.018 UTC [common/deliver] deliverBlocks -> DEBU 347[0m [channel: comunitychannel] Delivering block for (0xc42012f0c0) for 10.0.0.38:40066
[36m2019-01-29 11:12:44.018 UTC [common/deliver] deliverBlocks -> DEBU 348[0m [channel: comunitychannel] Done delivering to 10.0.0.38:40066 for (0xc42012f0c0)
[36m2019-01-29 11:12:44.018 UTC [common/deliver] Handle -> DEBU 349[0m Waiting for new SeekInfo from 10.0.0.38:40066
[36m2019-01-29 11:12:44.018 UTC [common/deliver] Handle -> DEBU 34a[0m Attempting to read seek info message from 10.0.0.38:40066
[33m2019-01-29 11:12:44.020 UTC [common/deliver] Handle -> WARN 34b[0m Error reading from 10.0.0.38:40066: rpc error: code = Canceled desc = context canceled
[36m2019-01-29 11:12:44.020 UTC [orderer/common/server] func1 -> DEBU 34c[0m Closing Deliver stream
[36m2019-01-29 11:16:53.033 UTC [orderer/common/server] Deliver -> DEBU 34d[0m Starting new Deliver handler
[36m2019-01-29 11:16:53.033 UTC [common/deliver] Handle -> DEBU 34e[0m Starting new deliver loop for 10.0.0.6:49108
[36m2019-01-29 11:16:53.033 UTC [common/deliver] Handle -> DEBU 34f[0m Attempting to read seek info message from 10.0.0.6:49108
[36m2019-01-29 11:16:53.033 UTC [policies] Evaluate -> DEBU 350[0m == Evaluating *policies.implicitMetaPolicy Policy /Channel/Readers ==
[36m2019-01-29 11:16:53.033 UTC [policies] Evaluate -> DEBU 351[0m This is an implicit meta policy, it will trigger other policy evaluations, whose failures may be benign
[36m2019-01-29 11:16:53.033 UTC [policies] Evaluate -> DEBU 352[0m == Evaluating *policies.implicitMetaPolicy Policy /Channel/Application/Readers ==
[36m2019-01-29 11:16:53.033 UTC [policies] Evaluate -> DEBU 353[0m This is an implicit meta policy, it will trigger other policy evaluations, whose failures may be benign
[36m2019-01-29 11:16:53.033 UTC [policies] Evaluate -> DEBU 354[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital1MSP/Readers ==
2019-01-29 11:16:53.033 UTC [msp] DeserializeIdentity -> INFO 355[0m Obtaining identity
[36m2019-01-29 11:16:53.034 UTC [msp/identity] newIdentity -> DEBU 356[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAI8BA/5Jf+5m8ncI+D7aSiMwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwzLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABF1IehIKIjh8tXYZ7rw4QOuc
g/tpBAkJeOt44zr/LepbjhyFW8vIRnkw75i6Wcg+LOoAS+2NFNg2oNjqg//yCHWj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIDu9
VYVdamBkGiNDVkvFS+AEt6Jrn0yK8hFyPGZhqenJMAoGCCqGSM49BAMCA0cAMEQC
IFyc85pwbCAxGNdw4fflsX2I3HrP3h93YAB2zSDC8HtkAiAQxblAZfEnXUiQKrqE
8I10bYJqD6pJz1jb3Pv+4xplTA==
-----END CERTIFICATE-----
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func1 -> DEBU 357[0m 0xc42000e030 gate 1548760613034341861 evaluation starts
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func2 -> DEBU 358[0m 0xc42000e030 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func2 -> DEBU 359[0m 0xc42000e030 processing identity 0 with bytes of 0a0c486f73706974616c334d535012df062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d494943547a434341666167417749424167495241493842412f354a662b356d386e63492b44376153694d77436759494b6f5a497a6a304541774977675973780a437a414a42674e5642415954416c56544d524d77455159445651514945777044595778705a6d3979626d6c684d525977464159445651514845773154595734670a526e4a68626d4e7063324e764d535577497759445651514b4578786f62334e776158526862444d756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70680a4d5367774a675944565151444578396a5953356f62334e776158526862444d756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445350a4d4445794f5441334e4445314e466f58445449354d4445794e6a41334e4445314e466f776544454c4d416b474131554542684d4356564d78457a415242674e560a42416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e6862694247636d467559326c7a59323878447a414e42674e56424173540a426d4e7361575675644445724d436b47413155454177776951575274615735416147397a63476c305957777a4c6e4e336158526a61444a73623264705979356a0a627935365954425a4d424d4742797147534d34394167454743437147534d34394177454841304941424631496568494b496a68387458595a37727734514f75630a672f747042416b4a654f7434347a722f4c6570626a68794657387649526e6b77373569365763672b4c4f6f41532b324e464e67326f4e6a71672f2f794348576a0a5454424c4d41344741315564447745422f775145417749486744414d42674e5648524d4241663845416a41414d437347413155644977516b4d434b41494475390a56595664616d426b47694e44566b7646532b414574364a726e30794b3868467950475a6871656e4a4d416f4743437147534d343942414d43413063414d4551430a494679633835707762434178474e64773466666c735832493348725033683933594142327a5344433848746b4169415178626c415a66456e585569514b7271450a3849313062594a714436704a7a316a623350762b3478706c54413d3d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func2 -> DEBU 35a[0m 0xc42000e030 identity 0 does not satisfy principal: the identity is a member of a different MSP (expected Hospital1MSP, got Hospital3MSP)
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func2 -> DEBU 35b[0m 0xc42000e030 principal evaluation fails
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func1 -> DEBU 35c[0m 0xc42000e030 gate 1548760613034341861 evaluation fails
[36m2019-01-29 11:16:53.034 UTC [policies] Evaluate -> DEBU 35d[0m Signature set did not satisfy policy /Channel/Application/Hospital1MSP/Readers
[36m2019-01-29 11:16:53.034 UTC [policies] Evaluate -> DEBU 35e[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital1MSP/Readers
[36m2019-01-29 11:16:53.034 UTC [policies] Evaluate -> DEBU 35f[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital2MSP/Readers ==
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func1 -> DEBU 360[0m 0xc42000e060 gate 1548760613034513362 evaluation starts
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func2 -> DEBU 361[0m 0xc42000e060 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func2 -> DEBU 362[0m 0xc42000e060 processing identity 0 with bytes of 0a0c486f73706974616c334d535012df062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d494943547a434341666167417749424167495241493842412f354a662b356d386e63492b44376153694d77436759494b6f5a497a6a304541774977675973780a437a414a42674e5642415954416c56544d524d77455159445651514945777044595778705a6d3979626d6c684d525977464159445651514845773154595734670a526e4a68626d4e7063324e764d535577497759445651514b4578786f62334e776158526862444d756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70680a4d5367774a675944565151444578396a5953356f62334e776158526862444d756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445350a4d4445794f5441334e4445314e466f58445449354d4445794e6a41334e4445314e466f776544454c4d416b474131554542684d4356564d78457a415242674e560a42416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e6862694247636d467559326c7a59323878447a414e42674e56424173540a426d4e7361575675644445724d436b47413155454177776951575274615735416147397a63476c305957777a4c6e4e336158526a61444a73623264705979356a0a627935365954425a4d424d4742797147534d34394167454743437147534d34394177454841304941424631496568494b496a68387458595a37727734514f75630a672f747042416b4a654f7434347a722f4c6570626a68794657387649526e6b77373569365763672b4c4f6f41532b324e464e67326f4e6a71672f2f794348576a0a5454424c4d41344741315564447745422f775145417749486744414d42674e5648524d4241663845416a41414d437347413155644977516b4d434b41494475390a56595664616d426b47694e44566b7646532b414574364a726e30794b3868467950475a6871656e4a4d416f4743437147534d343942414d43413063414d4551430a494679633835707762434178474e64773466666c735832493348725033683933594142327a5344433848746b4169415178626c415a66456e585569514b7271450a3849313062594a714436704a7a316a623350762b3478706c54413d3d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func2 -> DEBU 363[0m 0xc42000e060 identity 0 does not satisfy principal: the identity is a member of a different MSP (expected Hospital2MSP, got Hospital3MSP)
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func2 -> DEBU 364[0m 0xc42000e060 principal evaluation fails
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func1 -> DEBU 365[0m 0xc42000e060 gate 1548760613034513362 evaluation fails
[36m2019-01-29 11:16:53.034 UTC [policies] Evaluate -> DEBU 366[0m Signature set did not satisfy policy /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 11:16:53.034 UTC [policies] Evaluate -> DEBU 367[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 11:16:53.034 UTC [policies] Evaluate -> DEBU 368[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital3MSP/Readers ==
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func1 -> DEBU 369[0m 0xc42000e080 gate 1548760613034689856 evaluation starts
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func2 -> DEBU 36a[0m 0xc42000e080 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:16:53.034 UTC [cauthdsl] func2 -> DEBU 36b[0m 0xc42000e080 processing identity 0 with bytes of 0a0c486f73706974616c334d535012df062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d494943547a434341666167417749424167495241493842412f354a662b356d386e63492b44376153694d77436759494b6f5a497a6a304541774977675973780a437a414a42674e5642415954416c56544d524d77455159445651514945777044595778705a6d3979626d6c684d525977464159445651514845773154595734670a526e4a68626d4e7063324e764d535577497759445651514b4578786f62334e776158526862444d756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70680a4d5367774a675944565151444578396a5953356f62334e776158526862444d756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445350a4d4445794f5441334e4445314e466f58445449354d4445794e6a41334e4445314e466f776544454c4d416b474131554542684d4356564d78457a415242674e560a42416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e6862694247636d467559326c7a59323878447a414e42674e56424173540a426d4e7361575675644445724d436b47413155454177776951575274615735416147397a63476c305957777a4c6e4e336158526a61444a73623264705979356a0a627935365954425a4d424d4742797147534d34394167454743437147534d34394177454841304941424631496568494b496a68387458595a37727734514f75630a672f747042416b4a654f7434347a722f4c6570626a68794657387649526e6b77373569365763672b4c4f6f41532b324e464e67326f4e6a71672f2f794348576a0a5454424c4d41344741315564447745422f775145417749486744414d42674e5648524d4241663845416a41414d437347413155644977516b4d434b41494475390a56595664616d426b47694e44566b7646532b414574364a726e30794b3868467950475a6871656e4a4d416f4743437147534d343942414d43413063414d4551430a494679633835707762434178474e64773466666c735832493348725033683933594142327a5344433848746b4169415178626c415a66456e585569514b7271450a3849313062594a714436704a7a316a623350762b3478706c54413d3d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:16:53.034 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 36c[0m Checking if identity satisfies MEMBER role for Hospital3MSP
[36m2019-01-29 11:16:53.034 UTC [msp] Validate -> DEBU 36d[0m MSP Hospital3MSP validating identity
[36m2019-01-29 11:16:53.035 UTC [msp] getCertificationChain -> DEBU 36e[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 11:16:53.035 UTC [cauthdsl] func2 -> DEBU 36f[0m 0xc42000e080 principal matched by identity 0
[36m2019-01-29 11:16:53.035 UTC [msp/identity] Verify -> DEBU 370[0m Verify: digest = 00000000  70 ca 3e 66 15 57 ca 21  bb c2 83 1a 5d 6e 43 f0  |p.>f.W.!....]nC.|
00000010  94 ee 4f 4d 44 b3 e6 76  27 a4 f0 8e c4 29 de 2e  |..OMD..v'....)..|
[36m2019-01-29 11:16:53.035 UTC [msp/identity] Verify -> DEBU 371[0m Verify: sig = 00000000  30 45 02 21 00 8b 5f 76  be 74 b7 d3 31 00 60 92  |0E.!.._v.t..1.`.|
00000010  14 22 20 55 ca f5 28 62  6b 64 5a e3 d1 ec ee e1  |." U..(bkdZ.....|
00000020  18 96 a1 69 be 02 20 21  d0 98 ee d4 c9 41 32 a1  |...i.. !.....A2.|
00000030  b5 a4 b0 04 c2 10 50 b3  f2 0b b5 f0 53 9a dd 09  |......P.....S...|
00000040  16 a7 01 14 58 e6 6b                              |....X.k|
[36m2019-01-29 11:16:53.035 UTC [cauthdsl] func2 -> DEBU 372[0m 0xc42000e080 principal evaluation succeeds for identity 0
[36m2019-01-29 11:16:53.035 UTC [cauthdsl] func1 -> DEBU 373[0m 0xc42000e080 gate 1548760613034689856 evaluation succeeds
[36m2019-01-29 11:16:53.035 UTC [policies] Evaluate -> DEBU 374[0m Signature set satisfies policy /Channel/Application/Hospital3MSP/Readers
[36m2019-01-29 11:16:53.035 UTC [policies] Evaluate -> DEBU 375[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital3MSP/Readers
[36m2019-01-29 11:16:53.035 UTC [policies] Evaluate -> DEBU 376[0m Signature set satisfies policy /Channel/Application/Readers
[36m2019-01-29 11:16:53.035 UTC [policies] Evaluate -> DEBU 377[0m == Done Evaluating *policies.implicitMetaPolicy Policy /Channel/Application/Readers
[36m2019-01-29 11:16:53.035 UTC [policies] Evaluate -> DEBU 378[0m Signature set satisfies policy /Channel/Readers
[36m2019-01-29 11:16:53.035 UTC [policies] Evaluate -> DEBU 379[0m == Done Evaluating *policies.implicitMetaPolicy Policy /Channel/Readers
[36m2019-01-29 11:16:53.035 UTC [common/deliver] deliverBlocks -> DEBU 37a[0m [channel: comunitychannel] Received seekInfo (0xc4200772c0) start:<specified:<> > stop:<specified:<> >  from 10.0.0.6:49108
[36m2019-01-29 11:16:53.035 UTC [fsblkstorage] Next -> DEBU 37b[0m Initializing block stream for iterator. itr.maxBlockNumAvailable=0
[36m2019-01-29 11:16:53.035 UTC [fsblkstorage] newBlockfileStream -> DEBU 37c[0m newBlockfileStream(): filePath=[/var/hyperledger/production/orderer/chains/comunitychannel/blockfile_000000], startOffset=[0]
[36m2019-01-29 11:16:53.035 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 37d[0m Remaining bytes=[21745], Going to peek [8] bytes
[36m2019-01-29 11:16:53.035 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 37e[0m Returning blockbytes - length=[21742], placementInfo={fileNum=[0], startOffset=[0], bytesOffset=[3]}
[36m2019-01-29 11:16:53.035 UTC [fsblkstorage] nextBlockBytesAndPlacementInfo -> DEBU 37f[0m blockbytes [21742] read from file [0]
[36m2019-01-29 11:16:53.035 UTC [common/deliver] deliverBlocks -> DEBU 380[0m [channel: comunitychannel] Delivering block for (0xc4200772c0) for 10.0.0.6:49108
[36m2019-01-29 11:16:53.035 UTC [common/deliver] deliverBlocks -> DEBU 381[0m [channel: comunitychannel] Done delivering to 10.0.0.6:49108 for (0xc4200772c0)
[36m2019-01-29 11:16:53.036 UTC [common/deliver] Handle -> DEBU 382[0m Waiting for new SeekInfo from 10.0.0.6:49108
[36m2019-01-29 11:16:53.036 UTC [common/deliver] Handle -> DEBU 383[0m Attempting to read seek info message from 10.0.0.6:49108
[33m2019-01-29 11:16:53.037 UTC [common/deliver] Handle -> WARN 384[0m Error reading from 10.0.0.6:49108: rpc error: code = Canceled desc = context canceled
[36m2019-01-29 11:16:53.037 UTC [orderer/common/server] func1 -> DEBU 385[0m Closing Deliver stream
[36m2019-01-29 11:17:22.115 UTC [orderer/consensus/kafka] try -> DEBU 386[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 11:17:22.118 UTC [orderer/consensus/kafka] try -> DEBU 387[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 11:21:21.941 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 388[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 5. Inspecting type...
[36m2019-01-29 11:21:21.941 UTC [orderer/consensus/kafka] processRegular -> DEBU 389[0m [channel: comunitychannel] Processing regular Kafka message of type CONFIG
[36m2019-01-29 11:21:21.941 UTC [orderer/consensus/kafka] func2 -> DEBU 38a[0m [channel: comunitychannel] Received config message
[36m2019-01-29 11:21:21.941 UTC [orderer/consensus/kafka] func2 -> DEBU 38b[0m [channel: comunitychannel] Creating isolated block for config message
[36m2019-01-29 11:21:21.942 UTC [common/configtx] addToMap -> DEBU 38c[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 11:21:21.942 UTC [common/configtx] addToMap -> DEBU 38d[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 11:21:21.942 UTC [common/configtx] addToMap -> DEBU 38e[0m Adding to config map: [Group]  /Channel/Application/Hospital3MSP
[36m2019-01-29 11:21:21.942 UTC [common/configtx] addToMap -> DEBU 38f[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/MSP
[36m2019-01-29 11:21:21.942 UTC [common/configtx] addToMap -> DEBU 390[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Admins
[36m2019-01-29 11:21:21.943 UTC [common/configtx] addToMap -> DEBU 391[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Readers
[36m2019-01-29 11:21:21.943 UTC [common/configtx] addToMap -> DEBU 392[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Writers
[36m2019-01-29 11:21:21.943 UTC [common/configtx] addToMap -> DEBU 393[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 11:21:21.943 UTC [common/configtx] addToMap -> DEBU 394[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 11:21:21.943 UTC [common/configtx] addToMap -> DEBU 395[0m Adding to config map: [Group]  /Channel/Application/Hospital3MSP
[36m2019-01-29 11:21:21.944 UTC [common/configtx] addToMap -> DEBU 396[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/MSP
[36m2019-01-29 11:21:21.944 UTC [common/configtx] addToMap -> DEBU 397[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/AnchorPeers
[36m2019-01-29 11:21:21.944 UTC [common/configtx] addToMap -> DEBU 398[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Writers
[36m2019-01-29 11:21:21.944 UTC [common/configtx] addToMap -> DEBU 399[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Admins
[36m2019-01-29 11:21:21.944 UTC [common/configtx] addToMap -> DEBU 39a[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Readers
[36m2019-01-29 11:21:21.944 UTC [common/configtx] verifyDeltaSet -> DEBU 39b[0m Processing change to key: [Group]  /Channel/Application/Hospital3MSP
[36m2019-01-29 11:21:21.944 UTC [common/configtx] policyForItem -> DEBU 39c[0m Getting policy for item Hospital3MSP with mod_policy Admins
[36m2019-01-29 11:21:21.944 UTC [policies] Manager -> DEBU 39d[0m Manager Channel looking up path [Application]
[36m2019-01-29 11:21:21.944 UTC [policies] Manager -> DEBU 39e[0m Manager Channel has managers Application
[36m2019-01-29 11:21:21.944 UTC [policies] Manager -> DEBU 39f[0m Manager Channel has managers Orderer
[36m2019-01-29 11:21:21.944 UTC [policies] Manager -> DEBU 3a0[0m Manager Channel/Application looking up path []
[36m2019-01-29 11:21:21.944 UTC [policies] Manager -> DEBU 3a1[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 11:21:21.944 UTC [policies] Manager -> DEBU 3a2[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 11:21:21.944 UTC [policies] Manager -> DEBU 3a3[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 11:21:21.944 UTC [policies] Manager -> DEBU 3a4[0m Manager Channel/Application looking up path [Hospital3MSP]
[36m2019-01-29 11:21:21.944 UTC [policies] Manager -> DEBU 3a5[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 11:21:21.944 UTC [policies] Manager -> DEBU 3a6[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 11:21:21.944 UTC [policies] Manager -> DEBU 3a7[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 11:21:21.944 UTC [policies] Manager -> DEBU 3a8[0m Manager Channel/Application/Hospital3MSP looking up path []
[36m2019-01-29 11:21:21.945 UTC [policies] Evaluate -> DEBU 3a9[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital3MSP/Admins ==
[36m2019-01-29 11:21:21.945 UTC [cauthdsl] func1 -> DEBU 3aa[0m 0xc42000e710 gate 1548760881945064391 evaluation starts
[36m2019-01-29 11:21:21.945 UTC [cauthdsl] func2 -> DEBU 3ab[0m 0xc42000e710 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:21:21.945 UTC [cauthdsl] func2 -> DEBU 3ac[0m 0xc42000e710 processing identity 0 with bytes of 0a0c486f73706974616c334d535012df062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d494943547a434341666167417749424167495241493842412f354a662b356d386e63492b44376153694d77436759494b6f5a497a6a304541774977675973780a437a414a42674e5642415954416c56544d524d77455159445651514945777044595778705a6d3979626d6c684d525977464159445651514845773154595734670a526e4a68626d4e7063324e764d535577497759445651514b4578786f62334e776158526862444d756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70680a4d5367774a675944565151444578396a5953356f62334e776158526862444d756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445350a4d4445794f5441334e4445314e466f58445449354d4445794e6a41334e4445314e466f776544454c4d416b474131554542684d4356564d78457a415242674e560a42416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e6862694247636d467559326c7a59323878447a414e42674e56424173540a426d4e7361575675644445724d436b47413155454177776951575274615735416147397a63476c305957777a4c6e4e336158526a61444a73623264705979356a0a627935365954425a4d424d4742797147534d34394167454743437147534d34394177454841304941424631496568494b496a68387458595a37727734514f75630a672f747042416b4a654f7434347a722f4c6570626a68794657387649526e6b77373569365763672b4c4f6f41532b324e464e67326f4e6a71672f2f794348576a0a5454424c4d41344741315564447745422f775145417749486744414d42674e5648524d4241663845416a41414d437347413155644977516b4d434b41494475390a56595664616d426b47694e44566b7646532b414574364a726e30794b3868467950475a6871656e4a4d416f4743437147534d343942414d43413063414d4551430a494679633835707762434178474e64773466666c735832493348725033683933594142327a5344433848746b4169415178626c415a66456e585569514b7271450a3849313062594a714436704a7a316a623350762b3478706c54413d3d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:21:21.945 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 3ad[0m Checking if identity satisfies ADMIN role for Hospital3MSP
[36m2019-01-29 11:21:21.945 UTC [cauthdsl] func2 -> DEBU 3ae[0m 0xc42000e710 principal matched by identity 0
[36m2019-01-29 11:21:21.945 UTC [msp/identity] Verify -> DEBU 3af[0m Verify: digest = 00000000  5a 4b e6 c6 6d 21 aa c7  ba 9e 82 2a bd 7f 29 b1  |ZK..m!.....*..).|
00000010  0b 0c 11 d7 f3 10 8b 76  2b d5 e6 46 9c 28 fa 43  |.......v+..F.(.C|
[36m2019-01-29 11:21:21.945 UTC [msp/identity] Verify -> DEBU 3b0[0m Verify: sig = 00000000  30 44 02 20 73 ea 38 17  94 6e c4 65 bd 26 45 ea  |0D. s.8..n.e.&E.|
00000010  e1 8c f8 ca 26 92 17 2d  af 7c f8 cf 73 88 e3 94  |....&..-.|..s...|
00000020  eb 32 a9 94 02 20 37 13  e7 ef 73 80 f9 6d 8e 2e  |.2... 7...s..m..|
00000030  69 7c e5 a4 bf e8 39 f2  19 54 fa 6e c4 41 46 78  |i|....9..T.n.AFx|
00000040  0e de 00 86 5a 5b                                 |....Z[|
[36m2019-01-29 11:21:21.945 UTC [cauthdsl] func2 -> DEBU 3b1[0m 0xc42000e710 principal evaluation succeeds for identity 0
[36m2019-01-29 11:21:21.945 UTC [cauthdsl] func1 -> DEBU 3b2[0m 0xc42000e710 gate 1548760881945064391 evaluation succeeds
[36m2019-01-29 11:21:21.945 UTC [policies] Evaluate -> DEBU 3b3[0m Signature set satisfies policy /Channel/Application/Hospital3MSP/Admins
[36m2019-01-29 11:21:21.946 UTC [policies] Evaluate -> DEBU 3b4[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital3MSP/Admins
[36m2019-01-29 11:21:21.946 UTC [common/configtx] verifyDeltaSet -> DEBU 3b5[0m Processing change to key: [Value]  /Channel/Application/Hospital3MSP/AnchorPeers
[36m2019-01-29 11:21:21.946 UTC [common/configtx] recurseConfigMap -> DEBU 3b6[0m Setting policy for key Readers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital2MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.946 UTC [common/configtx] recurseConfigMap -> DEBU 3b7[0m Setting policy for key Writers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital2MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.946 UTC [common/configtx] recurseConfigMap -> DEBU 3b8[0m Setting policy for key Admins to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\022\022\020\n\014Hospital2MSP\020\001" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.946 UTC [common/configtx] recurseConfigMap -> DEBU 3b9[0m Setting policy for key Admins to 
[36m2019-01-29 11:21:21.946 UTC [common/configtx] recurseConfigMap -> DEBU 3ba[0m Setting policy for key Readers to 
[36m2019-01-29 11:21:21.946 UTC [common/configtx] recurseConfigMap -> DEBU 3bb[0m Setting policy for key Writers to 
[36m2019-01-29 11:21:21.947 UTC [common/configtx] recurseConfigMap -> DEBU 3bc[0m Setting policy for key Admins to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\022\022\020\n\014Hospital1MSP\020\001" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.947 UTC [common/configtx] recurseConfigMap -> DEBU 3bd[0m Setting policy for key Readers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital1MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.947 UTC [common/configtx] recurseConfigMap -> DEBU 3be[0m Setting policy for key Writers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital1MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.947 UTC [common/configtx] recurseConfigMap -> DEBU 3bf[0m Setting policy for key Writers to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.947 UTC [common/configtx] recurseConfigMap -> DEBU 3c0[0m Setting policy for key Admins to policy:<type:3 value:"\n\006Admins\020\002" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.947 UTC [common/configtx] recurseConfigMap -> DEBU 3c1[0m Setting policy for key Readers to policy:<type:3 value:"\n\007Readers" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.947 UTC [common/configtx] recurseConfigMap -> DEBU 3c2[0m Setting policy for key Admins to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\nOrdererMSP\020\001" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.947 UTC [common/configtx] recurseConfigMap -> DEBU 3c3[0m Setting policy for key Readers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\016\022\014\n\nOrdererMSP" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.947 UTC [common/configtx] recurseConfigMap -> DEBU 3c4[0m Setting policy for key Writers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\016\022\014\n\nOrdererMSP" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.947 UTC [common/configtx] recurseConfigMap -> DEBU 3c5[0m Setting policy for key BlockValidation to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.947 UTC [common/configtx] recurseConfigMap -> DEBU 3c6[0m Setting policy for key Admins to policy:<type:3 value:"\n\006Admins\020\002" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.947 UTC [common/configtx] recurseConfigMap -> DEBU 3c7[0m Setting policy for key Readers to policy:<type:3 value:"\n\007Readers" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.947 UTC [common/configtx] recurseConfigMap -> DEBU 3c8[0m Setting policy for key Writers to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.948 UTC [common/configtx] recurseConfigMap -> DEBU 3c9[0m Setting policy for key Readers to policy:<type:3 value:"\n\007Readers" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.948 UTC [common/configtx] recurseConfigMap -> DEBU 3ca[0m Setting policy for key Writers to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.948 UTC [common/configtx] recurseConfigMap -> DEBU 3cb[0m Setting policy for key Admins to policy:<type:3 value:"\n\006Admins\020\002" > mod_policy:"Admins" 
[36m2019-01-29 11:21:21.948 UTC [common/channelconfig] NewStandardValues -> DEBU 3cc[0m Initializing protos for *channelconfig.ChannelProtos
[36m2019-01-29 11:21:21.948 UTC [common/channelconfig] initializeProtosStruct -> DEBU 3cd[0m Processing field: HashingAlgorithm
[36m2019-01-29 11:21:21.948 UTC [common/channelconfig] initializeProtosStruct -> DEBU 3ce[0m Processing field: BlockDataHashingStructure
[36m2019-01-29 11:21:21.948 UTC [common/channelconfig] initializeProtosStruct -> DEBU 3cf[0m Processing field: OrdererAddresses
[36m2019-01-29 11:21:21.948 UTC [common/channelconfig] initializeProtosStruct -> DEBU 3d0[0m Processing field: Consortium
[36m2019-01-29 11:21:21.949 UTC [common/channelconfig] initializeProtosStruct -> DEBU 3d1[0m Processing field: Capabilities
[36m2019-01-29 11:21:21.949 UTC [common/channelconfig] NewStandardValues -> DEBU 3d2[0m Initializing protos for *channelconfig.ApplicationProtos
[36m2019-01-29 11:21:21.949 UTC [common/channelconfig] initializeProtosStruct -> DEBU 3d3[0m Processing field: ACLs
[36m2019-01-29 11:21:21.949 UTC [common/channelconfig] initializeProtosStruct -> DEBU 3d4[0m Processing field: Capabilities
[36m2019-01-29 11:21:21.949 UTC [common/channelconfig] NewStandardValues -> DEBU 3d5[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 11:21:21.949 UTC [common/channelconfig] initializeProtosStruct -> DEBU 3d6[0m Processing field: AnchorPeers
[36m2019-01-29 11:21:21.949 UTC [common/channelconfig] NewStandardValues -> DEBU 3d7[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:21:21.949 UTC [common/channelconfig] initializeProtosStruct -> DEBU 3d8[0m Processing field: MSP
[36m2019-01-29 11:21:21.949 UTC [common/channelconfig] Validate -> DEBU 3d9[0m Anchor peers for org Hospital1MSP are 
[36m2019-01-29 11:21:21.949 UTC [common/channelconfig] validateMSP -> DEBU 3da[0m Setting up MSP for org Hospital1MSP
[36m2019-01-29 11:21:21.949 UTC [msp] newBccspMsp -> DEBU 3db[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:21:21.949 UTC [msp] New -> DEBU 3dc[0m Creating Cache-MSP instance
[36m2019-01-29 11:21:21.949 UTC [msp] Setup -> DEBU 3dd[0m Setting up MSP instance Hospital1MSP
[36m2019-01-29 11:21:21.950 UTC [msp/identity] newIdentity -> DEBU 3de[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdDCCAhugAwIBAgIQZxH8VsnceZxXgKxlURLgVTAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMS5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQX9V4k/h/3pFxByKDscjgQrC0YS/bSbKvzSG2Z2PvltEWp40qB9OaKUN0GQYzo
yK2Etdvyjfd1OFwaTjpGSvv9o18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCBVU7DoP9Msf/nNTNl6
5FxwAXZ82eaGBT7zWYdyh4QbBjAKBggqhkjOPQQDAgNHADBEAiBmXGWQbxCGRp0c
5/y9qJyciB1CDHsknRZDjNzt5f563wIgMy7VPi1R8DpIIIRN9B3mfhDpRa+J+8PA
S4DOJy7rjp4=
-----END CERTIFICATE-----
[36m2019-01-29 11:21:21.950 UTC [msp/identity] newIdentity -> DEBU 3df[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfWgAwIBAgIQbzxpSKiuJCzDiDlZp+XbWDAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjB4MQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZyYW5jaXNjbzEPMA0GA1UECxMG
Y2xpZW50MSswKQYDVQQDDCJBZG1pbkBob3NwaXRhbDEuc3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEnpADl8+aUBcVWv6q3IgMQ4yg
ISawQ0wamHmpSv+/b1B5hf4V2HyoPrawIr45+o4/Qz++WazZlyY7PkoT27r7KaNN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgVVOw
6D/TLH/5zUzZeuRccAF2fNnmhgU+81mHcoeEGwYwCgYIKoZIzj0EAwIDSAAwRQIh
ALavdMm9i6xSsnWdlliMh10s6dmGBaXO0CxaCowLJIMtAiBEduudGJymDDE1zbiX
YwX83cYWZHUcYV8IXeZPFymC+w==
-----END CERTIFICATE-----
[36m2019-01-29 11:21:21.951 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 3e0[0m Checking if identity satisfies role [CLIENT] for Hospital1MSP
[36m2019-01-29 11:21:21.951 UTC [msp] Validate -> DEBU 3e1[0m MSP Hospital1MSP validating identity
[36m2019-01-29 11:21:21.952 UTC [msp] getCertificationChain -> DEBU 3e2[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 11:21:21.952 UTC [msp] hasOURole -> DEBU 3e3[0m MSP Hospital1MSP checking if the identity is a client
[36m2019-01-29 11:21:21.952 UTC [msp] getCertificationChain -> DEBU 3e4[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 11:21:21.952 UTC [common/channelconfig] NewStandardValues -> DEBU 3e5[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 11:21:21.952 UTC [common/channelconfig] initializeProtosStruct -> DEBU 3e6[0m Processing field: AnchorPeers
[36m2019-01-29 11:21:21.952 UTC [common/channelconfig] NewStandardValues -> DEBU 3e7[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:21:21.952 UTC [common/channelconfig] initializeProtosStruct -> DEBU 3e8[0m Processing field: MSP
[36m2019-01-29 11:21:21.952 UTC [common/channelconfig] Validate -> DEBU 3e9[0m Anchor peers for org Hospital2MSP are 
[36m2019-01-29 11:21:21.952 UTC [common/channelconfig] validateMSP -> DEBU 3ea[0m Setting up MSP for org Hospital2MSP
[36m2019-01-29 11:21:21.953 UTC [msp] newBccspMsp -> DEBU 3eb[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:21:21.953 UTC [msp] New -> DEBU 3ec[0m Creating Cache-MSP instance
[36m2019-01-29 11:21:21.953 UTC [msp] Setup -> DEBU 3ed[0m Setting up MSP instance Hospital2MSP
[36m2019-01-29 11:21:21.953 UTC [msp/identity] newIdentity -> DEBU 3ee[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdjCCAhygAwIBAgIRALZ3Pffn/xWUtUWPSK6CYVAwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFowgYsxCzAJBgNVBAYTAlVTMRMwEQYD
VQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4gRnJhbmNpc2NvMSUwIwYDVQQK
Exxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMSgwJgYDVQQDEx9jYS5ob3Nw
aXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcD
QgAESzVpiz6P4mIb+KwvrttcXJKZR5i137Is4298E7OrkYdAg0tB4rpfKTXzUMwW
vI12cTDujpyaZSiqQ3/zP4fOQqNfMF0wDgYDVR0PAQH/BAQDAgGmMA8GA1UdJQQI
MAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQg8QJqWKPaX24HINwR
S6sINFSwRD+440/ccSnvFVaGF24wCgYIKoZIzj0EAwIDSAAwRQIhAPO2Nng3/nqb
cKPliUqVPVjBMu+D55M90+jexWSOpkjcAiADPx8qv9exZ4BfP3+G49Qzpx0Meblj
53vzUgYFa/0EXw==
-----END CERTIFICATE-----
[36m2019-01-29 11:21:21.953 UTC [msp/identity] newIdentity -> DEBU 3ef[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAJ6XtHMTTW1JzdpD54qCc3wwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwyLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABA+z1rb9aA1HwHfNLi9V9VZe
bdwT4MXak445zGz4DXzRUsmNeBngzntKb6qpgHQpeFtzbzLx+zwiynRDvfdzORGj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIPEC
alij2l9uByDcEUurCDRUsEQ/uONP3HEp7xVWhhduMAoGCCqGSM49BAMCA0cAMEQC
IA8A3CCJeCasyy7gYd/M1aHYmwWsecY7UY7cVUGy4XOxAiB0rrmfnGW6JA11PDCu
+5c5Rpn0jF5ddsFn+UIpzBFvmg==
-----END CERTIFICATE-----
[36m2019-01-29 11:21:21.954 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 3f0[0m Checking if identity satisfies role [CLIENT] for Hospital2MSP
[36m2019-01-29 11:21:21.954 UTC [msp] Validate -> DEBU 3f1[0m MSP Hospital2MSP validating identity
[36m2019-01-29 11:21:21.955 UTC [msp] getCertificationChain -> DEBU 3f2[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 11:21:21.955 UTC [msp] hasOURole -> DEBU 3f3[0m MSP Hospital2MSP checking if the identity is a client
[36m2019-01-29 11:21:21.955 UTC [msp] getCertificationChain -> DEBU 3f4[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 11:21:21.956 UTC [common/channelconfig] NewStandardValues -> DEBU 3f5[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 11:21:21.956 UTC [common/channelconfig] initializeProtosStruct -> DEBU 3f6[0m Processing field: AnchorPeers
[36m2019-01-29 11:21:21.956 UTC [common/channelconfig] NewStandardValues -> DEBU 3f7[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:21:21.956 UTC [common/channelconfig] initializeProtosStruct -> DEBU 3f8[0m Processing field: MSP
[36m2019-01-29 11:21:21.956 UTC [common/channelconfig] Validate -> DEBU 3f9[0m Anchor peers for org Hospital3MSP are anchor_peers:<host:"peer0.hospital3.switch2logic.co.za" port:7051 > 
[36m2019-01-29 11:21:21.956 UTC [common/channelconfig] validateMSP -> DEBU 3fa[0m Setting up MSP for org Hospital3MSP
[36m2019-01-29 11:21:21.956 UTC [msp] newBccspMsp -> DEBU 3fb[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:21:21.956 UTC [msp] New -> DEBU 3fc[0m Creating Cache-MSP instance
[36m2019-01-29 11:21:21.956 UTC [msp] Setup -> DEBU 3fd[0m Setting up MSP instance Hospital3MSP
[36m2019-01-29 11:21:21.956 UTC [msp/identity] newIdentity -> DEBU 3fe[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdTCCAhugAwIBAgIQCCXeHGgObIJo8aq4AdvgVjAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMy5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQm1Oo/AEu7ZZToE15Y5ntlaN128Hs/exX3jNH5nO6r4tvyFtBBNEn1ecXxxPtm
dmQ+nPHONorLwDC42SMAKwfro18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCA7vVWFXWpgZBojQ1ZL
xUvgBLeia59MivIRcjxmYanpyTAKBggqhkjOPQQDAgNIADBFAiEAlOUoPtpfO8V7
vFRCanjU5zZWGO5ajFlPDJjjDTy3UrwCICrUYV32JrR/m3dslCl15dSThHrKtYCC
Ehvyw1+lNqiG
-----END CERTIFICATE-----
[36m2019-01-29 11:21:21.957 UTC [msp/identity] newIdentity -> DEBU 3ff[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAI8BA/5Jf+5m8ncI+D7aSiMwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwzLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABF1IehIKIjh8tXYZ7rw4QOuc
g/tpBAkJeOt44zr/LepbjhyFW8vIRnkw75i6Wcg+LOoAS+2NFNg2oNjqg//yCHWj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIDu9
VYVdamBkGiNDVkvFS+AEt6Jrn0yK8hFyPGZhqenJMAoGCCqGSM49BAMCA0cAMEQC
IFyc85pwbCAxGNdw4fflsX2I3HrP3h93YAB2zSDC8HtkAiAQxblAZfEnXUiQKrqE
8I10bYJqD6pJz1jb3Pv+4xplTA==
-----END CERTIFICATE-----
[36m2019-01-29 11:21:21.958 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 400[0m Checking if identity satisfies role [CLIENT] for Hospital3MSP
[36m2019-01-29 11:21:21.958 UTC [msp] Validate -> DEBU 401[0m MSP Hospital3MSP validating identity
[36m2019-01-29 11:21:21.958 UTC [msp] getCertificationChain -> DEBU 402[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 11:21:21.958 UTC [msp] hasOURole -> DEBU 403[0m MSP Hospital3MSP checking if the identity is a client
[36m2019-01-29 11:21:21.964 UTC [msp] getCertificationChain -> DEBU 404[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 11:21:21.965 UTC [common/channelconfig] NewStandardValues -> DEBU 405[0m Initializing protos for *channelconfig.OrdererProtos
[36m2019-01-29 11:21:21.965 UTC [common/channelconfig] initializeProtosStruct -> DEBU 406[0m Processing field: ConsensusType
[36m2019-01-29 11:21:21.965 UTC [common/channelconfig] initializeProtosStruct -> DEBU 407[0m Processing field: BatchSize
[36m2019-01-29 11:21:21.965 UTC [common/channelconfig] initializeProtosStruct -> DEBU 408[0m Processing field: BatchTimeout
[36m2019-01-29 11:21:21.965 UTC [common/channelconfig] initializeProtosStruct -> DEBU 409[0m Processing field: KafkaBrokers
[36m2019-01-29 11:21:21.965 UTC [common/channelconfig] initializeProtosStruct -> DEBU 40a[0m Processing field: ChannelRestrictions
[36m2019-01-29 11:21:21.965 UTC [common/channelconfig] initializeProtosStruct -> DEBU 40b[0m Processing field: Capabilities
[36m2019-01-29 11:21:21.966 UTC [common/channelconfig] NewStandardValues -> DEBU 40c[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:21:21.966 UTC [common/channelconfig] initializeProtosStruct -> DEBU 40d[0m Processing field: MSP
[36m2019-01-29 11:21:21.966 UTC [common/channelconfig] validateMSP -> DEBU 40e[0m Setting up MSP for org OrdererOrg
[36m2019-01-29 11:21:21.966 UTC [msp] newBccspMsp -> DEBU 40f[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:21:21.966 UTC [msp] New -> DEBU 410[0m Creating Cache-MSP instance
[36m2019-01-29 11:21:21.966 UTC [msp] Setup -> DEBU 411[0m Setting up MSP instance OrdererMSP
[36m2019-01-29 11:21:21.966 UTC [msp/identity] newIdentity -> DEBU 412[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICSzCCAfKgAwIBAgIRAO7EFp+tGDrZX/4Yn1ExG4IwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowdzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEe
MBwGA1UEAxMVY2Euc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZI
zj0DAQcDQgAE+ci0VrQQEnBN2VlYMEvGL0RvqwQ9zVhgyxdKDi9AB8iyQ0dhyWzJ
CZ9MnAWGk29pw9b+9HdNkbalpJKWkcctJ6NfMF0wDgYDVR0PAQH/BAQDAgGmMA8G
A1UdJQQIMAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgGIY2e0Pm
0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDRwAwRAIgcoBa
RHN5r57Qu7sd8TwCzfyJI+uozczAYI2SsN06iKgCIAeAP4FbTHxjqSLcNZMNGbTZ
YWA1h+rDBMa99duId/0D
-----END CERTIFICATE-----
[36m2019-01-29 11:21:21.967 UTC [msp/identity] newIdentity -> DEBU 413[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICHzCCAcWgAwIBAgIQRo5Qm6m11gCv1i2SXwRJAjAKBggqhkjOPQQDAjB3MQsw
CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy
YW5jaXNjbzEbMBkGA1UEChMSc3dpdGNoMmxvZ2ljLmNvLnphMR4wHAYDVQQDExVj
YS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkwMTI5MDc0MTU0WhcNMjkwMTI2MDc0
MTU0WjBdMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UE
BxMNU2FuIEZyYW5jaXNjbzEhMB8GA1UEAwwYQWRtaW5Ac3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE0QeSwnrMZdy7TKSYF/JzQ12C
vfINZcjx7xyeUuj/96gj42fjc1ctn7oo/tDl1eJNZbDhFvkRzefYmxtoSnH5Y6NN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgGIY2
e0Pm0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDSAAwRQIh
AM8EkjCZIKrAf9sL1d1fThizng+66jmEVlKPbTpimVbiAiAhCJZoeBIJGcgxbCr2
5Rd2IW34zWcPhemkNZvCKv27WA==
-----END CERTIFICATE-----
[36m2019-01-29 11:21:21.968 UTC [msp] Validate -> DEBU 414[0m MSP OrdererMSP validating identity
[36m2019-01-29 11:21:21.968 UTC [msp] Setup -> DEBU 415[0m Setting up the MSP manager (4 msps)
[36m2019-01-29 11:21:21.968 UTC [msp] Setup -> DEBU 416[0m MSP manager setup complete, setup 4 msps
[36m2019-01-29 11:21:21.968 UTC [policies] NewManagerImpl -> DEBU 417[0m Proposed new policy Admins for Channel/Application/Hospital1MSP
[36m2019-01-29 11:21:21.968 UTC [policies] NewManagerImpl -> DEBU 418[0m Proposed new policy Readers for Channel/Application/Hospital1MSP
[36m2019-01-29 11:21:21.968 UTC [policies] NewManagerImpl -> DEBU 419[0m Proposed new policy Writers for Channel/Application/Hospital1MSP
[36m2019-01-29 11:21:21.968 UTC [policies] NewManagerImpl -> DEBU 41a[0m Proposed new policy Readers for Channel/Application/Hospital2MSP
[36m2019-01-29 11:21:21.968 UTC [policies] NewManagerImpl -> DEBU 41b[0m Proposed new policy Writers for Channel/Application/Hospital2MSP
[36m2019-01-29 11:21:21.968 UTC [policies] NewManagerImpl -> DEBU 41c[0m Proposed new policy Admins for Channel/Application/Hospital2MSP
[36m2019-01-29 11:21:21.968 UTC [policies] NewManagerImpl -> DEBU 41d[0m Proposed new policy Admins for Channel/Application/Hospital3MSP
[36m2019-01-29 11:21:21.968 UTC [policies] NewManagerImpl -> DEBU 41e[0m Proposed new policy Readers for Channel/Application/Hospital3MSP
[36m2019-01-29 11:21:21.969 UTC [policies] NewManagerImpl -> DEBU 41f[0m Proposed new policy Writers for Channel/Application/Hospital3MSP
[36m2019-01-29 11:21:21.969 UTC [policies] NewManagerImpl -> DEBU 420[0m Proposed new policy Writers for Channel/Application
[36m2019-01-29 11:21:21.969 UTC [policies] NewManagerImpl -> DEBU 421[0m Proposed new policy Admins for Channel/Application
[36m2019-01-29 11:21:21.969 UTC [policies] NewManagerImpl -> DEBU 422[0m Proposed new policy Readers for Channel/Application
[36m2019-01-29 11:21:21.969 UTC [policies] NewManagerImpl -> DEBU 423[0m Proposed new policy Writers for Channel/Orderer/OrdererOrg
[36m2019-01-29 11:21:21.969 UTC [policies] NewManagerImpl -> DEBU 424[0m Proposed new policy Admins for Channel/Orderer/OrdererOrg
[36m2019-01-29 11:21:21.970 UTC [policies] NewManagerImpl -> DEBU 425[0m Proposed new policy Readers for Channel/Orderer/OrdererOrg
[36m2019-01-29 11:21:21.970 UTC [policies] NewManagerImpl -> DEBU 426[0m Proposed new policy BlockValidation for Channel/Orderer
[36m2019-01-29 11:21:21.970 UTC [policies] NewManagerImpl -> DEBU 427[0m Proposed new policy Admins for Channel/Orderer
[36m2019-01-29 11:21:21.970 UTC [policies] NewManagerImpl -> DEBU 428[0m Proposed new policy Readers for Channel/Orderer
[36m2019-01-29 11:21:21.970 UTC [policies] NewManagerImpl -> DEBU 429[0m Proposed new policy Writers for Channel/Orderer
[36m2019-01-29 11:21:21.970 UTC [policies] NewManagerImpl -> DEBU 42a[0m Proposed new policy Admins for Channel
[36m2019-01-29 11:21:21.971 UTC [policies] NewManagerImpl -> DEBU 42b[0m Proposed new policy Readers for Channel
[36m2019-01-29 11:21:21.971 UTC [policies] NewManagerImpl -> DEBU 42c[0m Proposed new policy Writers for Channel
[36m2019-01-29 11:21:21.971 UTC [common/configtx] addToMap -> DEBU 42d[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 11:21:21.971 UTC [common/configtx] addToMap -> DEBU 42e[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 11:21:21.971 UTC [common/configtx] addToMap -> DEBU 42f[0m Adding to config map: [Group]  /Channel/Application/Hospital1MSP
[36m2019-01-29 11:21:21.971 UTC [common/configtx] addToMap -> DEBU 430[0m Adding to config map: [Value]  /Channel/Application/Hospital1MSP/MSP
[36m2019-01-29 11:21:21.972 UTC [common/configtx] addToMap -> DEBU 431[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Admins
[36m2019-01-29 11:21:21.972 UTC [common/configtx] addToMap -> DEBU 432[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Readers
[36m2019-01-29 11:21:21.972 UTC [common/configtx] addToMap -> DEBU 433[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Writers
[36m2019-01-29 11:21:21.972 UTC [common/configtx] addToMap -> DEBU 434[0m Adding to config map: [Group]  /Channel/Application/Hospital2MSP
[36m2019-01-29 11:21:21.972 UTC [common/configtx] addToMap -> DEBU 435[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/MSP
[36m2019-01-29 11:21:21.972 UTC [common/configtx] addToMap -> DEBU 436[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 11:21:21.973 UTC [common/configtx] addToMap -> DEBU 437[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 11:21:21.973 UTC [common/configtx] addToMap -> DEBU 438[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 11:21:21.973 UTC [common/configtx] addToMap -> DEBU 439[0m Adding to config map: [Group]  /Channel/Application/Hospital3MSP
[36m2019-01-29 11:21:21.973 UTC [common/configtx] addToMap -> DEBU 43a[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/MSP
[36m2019-01-29 11:21:21.974 UTC [common/configtx] addToMap -> DEBU 43b[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/AnchorPeers
[36m2019-01-29 11:21:21.974 UTC [common/configtx] addToMap -> DEBU 43c[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Writers
[36m2019-01-29 11:21:21.974 UTC [common/configtx] addToMap -> DEBU 43d[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Admins
[36m2019-01-29 11:21:21.974 UTC [common/configtx] addToMap -> DEBU 43e[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Readers
[36m2019-01-29 11:21:21.974 UTC [common/configtx] addToMap -> DEBU 43f[0m Adding to config map: [Value]  /Channel/Application/Capabilities
[36m2019-01-29 11:21:21.974 UTC [common/configtx] addToMap -> DEBU 440[0m Adding to config map: [Policy] /Channel/Application/Writers
[36m2019-01-29 11:21:21.974 UTC [common/configtx] addToMap -> DEBU 441[0m Adding to config map: [Policy] /Channel/Application/Admins
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 442[0m Adding to config map: [Policy] /Channel/Application/Readers
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 443[0m Adding to config map: [Group]  /Channel/Orderer
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 444[0m Adding to config map: [Group]  /Channel/Orderer/OrdererOrg
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 445[0m Adding to config map: [Value]  /Channel/Orderer/OrdererOrg/MSP
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 446[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Admins
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 447[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Readers
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 448[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Writers
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 449[0m Adding to config map: [Value]  /Channel/Orderer/ChannelRestrictions
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 44a[0m Adding to config map: [Value]  /Channel/Orderer/Capabilities
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 44b[0m Adding to config map: [Value]  /Channel/Orderer/KafkaBrokers
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 44c[0m Adding to config map: [Value]  /Channel/Orderer/ConsensusType
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 44d[0m Adding to config map: [Value]  /Channel/Orderer/BatchSize
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 44e[0m Adding to config map: [Value]  /Channel/Orderer/BatchTimeout
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 44f[0m Adding to config map: [Policy] /Channel/Orderer/BlockValidation
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 450[0m Adding to config map: [Policy] /Channel/Orderer/Admins
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 451[0m Adding to config map: [Policy] /Channel/Orderer/Readers
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 452[0m Adding to config map: [Policy] /Channel/Orderer/Writers
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 453[0m Adding to config map: [Value]  /Channel/HashingAlgorithm
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 454[0m Adding to config map: [Value]  /Channel/BlockDataHashingStructure
[36m2019-01-29 11:21:21.975 UTC [common/configtx] addToMap -> DEBU 455[0m Adding to config map: [Value]  /Channel/OrdererAddresses
[36m2019-01-29 11:21:21.976 UTC [common/configtx] addToMap -> DEBU 456[0m Adding to config map: [Value]  /Channel/Capabilities
[36m2019-01-29 11:21:21.976 UTC [common/configtx] addToMap -> DEBU 457[0m Adding to config map: [Value]  /Channel/Consortium
[36m2019-01-29 11:21:21.976 UTC [common/configtx] addToMap -> DEBU 458[0m Adding to config map: [Policy] /Channel/Admins
[36m2019-01-29 11:21:21.976 UTC [common/configtx] addToMap -> DEBU 459[0m Adding to config map: [Policy] /Channel/Readers
[36m2019-01-29 11:21:21.976 UTC [common/configtx] addToMap -> DEBU 45a[0m Adding to config map: [Policy] /Channel/Writers
[36m2019-01-29 11:21:21.976 UTC [common/channelconfig] LogSanityChecks -> DEBU 45b[0m As expected, current configuration has policy '/Channel/Readers'
[36m2019-01-29 11:21:21.976 UTC [common/channelconfig] LogSanityChecks -> DEBU 45c[0m As expected, current configuration has policy '/Channel/Writers'
[36m2019-01-29 11:21:21.976 UTC [policies] Manager -> DEBU 45d[0m Manager Channel looking up path [Application]
[36m2019-01-29 11:21:21.976 UTC [policies] Manager -> DEBU 45e[0m Manager Channel has managers Orderer
[36m2019-01-29 11:21:21.976 UTC [policies] Manager -> DEBU 45f[0m Manager Channel has managers Application
[36m2019-01-29 11:21:21.976 UTC [policies] Manager -> DEBU 460[0m Manager Channel/Application looking up path []
[36m2019-01-29 11:21:21.976 UTC [policies] Manager -> DEBU 461[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 11:21:21.976 UTC [policies] Manager -> DEBU 462[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 11:21:21.976 UTC [policies] Manager -> DEBU 463[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 11:21:21.976 UTC [common/channelconfig] LogSanityChecks -> DEBU 464[0m As expected, current configuration has policy '/Channel/Application/Readers'
[36m2019-01-29 11:21:21.976 UTC [common/channelconfig] LogSanityChecks -> DEBU 465[0m As expected, current configuration has policy '/Channel/Application/Writers'
[36m2019-01-29 11:21:21.977 UTC [common/channelconfig] LogSanityChecks -> DEBU 466[0m As expected, current configuration has policy '/Channel/Application/Admins'
[36m2019-01-29 11:21:21.977 UTC [policies] Manager -> DEBU 467[0m Manager Channel looking up path [Orderer]
[36m2019-01-29 11:21:21.977 UTC [policies] Manager -> DEBU 468[0m Manager Channel has managers Application
[36m2019-01-29 11:21:21.977 UTC [policies] Manager -> DEBU 469[0m Manager Channel has managers Orderer
[36m2019-01-29 11:21:21.977 UTC [policies] Manager -> DEBU 46a[0m Manager Channel/Orderer looking up path []
[36m2019-01-29 11:21:21.977 UTC [policies] Manager -> DEBU 46b[0m Manager Channel/Orderer has managers OrdererOrg
[36m2019-01-29 11:21:21.977 UTC [common/channelconfig] LogSanityChecks -> DEBU 46c[0m As expected, current configuration has policy '/Channel/Orderer/BlockValidation'
[36m2019-01-29 11:21:21.977 UTC [common/capabilities] Supported -> DEBU 46d[0m Orderer capability V1_1 is supported and is enabled
[36m2019-01-29 11:21:21.977 UTC [common/capabilities] Supported -> DEBU 46e[0m Channel capability V1_1 is supported and is enabled
[36m2019-01-29 11:21:21.978 UTC [msp] GetDefaultSigningIdentity -> DEBU 46f[0m Obtaining default signing identity
[36m2019-01-29 11:21:21.978 UTC [msp] GetDefaultSigningIdentity -> DEBU 470[0m Obtaining default signing identity
[36m2019-01-29 11:21:21.978 UTC [msp/identity] Sign -> DEBU 471[0m Sign: plaintext: 0ABD060A0A4F7264657265724D535012...2A82DF99490F6297F1B81F05E12A880C 
[36m2019-01-29 11:21:21.978 UTC [msp/identity] Sign -> DEBU 472[0m Sign: digest: 777C3069651FD005A747EE3ACBDA357BC02C73FC0191F3A9F7105CBDA88A2582 
[36m2019-01-29 11:21:21.979 UTC [orderer/commmon/multichannel] addLastConfigSignature -> DEBU 473[0m [channel: comunitychannel] Detected lastConfigSeq transitioning from 1 to 2, setting lastConfigBlockNum from 0 to 1
[36m2019-01-29 11:21:21.979 UTC [msp] GetDefaultSigningIdentity -> DEBU 474[0m Obtaining default signing identity
[36m2019-01-29 11:21:21.979 UTC [orderer/commmon/multichannel] addLastConfigSignature -> DEBU 475[0m [channel: comunitychannel] About to write block, setting its LAST_CONFIG to 1
[36m2019-01-29 11:21:21.979 UTC [msp] GetDefaultSigningIdentity -> DEBU 476[0m Obtaining default signing identity
[36m2019-01-29 11:21:21.979 UTC [msp/identity] Sign -> DEBU 477[0m Sign: plaintext: 08010ABD060A0A4F7264657265724D53...2A82DF99490F6297F1B81F05E12A880C 
[36m2019-01-29 11:21:21.979 UTC [msp/identity] Sign -> DEBU 478[0m Sign: digest: 3D3EC714674B0EF2C984E0D964255EEB6CDE975B597E4085038EA3F78A62E318 
[36m2019-01-29 11:21:21.987 UTC [fsblkstorage] indexBlock -> DEBU 479[0m Indexing block [blockNum=1, blockHash=[]byte{0x87, 0x8c, 0x57, 0x6, 0xf3, 0x2d, 0x72, 0xb7, 0x61, 0xc1, 0xd1, 0x44, 0x49, 0x9d, 0x88, 0x8a, 0xaa, 0x34, 0x55, 0x9d, 0x1d, 0xc1, 0x2d, 0x27, 0xb8, 0x2b, 0xe, 0x3d, 0x15, 0x1b, 0x33, 0x92} txOffsets=
txId= locPointer=offset=71, bytesLength=21681
]
[36m2019-01-29 11:21:21.991 UTC [fsblkstorage] updateCheckpoint -> DEBU 47a[0m Broadcasting about update checkpointInfo: latestFileChunkSuffixNum=[0], latestFileChunksize=[45385], isChainEmpty=[false], lastBlockNumber=[1]
[36m2019-01-29 11:21:21.991 UTC [orderer/commmon/multichannel] commitBlock -> DEBU 47b[0m [channel: comunitychannel] Wrote block 1
[36m2019-01-29 11:21:52.080 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 47c[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:9092
[36m2019-01-29 11:21:52.090 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 47d[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:21:52.099 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 47e[0m client/metadata fetching metadata for all topics from broker kafka1.switch2logic.co.za:9092
[36m2019-01-29 11:21:52.099 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 47f[0m client/metadata got error from broker while fetching metadata: EOF
[36m2019-01-29 11:21:52.100 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 480[0m Closed connection to broker kafka1.switch2logic.co.za:9092
[36m2019-01-29 11:21:52.100 UTC [orderer/consensus/kafka/sarama] tryRefreshMetadata -> DEBU 481[0m client/brokers deregistered broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 11:21:52.100 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 482[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:21:52.100 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 483[0m client/metadata fetching metadata for all topics from broker kafka2.switch2logic.co.za:9092
[36m2019-01-29 11:21:52.101 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 484[0m Connected to broker at kafka2.switch2logic.co.za:9092 (registered as #2)
[36m2019-01-29 11:21:52.103 UTC [orderer/consensus/kafka/sarama] updateMetadata -> DEBU 485[0m client/brokers registered new broker #1 at kafka1.switch2logic.co.za:9092
[36m2019-01-29 11:21:52.108 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 486[0m client/metadata fetching metadata for all topics from broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:22:06.139 UTC [orderer/common/server] Deliver -> DEBU 487[0m Starting new Deliver handler
[36m2019-01-29 11:22:06.139 UTC [common/deliver] Handle -> DEBU 488[0m Starting new deliver loop for 10.0.0.38:40154
[36m2019-01-29 11:22:06.139 UTC [common/deliver] Handle -> DEBU 489[0m Attempting to read seek info message from 10.0.0.38:40154
[36m2019-01-29 11:22:06.145 UTC [orderer/common/server] Broadcast -> DEBU 48a[0m Starting new Broadcast handler
[36m2019-01-29 11:22:06.145 UTC [orderer/common/broadcast] Handle -> DEBU 48b[0m Starting new broadcast loop for 10.0.0.38:40156
[36m2019-01-29 11:22:06.145 UTC [orderer/common/broadcast] Handle -> DEBU 48c[0m [channel: comunitychannel] Broadcast is processing config update message from 10.0.0.38:40156
[36m2019-01-29 11:22:06.146 UTC [orderer/common/msgprocessor] ProcessConfigUpdateMsg -> DEBU 48d[0m Processing config update message for channel comunitychannel
[36m2019-01-29 11:22:06.146 UTC [policies] Evaluate -> DEBU 48e[0m == Evaluating *policies.implicitMetaPolicy Policy /Channel/Writers ==
[36m2019-01-29 11:22:06.146 UTC [policies] Evaluate -> DEBU 48f[0m This is an implicit meta policy, it will trigger other policy evaluations, whose failures may be benign
[36m2019-01-29 11:22:06.146 UTC [policies] Evaluate -> DEBU 490[0m == Evaluating *policies.implicitMetaPolicy Policy /Channel/Application/Writers ==
[36m2019-01-29 11:22:06.146 UTC [policies] Evaluate -> DEBU 491[0m This is an implicit meta policy, it will trigger other policy evaluations, whose failures may be benign
[36m2019-01-29 11:22:06.146 UTC [policies] Evaluate -> DEBU 492[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital1MSP/Writers ==
2019-01-29 11:22:06.146 UTC [msp] DeserializeIdentity -> INFO 493[0m Obtaining identity
[36m2019-01-29 11:22:06.146 UTC [msp/identity] newIdentity -> DEBU 494[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAJ6XtHMTTW1JzdpD54qCc3wwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwyLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABA+z1rb9aA1HwHfNLi9V9VZe
bdwT4MXak445zGz4DXzRUsmNeBngzntKb6qpgHQpeFtzbzLx+zwiynRDvfdzORGj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIPEC
alij2l9uByDcEUurCDRUsEQ/uONP3HEp7xVWhhduMAoGCCqGSM49BAMCA0cAMEQC
IA8A3CCJeCasyy7gYd/M1aHYmwWsecY7UY7cVUGy4XOxAiB0rrmfnGW6JA11PDCu
+5c5Rpn0jF5ddsFn+UIpzBFvmg==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.146 UTC [cauthdsl] func1 -> DEBU 495[0m 0xc42000e060 gate 1548760926146745054 evaluation starts
[36m2019-01-29 11:22:06.146 UTC [cauthdsl] func2 -> DEBU 496[0m 0xc42000e060 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:22:06.146 UTC [cauthdsl] func2 -> DEBU 497[0m 0xc42000e060 processing identity 0 with bytes of 0a0c486f73706974616c324d535012df062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d494943547a4343416661674177494241674952414a365874484d545457314a7a6470443534714363337777436759494b6f5a497a6a304541774977675973780a437a414a42674e5642415954416c56544d524d77455159445651514945777044595778705a6d3979626d6c684d525977464159445651514845773154595734670a526e4a68626d4e7063324e764d535577497759445651514b4578786f62334e7761585268624449756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70680a4d5367774a675944565151444578396a5953356f62334e7761585268624449756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445350a4d4445794f5441334e4445314e466f58445449354d4445794e6a41334e4445314e466f776544454c4d416b474131554542684d4356564d78457a415242674e560a42416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e6862694247636d467559326c7a59323878447a414e42674e56424173540a426d4e7361575675644445724d436b47413155454177776951575274615735416147397a63476c30595777794c6e4e336158526a61444a73623264705979356a0a627935365954425a4d424d4742797147534d34394167454743437147534d3439417745484130494142412b7a31726239614131487748664e4c69395639565a650a62647754344d58616b3434357a477a3444587a5255736d4e65426e677a6e744b62367170674851706546747a627a4c782b7a7769796e52447666647a4f52476a0a5454424c4d41344741315564447745422f775145417749486744414d42674e5648524d4241663845416a41414d437347413155644977516b4d434b41495045430a616c696a326c39754279446345557572434452557345512f754f4e503348457037785657686864754d416f4743437147534d343942414d43413063414d4551430a494138413343434a654361737979376759642f4d316148596d77577365635937555937635655477934584f784169423072726d666e4757364a413131504443750a2b35633552706e306a4635646473466e2b5549707a4246766d673d3d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:22:06.146 UTC [cauthdsl] func2 -> DEBU 498[0m 0xc42000e060 identity 0 does not satisfy principal: the identity is a member of a different MSP (expected Hospital1MSP, got Hospital2MSP)
[36m2019-01-29 11:22:06.146 UTC [cauthdsl] func2 -> DEBU 499[0m 0xc42000e060 principal evaluation fails
[36m2019-01-29 11:22:06.146 UTC [cauthdsl] func1 -> DEBU 49a[0m 0xc42000e060 gate 1548760926146745054 evaluation fails
[36m2019-01-29 11:22:06.146 UTC [policies] Evaluate -> DEBU 49b[0m Signature set did not satisfy policy /Channel/Application/Hospital1MSP/Writers
[36m2019-01-29 11:22:06.146 UTC [policies] Evaluate -> DEBU 49c[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital1MSP/Writers
[36m2019-01-29 11:22:06.146 UTC [policies] Evaluate -> DEBU 49d[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital2MSP/Writers ==
[36m2019-01-29 11:22:06.147 UTC [cauthdsl] func1 -> DEBU 49e[0m 0xc42000e088 gate 1548760926147005781 evaluation starts
[36m2019-01-29 11:22:06.147 UTC [cauthdsl] func2 -> DEBU 49f[0m 0xc42000e088 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:22:06.147 UTC [cauthdsl] func2 -> DEBU 4a0[0m 0xc42000e088 processing identity 0 with bytes of 0a0c486f73706974616c324d535012df062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d494943547a4343416661674177494241674952414a365874484d545457314a7a6470443534714363337777436759494b6f5a497a6a304541774977675973780a437a414a42674e5642415954416c56544d524d77455159445651514945777044595778705a6d3979626d6c684d525977464159445651514845773154595734670a526e4a68626d4e7063324e764d535577497759445651514b4578786f62334e7761585268624449756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70680a4d5367774a675944565151444578396a5953356f62334e7761585268624449756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445350a4d4445794f5441334e4445314e466f58445449354d4445794e6a41334e4445314e466f776544454c4d416b474131554542684d4356564d78457a415242674e560a42416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e6862694247636d467559326c7a59323878447a414e42674e56424173540a426d4e7361575675644445724d436b47413155454177776951575274615735416147397a63476c30595777794c6e4e336158526a61444a73623264705979356a0a627935365954425a4d424d4742797147534d34394167454743437147534d3439417745484130494142412b7a31726239614131487748664e4c69395639565a650a62647754344d58616b3434357a477a3444587a5255736d4e65426e677a6e744b62367170674851706546747a627a4c782b7a7769796e52447666647a4f52476a0a5454424c4d41344741315564447745422f775145417749486744414d42674e5648524d4241663845416a41414d437347413155644977516b4d434b41495045430a616c696a326c39754279446345557572434452557345512f754f4e503348457037785657686864754d416f4743437147534d343942414d43413063414d4551430a494138413343434a654361737979376759642f4d316148596d77577365635937555937635655477934584f784169423072726d666e4757364a413131504443750a2b35633552706e306a4635646473466e2b5549707a4246766d673d3d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:22:06.147 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 4a1[0m Checking if identity satisfies MEMBER role for Hospital2MSP
[36m2019-01-29 11:22:06.147 UTC [msp] Validate -> DEBU 4a2[0m MSP Hospital2MSP validating identity
[36m2019-01-29 11:22:06.147 UTC [msp] getCertificationChain -> DEBU 4a3[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 11:22:06.147 UTC [cauthdsl] func2 -> DEBU 4a4[0m 0xc42000e088 principal matched by identity 0
[36m2019-01-29 11:22:06.147 UTC [msp/identity] Verify -> DEBU 4a5[0m Verify: digest = 00000000  91 4b 46 b5 df 91 0b 6c  be 74 f1 98 69 a3 8c d8  |.KF....l.t..i...|
00000010  b5 cf ee 1d 95 9c a6 53  da 87 4f 54 67 f4 09 9e  |.......S..OTg...|
[36m2019-01-29 11:22:06.147 UTC [msp/identity] Verify -> DEBU 4a6[0m Verify: sig = 00000000  30 44 02 20 72 f0 12 92  3b d5 14 8e 52 79 bb 35  |0D. r...;...Ry.5|
00000010  50 f9 9f d6 c7 ea 65 4e  1a 23 40 f6 15 8a 81 b1  |P.....eN.#@.....|
00000020  92 47 ed 7f 02 20 2b 9e  0a ca d0 ef e0 5b 3b 4a  |.G... +......[;J|
00000030  de 52 a6 ff a4 fc 9d 48  05 e7 0f c1 a6 f7 e0 81  |.R.....H........|
00000040  a0 16 b9 35 0b eb                                 |...5..|
[36m2019-01-29 11:22:06.147 UTC [cauthdsl] func2 -> DEBU 4a7[0m 0xc42000e088 principal evaluation succeeds for identity 0
[36m2019-01-29 11:22:06.147 UTC [cauthdsl] func1 -> DEBU 4a8[0m 0xc42000e088 gate 1548760926147005781 evaluation succeeds
[36m2019-01-29 11:22:06.147 UTC [policies] Evaluate -> DEBU 4a9[0m Signature set satisfies policy /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 11:22:06.147 UTC [policies] Evaluate -> DEBU 4aa[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 11:22:06.147 UTC [policies] Evaluate -> DEBU 4ab[0m Signature set satisfies policy /Channel/Application/Writers
[36m2019-01-29 11:22:06.147 UTC [policies] Evaluate -> DEBU 4ac[0m == Done Evaluating *policies.implicitMetaPolicy Policy /Channel/Application/Writers
[36m2019-01-29 11:22:06.147 UTC [policies] Evaluate -> DEBU 4ad[0m Signature set satisfies policy /Channel/Writers
[36m2019-01-29 11:22:06.147 UTC [policies] Evaluate -> DEBU 4ae[0m == Done Evaluating *policies.implicitMetaPolicy Policy /Channel/Writers
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4af[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4b0[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4b1[0m Adding to config map: [Group]  /Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4b2[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/MSP
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4b3[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4b4[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4b5[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4b6[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4b7[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4b8[0m Adding to config map: [Group]  /Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4b9[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/AnchorPeers
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4ba[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/MSP
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4bb[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4bc[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 11:22:06.148 UTC [common/configtx] addToMap -> DEBU 4bd[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 11:22:06.148 UTC [common/configtx] verifyDeltaSet -> DEBU 4be[0m Processing change to key: [Group]  /Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.148 UTC [common/configtx] policyForItem -> DEBU 4bf[0m Getting policy for item Hospital2MSP with mod_policy Admins
[36m2019-01-29 11:22:06.148 UTC [policies] Manager -> DEBU 4c0[0m Manager Channel looking up path [Application]
[36m2019-01-29 11:22:06.148 UTC [policies] Manager -> DEBU 4c1[0m Manager Channel has managers Orderer
[36m2019-01-29 11:22:06.148 UTC [policies] Manager -> DEBU 4c2[0m Manager Channel has managers Application
[36m2019-01-29 11:22:06.148 UTC [policies] Manager -> DEBU 4c3[0m Manager Channel/Application looking up path []
[36m2019-01-29 11:22:06.148 UTC [policies] Manager -> DEBU 4c4[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 11:22:06.148 UTC [policies] Manager -> DEBU 4c5[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 11:22:06.148 UTC [policies] Manager -> DEBU 4c6[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 11:22:06.148 UTC [policies] Manager -> DEBU 4c7[0m Manager Channel/Application looking up path [Hospital2MSP]
[36m2019-01-29 11:22:06.148 UTC [policies] Manager -> DEBU 4c8[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 11:22:06.148 UTC [policies] Manager -> DEBU 4c9[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 11:22:06.148 UTC [policies] Manager -> DEBU 4ca[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 11:22:06.148 UTC [policies] Manager -> DEBU 4cb[0m Manager Channel/Application/Hospital2MSP looking up path []
[36m2019-01-29 11:22:06.148 UTC [policies] Evaluate -> DEBU 4cc[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital2MSP/Admins ==
[36m2019-01-29 11:22:06.148 UTC [cauthdsl] func1 -> DEBU 4cd[0m 0xc42000e310 gate 1548760926148785056 evaluation starts
[36m2019-01-29 11:22:06.148 UTC [cauthdsl] func2 -> DEBU 4ce[0m 0xc42000e310 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:22:06.148 UTC [cauthdsl] func2 -> DEBU 4cf[0m 0xc42000e310 processing identity 0 with bytes of 0a0c486f73706974616c324d535012df062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d494943547a4343416661674177494241674952414a365874484d545457314a7a6470443534714363337777436759494b6f5a497a6a304541774977675973780a437a414a42674e5642415954416c56544d524d77455159445651514945777044595778705a6d3979626d6c684d525977464159445651514845773154595734670a526e4a68626d4e7063324e764d535577497759445651514b4578786f62334e7761585268624449756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70680a4d5367774a675944565151444578396a5953356f62334e7761585268624449756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445350a4d4445794f5441334e4445314e466f58445449354d4445794e6a41334e4445314e466f776544454c4d416b474131554542684d4356564d78457a415242674e560a42416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e6862694247636d467559326c7a59323878447a414e42674e56424173540a426d4e7361575675644445724d436b47413155454177776951575274615735416147397a63476c30595777794c6e4e336158526a61444a73623264705979356a0a627935365954425a4d424d4742797147534d34394167454743437147534d3439417745484130494142412b7a31726239614131487748664e4c69395639565a650a62647754344d58616b3434357a477a3444587a5255736d4e65426e677a6e744b62367170674851706546747a627a4c782b7a7769796e52447666647a4f52476a0a5454424c4d41344741315564447745422f775145417749486744414d42674e5648524d4241663845416a41414d437347413155644977516b4d434b41495045430a616c696a326c39754279446345557572434452557345512f754f4e503348457037785657686864754d416f4743437147534d343942414d43413063414d4551430a494138413343434a654361737979376759642f4d316148596d77577365635937555937635655477934584f784169423072726d666e4757364a413131504443750a2b35633552706e306a4635646473466e2b5549707a4246766d673d3d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:22:06.148 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 4d0[0m Checking if identity satisfies ADMIN role for Hospital2MSP
[36m2019-01-29 11:22:06.148 UTC [cauthdsl] func2 -> DEBU 4d1[0m 0xc42000e310 principal matched by identity 0
[36m2019-01-29 11:22:06.148 UTC [msp/identity] Verify -> DEBU 4d2[0m Verify: digest = 00000000  8a d5 75 1d 1c c2 e6 24  2a 57 ab a4 f6 2e f5 ec  |..u....$*W......|
00000010  5b 3c 08 a2 15 39 d8 3b  09 36 09 a5 d9 fd e3 ed  |[<...9.;.6......|
[36m2019-01-29 11:22:06.148 UTC [msp/identity] Verify -> DEBU 4d3[0m Verify: sig = 00000000  30 44 02 20 6d 2a 1a 23  06 d6 7f 73 ea b2 4b 36  |0D. m*.#...s..K6|
00000010  b1 d5 e2 49 36 e6 61 25  e2 e5 58 86 3f 5e 03 f7  |...I6.a%..X.?^..|
00000020  cf e5 3d d0 02 20 7b e4  ee b4 5a 91 13 f9 ae 06  |..=.. {...Z.....|
00000030  6f bf 68 b3 84 fb 3a 37  49 98 5d 67 b6 c9 9b 00  |o.h...:7I.]g....|
00000040  54 66 c1 84 87 98                                 |Tf....|
[36m2019-01-29 11:22:06.149 UTC [cauthdsl] func2 -> DEBU 4d4[0m 0xc42000e310 principal evaluation succeeds for identity 0
[36m2019-01-29 11:22:06.149 UTC [cauthdsl] func1 -> DEBU 4d5[0m 0xc42000e310 gate 1548760926148785056 evaluation succeeds
[36m2019-01-29 11:22:06.149 UTC [policies] Evaluate -> DEBU 4d6[0m Signature set satisfies policy /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 11:22:06.149 UTC [policies] Evaluate -> DEBU 4d7[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 11:22:06.149 UTC [common/configtx] verifyDeltaSet -> DEBU 4d8[0m Processing change to key: [Value]  /Channel/Application/Hospital2MSP/AnchorPeers
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4d9[0m Setting policy for key Admins to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\022\022\020\n\014Hospital1MSP\020\001" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4da[0m Setting policy for key Readers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital1MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4db[0m Setting policy for key Writers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital1MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4dc[0m Setting policy for key Readers to 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4dd[0m Setting policy for key Writers to 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4de[0m Setting policy for key Admins to 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4df[0m Setting policy for key Writers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital3MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4e0[0m Setting policy for key Admins to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\022\022\020\n\014Hospital3MSP\020\001" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4e1[0m Setting policy for key Readers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital3MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4e2[0m Setting policy for key Writers to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4e3[0m Setting policy for key Admins to policy:<type:3 value:"\n\006Admins\020\002" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4e4[0m Setting policy for key Readers to policy:<type:3 value:"\n\007Readers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4e5[0m Setting policy for key Admins to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\nOrdererMSP\020\001" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4e6[0m Setting policy for key Readers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\016\022\014\n\nOrdererMSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.149 UTC [common/configtx] recurseConfigMap -> DEBU 4e7[0m Setting policy for key Writers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\016\022\014\n\nOrdererMSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.150 UTC [common/configtx] recurseConfigMap -> DEBU 4e8[0m Setting policy for key BlockValidation to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.150 UTC [common/configtx] recurseConfigMap -> DEBU 4e9[0m Setting policy for key Admins to policy:<type:3 value:"\n\006Admins\020\002" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.150 UTC [common/configtx] recurseConfigMap -> DEBU 4ea[0m Setting policy for key Readers to policy:<type:3 value:"\n\007Readers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.150 UTC [common/configtx] recurseConfigMap -> DEBU 4eb[0m Setting policy for key Writers to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.150 UTC [common/configtx] recurseConfigMap -> DEBU 4ec[0m Setting policy for key Readers to policy:<type:3 value:"\n\007Readers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.150 UTC [common/configtx] recurseConfigMap -> DEBU 4ed[0m Setting policy for key Writers to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.150 UTC [common/configtx] recurseConfigMap -> DEBU 4ee[0m Setting policy for key Admins to policy:<type:3 value:"\n\006Admins\020\002" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] NewStandardValues -> DEBU 4ef[0m Initializing protos for *channelconfig.ChannelProtos
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] initializeProtosStruct -> DEBU 4f0[0m Processing field: HashingAlgorithm
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] initializeProtosStruct -> DEBU 4f1[0m Processing field: BlockDataHashingStructure
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] initializeProtosStruct -> DEBU 4f2[0m Processing field: OrdererAddresses
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] initializeProtosStruct -> DEBU 4f3[0m Processing field: Consortium
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] initializeProtosStruct -> DEBU 4f4[0m Processing field: Capabilities
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] NewStandardValues -> DEBU 4f5[0m Initializing protos for *channelconfig.OrdererProtos
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] initializeProtosStruct -> DEBU 4f6[0m Processing field: ConsensusType
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] initializeProtosStruct -> DEBU 4f7[0m Processing field: BatchSize
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] initializeProtosStruct -> DEBU 4f8[0m Processing field: BatchTimeout
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] initializeProtosStruct -> DEBU 4f9[0m Processing field: KafkaBrokers
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] initializeProtosStruct -> DEBU 4fa[0m Processing field: ChannelRestrictions
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] initializeProtosStruct -> DEBU 4fb[0m Processing field: Capabilities
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] NewStandardValues -> DEBU 4fc[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] initializeProtosStruct -> DEBU 4fd[0m Processing field: MSP
[36m2019-01-29 11:22:06.150 UTC [common/channelconfig] validateMSP -> DEBU 4fe[0m Setting up MSP for org OrdererOrg
[36m2019-01-29 11:22:06.150 UTC [msp] newBccspMsp -> DEBU 4ff[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:22:06.150 UTC [msp] New -> DEBU 500[0m Creating Cache-MSP instance
[36m2019-01-29 11:22:06.150 UTC [msp] Setup -> DEBU 501[0m Setting up MSP instance OrdererMSP
[36m2019-01-29 11:22:06.150 UTC [msp/identity] newIdentity -> DEBU 502[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICSzCCAfKgAwIBAgIRAO7EFp+tGDrZX/4Yn1ExG4IwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowdzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEe
MBwGA1UEAxMVY2Euc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZI
zj0DAQcDQgAE+ci0VrQQEnBN2VlYMEvGL0RvqwQ9zVhgyxdKDi9AB8iyQ0dhyWzJ
CZ9MnAWGk29pw9b+9HdNkbalpJKWkcctJ6NfMF0wDgYDVR0PAQH/BAQDAgGmMA8G
A1UdJQQIMAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgGIY2e0Pm
0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDRwAwRAIgcoBa
RHN5r57Qu7sd8TwCzfyJI+uozczAYI2SsN06iKgCIAeAP4FbTHxjqSLcNZMNGbTZ
YWA1h+rDBMa99duId/0D
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.151 UTC [msp/identity] newIdentity -> DEBU 503[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICHzCCAcWgAwIBAgIQRo5Qm6m11gCv1i2SXwRJAjAKBggqhkjOPQQDAjB3MQsw
CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy
YW5jaXNjbzEbMBkGA1UEChMSc3dpdGNoMmxvZ2ljLmNvLnphMR4wHAYDVQQDExVj
YS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkwMTI5MDc0MTU0WhcNMjkwMTI2MDc0
MTU0WjBdMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UE
BxMNU2FuIEZyYW5jaXNjbzEhMB8GA1UEAwwYQWRtaW5Ac3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE0QeSwnrMZdy7TKSYF/JzQ12C
vfINZcjx7xyeUuj/96gj42fjc1ctn7oo/tDl1eJNZbDhFvkRzefYmxtoSnH5Y6NN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgGIY2
e0Pm0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDSAAwRQIh
AM8EkjCZIKrAf9sL1d1fThizng+66jmEVlKPbTpimVbiAiAhCJZoeBIJGcgxbCr2
5Rd2IW34zWcPhemkNZvCKv27WA==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.151 UTC [msp] Validate -> DEBU 504[0m MSP OrdererMSP validating identity
[36m2019-01-29 11:22:06.151 UTC [common/channelconfig] NewStandardValues -> DEBU 505[0m Initializing protos for *channelconfig.ApplicationProtos
[36m2019-01-29 11:22:06.151 UTC [common/channelconfig] initializeProtosStruct -> DEBU 506[0m Processing field: ACLs
[36m2019-01-29 11:22:06.151 UTC [common/channelconfig] initializeProtosStruct -> DEBU 507[0m Processing field: Capabilities
[36m2019-01-29 11:22:06.151 UTC [common/channelconfig] NewStandardValues -> DEBU 508[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 11:22:06.151 UTC [common/channelconfig] initializeProtosStruct -> DEBU 509[0m Processing field: AnchorPeers
[36m2019-01-29 11:22:06.151 UTC [common/channelconfig] NewStandardValues -> DEBU 50a[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:22:06.151 UTC [common/channelconfig] initializeProtosStruct -> DEBU 50b[0m Processing field: MSP
[36m2019-01-29 11:22:06.151 UTC [common/channelconfig] Validate -> DEBU 50c[0m Anchor peers for org Hospital2MSP are anchor_peers:<host:"peer0.hospital2.switch2logic.co.za" port:7051 > 
[36m2019-01-29 11:22:06.151 UTC [common/channelconfig] validateMSP -> DEBU 50d[0m Setting up MSP for org Hospital2MSP
[36m2019-01-29 11:22:06.151 UTC [msp] newBccspMsp -> DEBU 50e[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:22:06.151 UTC [msp] New -> DEBU 50f[0m Creating Cache-MSP instance
[36m2019-01-29 11:22:06.151 UTC [msp] Setup -> DEBU 510[0m Setting up MSP instance Hospital2MSP
[36m2019-01-29 11:22:06.151 UTC [msp/identity] newIdentity -> DEBU 511[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdjCCAhygAwIBAgIRALZ3Pffn/xWUtUWPSK6CYVAwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFowgYsxCzAJBgNVBAYTAlVTMRMwEQYD
VQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4gRnJhbmNpc2NvMSUwIwYDVQQK
Exxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMSgwJgYDVQQDEx9jYS5ob3Nw
aXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcD
QgAESzVpiz6P4mIb+KwvrttcXJKZR5i137Is4298E7OrkYdAg0tB4rpfKTXzUMwW
vI12cTDujpyaZSiqQ3/zP4fOQqNfMF0wDgYDVR0PAQH/BAQDAgGmMA8GA1UdJQQI
MAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQg8QJqWKPaX24HINwR
S6sINFSwRD+440/ccSnvFVaGF24wCgYIKoZIzj0EAwIDSAAwRQIhAPO2Nng3/nqb
cKPliUqVPVjBMu+D55M90+jexWSOpkjcAiADPx8qv9exZ4BfP3+G49Qzpx0Meblj
53vzUgYFa/0EXw==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.152 UTC [msp/identity] newIdentity -> DEBU 512[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAJ6XtHMTTW1JzdpD54qCc3wwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwyLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABA+z1rb9aA1HwHfNLi9V9VZe
bdwT4MXak445zGz4DXzRUsmNeBngzntKb6qpgHQpeFtzbzLx+zwiynRDvfdzORGj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIPEC
alij2l9uByDcEUurCDRUsEQ/uONP3HEp7xVWhhduMAoGCCqGSM49BAMCA0cAMEQC
IA8A3CCJeCasyy7gYd/M1aHYmwWsecY7UY7cVUGy4XOxAiB0rrmfnGW6JA11PDCu
+5c5Rpn0jF5ddsFn+UIpzBFvmg==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.152 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 513[0m Checking if identity satisfies role [CLIENT] for Hospital2MSP
[36m2019-01-29 11:22:06.152 UTC [msp] Validate -> DEBU 514[0m MSP Hospital2MSP validating identity
[36m2019-01-29 11:22:06.152 UTC [msp] getCertificationChain -> DEBU 515[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 11:22:06.153 UTC [msp] hasOURole -> DEBU 516[0m MSP Hospital2MSP checking if the identity is a client
[36m2019-01-29 11:22:06.153 UTC [msp] getCertificationChain -> DEBU 517[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 11:22:06.153 UTC [common/channelconfig] NewStandardValues -> DEBU 518[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 11:22:06.153 UTC [common/channelconfig] initializeProtosStruct -> DEBU 519[0m Processing field: AnchorPeers
[36m2019-01-29 11:22:06.153 UTC [common/channelconfig] NewStandardValues -> DEBU 51a[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:22:06.153 UTC [common/channelconfig] initializeProtosStruct -> DEBU 51b[0m Processing field: MSP
[36m2019-01-29 11:22:06.153 UTC [common/channelconfig] Validate -> DEBU 51c[0m Anchor peers for org Hospital3MSP are anchor_peers:<host:"peer0.hospital3.switch2logic.co.za" port:7051 > 
[36m2019-01-29 11:22:06.153 UTC [common/channelconfig] validateMSP -> DEBU 51d[0m Setting up MSP for org Hospital3MSP
[36m2019-01-29 11:22:06.153 UTC [msp] newBccspMsp -> DEBU 51e[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:22:06.153 UTC [msp] New -> DEBU 51f[0m Creating Cache-MSP instance
[36m2019-01-29 11:22:06.153 UTC [msp] Setup -> DEBU 520[0m Setting up MSP instance Hospital3MSP
[36m2019-01-29 11:22:06.153 UTC [msp/identity] newIdentity -> DEBU 521[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdTCCAhugAwIBAgIQCCXeHGgObIJo8aq4AdvgVjAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMy5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQm1Oo/AEu7ZZToE15Y5ntlaN128Hs/exX3jNH5nO6r4tvyFtBBNEn1ecXxxPtm
dmQ+nPHONorLwDC42SMAKwfro18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCA7vVWFXWpgZBojQ1ZL
xUvgBLeia59MivIRcjxmYanpyTAKBggqhkjOPQQDAgNIADBFAiEAlOUoPtpfO8V7
vFRCanjU5zZWGO5ajFlPDJjjDTy3UrwCICrUYV32JrR/m3dslCl15dSThHrKtYCC
Ehvyw1+lNqiG
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.153 UTC [msp/identity] newIdentity -> DEBU 522[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAI8BA/5Jf+5m8ncI+D7aSiMwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwzLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABF1IehIKIjh8tXYZ7rw4QOuc
g/tpBAkJeOt44zr/LepbjhyFW8vIRnkw75i6Wcg+LOoAS+2NFNg2oNjqg//yCHWj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIDu9
VYVdamBkGiNDVkvFS+AEt6Jrn0yK8hFyPGZhqenJMAoGCCqGSM49BAMCA0cAMEQC
IFyc85pwbCAxGNdw4fflsX2I3HrP3h93YAB2zSDC8HtkAiAQxblAZfEnXUiQKrqE
8I10bYJqD6pJz1jb3Pv+4xplTA==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.154 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 523[0m Checking if identity satisfies role [CLIENT] for Hospital3MSP
[36m2019-01-29 11:22:06.154 UTC [msp] Validate -> DEBU 524[0m MSP Hospital3MSP validating identity
[36m2019-01-29 11:22:06.154 UTC [msp] getCertificationChain -> DEBU 525[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 11:22:06.154 UTC [msp] hasOURole -> DEBU 526[0m MSP Hospital3MSP checking if the identity is a client
[36m2019-01-29 11:22:06.154 UTC [msp] getCertificationChain -> DEBU 527[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 11:22:06.154 UTC [common/channelconfig] NewStandardValues -> DEBU 528[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 11:22:06.154 UTC [common/channelconfig] initializeProtosStruct -> DEBU 529[0m Processing field: AnchorPeers
[36m2019-01-29 11:22:06.154 UTC [common/channelconfig] NewStandardValues -> DEBU 52a[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:22:06.154 UTC [common/channelconfig] initializeProtosStruct -> DEBU 52b[0m Processing field: MSP
[36m2019-01-29 11:22:06.154 UTC [common/channelconfig] Validate -> DEBU 52c[0m Anchor peers for org Hospital1MSP are 
[36m2019-01-29 11:22:06.154 UTC [common/channelconfig] validateMSP -> DEBU 52d[0m Setting up MSP for org Hospital1MSP
[36m2019-01-29 11:22:06.154 UTC [msp] newBccspMsp -> DEBU 52e[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:22:06.154 UTC [msp] New -> DEBU 52f[0m Creating Cache-MSP instance
[36m2019-01-29 11:22:06.155 UTC [msp] Setup -> DEBU 530[0m Setting up MSP instance Hospital1MSP
[36m2019-01-29 11:22:06.155 UTC [msp/identity] newIdentity -> DEBU 531[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdDCCAhugAwIBAgIQZxH8VsnceZxXgKxlURLgVTAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMS5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQX9V4k/h/3pFxByKDscjgQrC0YS/bSbKvzSG2Z2PvltEWp40qB9OaKUN0GQYzo
yK2Etdvyjfd1OFwaTjpGSvv9o18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCBVU7DoP9Msf/nNTNl6
5FxwAXZ82eaGBT7zWYdyh4QbBjAKBggqhkjOPQQDAgNHADBEAiBmXGWQbxCGRp0c
5/y9qJyciB1CDHsknRZDjNzt5f563wIgMy7VPi1R8DpIIIRN9B3mfhDpRa+J+8PA
S4DOJy7rjp4=
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.155 UTC [msp/identity] newIdentity -> DEBU 532[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfWgAwIBAgIQbzxpSKiuJCzDiDlZp+XbWDAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjB4MQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZyYW5jaXNjbzEPMA0GA1UECxMG
Y2xpZW50MSswKQYDVQQDDCJBZG1pbkBob3NwaXRhbDEuc3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEnpADl8+aUBcVWv6q3IgMQ4yg
ISawQ0wamHmpSv+/b1B5hf4V2HyoPrawIr45+o4/Qz++WazZlyY7PkoT27r7KaNN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgVVOw
6D/TLH/5zUzZeuRccAF2fNnmhgU+81mHcoeEGwYwCgYIKoZIzj0EAwIDSAAwRQIh
ALavdMm9i6xSsnWdlliMh10s6dmGBaXO0CxaCowLJIMtAiBEduudGJymDDE1zbiX
YwX83cYWZHUcYV8IXeZPFymC+w==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.155 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 533[0m Checking if identity satisfies role [CLIENT] for Hospital1MSP
[36m2019-01-29 11:22:06.155 UTC [msp] Validate -> DEBU 534[0m MSP Hospital1MSP validating identity
[36m2019-01-29 11:22:06.156 UTC [msp] getCertificationChain -> DEBU 535[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 11:22:06.156 UTC [msp] hasOURole -> DEBU 536[0m MSP Hospital1MSP checking if the identity is a client
[36m2019-01-29 11:22:06.156 UTC [msp] getCertificationChain -> DEBU 537[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 11:22:06.156 UTC [msp] Setup -> DEBU 538[0m Setting up the MSP manager (4 msps)
[36m2019-01-29 11:22:06.156 UTC [msp] Setup -> DEBU 539[0m MSP manager setup complete, setup 4 msps
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 53a[0m Proposed new policy Readers for Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 53b[0m Proposed new policy Writers for Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 53c[0m Proposed new policy Admins for Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 53d[0m Proposed new policy Readers for Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 53e[0m Proposed new policy Writers for Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 53f[0m Proposed new policy Admins for Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 540[0m Proposed new policy Writers for Channel/Application/Hospital3MSP
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 541[0m Proposed new policy Admins for Channel/Application/Hospital3MSP
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 542[0m Proposed new policy Readers for Channel/Application/Hospital3MSP
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 543[0m Proposed new policy Writers for Channel/Application
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 544[0m Proposed new policy Admins for Channel/Application
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 545[0m Proposed new policy Readers for Channel/Application
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 546[0m Proposed new policy Admins for Channel/Orderer/OrdererOrg
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 547[0m Proposed new policy Readers for Channel/Orderer/OrdererOrg
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 548[0m Proposed new policy Writers for Channel/Orderer/OrdererOrg
[36m2019-01-29 11:22:06.156 UTC [policies] NewManagerImpl -> DEBU 549[0m Proposed new policy BlockValidation for Channel/Orderer
[36m2019-01-29 11:22:06.157 UTC [policies] NewManagerImpl -> DEBU 54a[0m Proposed new policy Admins for Channel/Orderer
[36m2019-01-29 11:22:06.157 UTC [policies] NewManagerImpl -> DEBU 54b[0m Proposed new policy Readers for Channel/Orderer
[36m2019-01-29 11:22:06.157 UTC [policies] NewManagerImpl -> DEBU 54c[0m Proposed new policy Writers for Channel/Orderer
[36m2019-01-29 11:22:06.157 UTC [policies] NewManagerImpl -> DEBU 54d[0m Proposed new policy Admins for Channel
[36m2019-01-29 11:22:06.157 UTC [policies] NewManagerImpl -> DEBU 54e[0m Proposed new policy Readers for Channel
[36m2019-01-29 11:22:06.157 UTC [policies] NewManagerImpl -> DEBU 54f[0m Proposed new policy Writers for Channel
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 550[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 551[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 552[0m Adding to config map: [Group]  /Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 553[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/MSP
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 554[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/AnchorPeers
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 555[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 556[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 557[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 558[0m Adding to config map: [Group]  /Channel/Application/Hospital3MSP
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 559[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/MSP
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 55a[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/AnchorPeers
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 55b[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Writers
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 55c[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Admins
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 55d[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Readers
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 55e[0m Adding to config map: [Group]  /Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 55f[0m Adding to config map: [Value]  /Channel/Application/Hospital1MSP/MSP
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 560[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Admins
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 561[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Readers
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 562[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Writers
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 563[0m Adding to config map: [Value]  /Channel/Application/Capabilities
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 564[0m Adding to config map: [Policy] /Channel/Application/Writers
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 565[0m Adding to config map: [Policy] /Channel/Application/Admins
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 566[0m Adding to config map: [Policy] /Channel/Application/Readers
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 567[0m Adding to config map: [Group]  /Channel/Orderer
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 568[0m Adding to config map: [Group]  /Channel/Orderer/OrdererOrg
[36m2019-01-29 11:22:06.157 UTC [common/configtx] addToMap -> DEBU 569[0m Adding to config map: [Value]  /Channel/Orderer/OrdererOrg/MSP
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 56a[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Writers
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 56b[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Admins
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 56c[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Readers
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 56d[0m Adding to config map: [Value]  /Channel/Orderer/BatchTimeout
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 56e[0m Adding to config map: [Value]  /Channel/Orderer/ChannelRestrictions
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 56f[0m Adding to config map: [Value]  /Channel/Orderer/Capabilities
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 570[0m Adding to config map: [Value]  /Channel/Orderer/KafkaBrokers
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 571[0m Adding to config map: [Value]  /Channel/Orderer/ConsensusType
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 572[0m Adding to config map: [Value]  /Channel/Orderer/BatchSize
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 573[0m Adding to config map: [Policy] /Channel/Orderer/Readers
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 574[0m Adding to config map: [Policy] /Channel/Orderer/Writers
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 575[0m Adding to config map: [Policy] /Channel/Orderer/BlockValidation
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 576[0m Adding to config map: [Policy] /Channel/Orderer/Admins
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 577[0m Adding to config map: [Value]  /Channel/Capabilities
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 578[0m Adding to config map: [Value]  /Channel/Consortium
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 579[0m Adding to config map: [Value]  /Channel/HashingAlgorithm
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 57a[0m Adding to config map: [Value]  /Channel/BlockDataHashingStructure
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 57b[0m Adding to config map: [Value]  /Channel/OrdererAddresses
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 57c[0m Adding to config map: [Policy] /Channel/Admins
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 57d[0m Adding to config map: [Policy] /Channel/Readers
[36m2019-01-29 11:22:06.158 UTC [common/configtx] addToMap -> DEBU 57e[0m Adding to config map: [Policy] /Channel/Writers
[36m2019-01-29 11:22:06.158 UTC [common/channelconfig] LogSanityChecks -> DEBU 57f[0m As expected, current configuration has policy '/Channel/Readers'
[36m2019-01-29 11:22:06.158 UTC [common/channelconfig] LogSanityChecks -> DEBU 580[0m As expected, current configuration has policy '/Channel/Writers'
[36m2019-01-29 11:22:06.158 UTC [policies] Manager -> DEBU 581[0m Manager Channel looking up path [Application]
[36m2019-01-29 11:22:06.158 UTC [policies] Manager -> DEBU 582[0m Manager Channel has managers Application
[36m2019-01-29 11:22:06.158 UTC [policies] Manager -> DEBU 583[0m Manager Channel has managers Orderer
[36m2019-01-29 11:22:06.158 UTC [policies] Manager -> DEBU 584[0m Manager Channel/Application looking up path []
[36m2019-01-29 11:22:06.158 UTC [policies] Manager -> DEBU 585[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 11:22:06.158 UTC [policies] Manager -> DEBU 586[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 11:22:06.158 UTC [policies] Manager -> DEBU 587[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 11:22:06.158 UTC [common/channelconfig] LogSanityChecks -> DEBU 588[0m As expected, current configuration has policy '/Channel/Application/Readers'
[36m2019-01-29 11:22:06.158 UTC [common/channelconfig] LogSanityChecks -> DEBU 589[0m As expected, current configuration has policy '/Channel/Application/Writers'
[36m2019-01-29 11:22:06.158 UTC [common/channelconfig] LogSanityChecks -> DEBU 58a[0m As expected, current configuration has policy '/Channel/Application/Admins'
[36m2019-01-29 11:22:06.158 UTC [policies] Manager -> DEBU 58b[0m Manager Channel looking up path [Orderer]
[36m2019-01-29 11:22:06.158 UTC [policies] Manager -> DEBU 58c[0m Manager Channel has managers Application
[36m2019-01-29 11:22:06.158 UTC [policies] Manager -> DEBU 58d[0m Manager Channel has managers Orderer
[36m2019-01-29 11:22:06.158 UTC [policies] Manager -> DEBU 58e[0m Manager Channel/Orderer looking up path []
[36m2019-01-29 11:22:06.158 UTC [policies] Manager -> DEBU 58f[0m Manager Channel/Orderer has managers OrdererOrg
[36m2019-01-29 11:22:06.159 UTC [common/channelconfig] LogSanityChecks -> DEBU 590[0m As expected, current configuration has policy '/Channel/Orderer/BlockValidation'
[36m2019-01-29 11:22:06.159 UTC [common/capabilities] Supported -> DEBU 591[0m Orderer capability V1_1 is supported and is enabled
[36m2019-01-29 11:22:06.159 UTC [common/capabilities] Supported -> DEBU 592[0m Channel capability V1_1 is supported and is enabled
[36m2019-01-29 11:22:06.159 UTC [msp] GetDefaultSigningIdentity -> DEBU 593[0m Obtaining default signing identity
[36m2019-01-29 11:22:06.159 UTC [msp] GetDefaultSigningIdentity -> DEBU 594[0m Obtaining default signing identity
[36m2019-01-29 11:22:06.159 UTC [msp/identity] Sign -> DEBU 595[0m Sign: plaintext: 0AFA060A1B08011A0608DEEEC0E20522...9D4805E70FC1A6F7E081A016B9350BEB 
[36m2019-01-29 11:22:06.159 UTC [msp/identity] Sign -> DEBU 596[0m Sign: digest: 2C706712D1E5F23CC74B255F74D51886FC94E921C6A5CAA9113FC680707970DF 
[36m2019-01-29 11:22:06.159 UTC [policies] Evaluate -> DEBU 597[0m == Evaluating *policies.implicitMetaPolicy Policy /Channel/Writers ==
[36m2019-01-29 11:22:06.159 UTC [policies] Evaluate -> DEBU 598[0m This is an implicit meta policy, it will trigger other policy evaluations, whose failures may be benign
[36m2019-01-29 11:22:06.159 UTC [policies] Evaluate -> DEBU 599[0m == Evaluating *policies.implicitMetaPolicy Policy /Channel/Application/Writers ==
[36m2019-01-29 11:22:06.159 UTC [policies] Evaluate -> DEBU 59a[0m This is an implicit meta policy, it will trigger other policy evaluations, whose failures may be benign
[36m2019-01-29 11:22:06.159 UTC [policies] Evaluate -> DEBU 59b[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital1MSP/Writers ==
2019-01-29 11:22:06.159 UTC [msp] DeserializeIdentity -> INFO 59c[0m Obtaining identity
[36m2019-01-29 11:22:06.159 UTC [msp/identity] newIdentity -> DEBU 59d[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICLDCCAdOgAwIBAgIRALSnb5cS69ZjMJpS1JIoZEkwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowajELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xLjAsBgNVBAMTJW9yZGVyZXIwLmhvc3BpdGFsMi5z
d2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAAS6h69N
Iqb4d5ts04E2IRVEEawOWRIUoNntvpfHT6SnxVjSZi7exzn/YOTi0QQd6NGQa5iu
PFOZElkdCuGbgkyHo00wSzAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH/BAIwADAr
BgNVHSMEJDAigCAYhjZ7Q+bQZRvQvEDbHV3XtyLU0UWvqf/t8icEQrGycTAKBggq
hkjOPQQDAgNHADBEAiAqTM16gxhM8p3qA85cIM2a/xQXiZG35c3etBeP0/9uGAIg
FY2RcB+w2BjTJYTMYwIWQj/N9KTuAHugDITJ8afv1IU=
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func1 -> DEBU 59e[0m 0xc42000ed80 gate 1548760926160266597 evaluation starts
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func2 -> DEBU 59f[0m 0xc42000ed80 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func2 -> DEBU 5a0[0m 0xc42000ed80 processing identity 0 with bytes of 0a0a4f7264657265724d535012ae062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d4949434c44434341644f674177494241674952414c536e6235635336395a6a4d4a7053314a496f5a456b77436759494b6f5a497a6a304541774977647a454c0a4d416b474131554542684d4356564d78457a415242674e5642416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e68626942470a636d467559326c7a59323878477a415a42674e5642416f54456e4e336158526a61444a73623264705979356a62793536595445654d4277474131554541784d560a593245756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445354d4445794f5441334e4445314e466f58445449354d4445794e6a41330a4e4445314e466f77616a454c4d416b474131554542684d4356564d78457a415242674e5642416754436b4e6862476c6d62334a7561574578466a415542674e560a4241635444564e6862694247636d467559326c7a593238784c6a417342674e5642414d544a5739795a4756795a5849774c6d687663334270644746734d69357a0a64326c30593267796247396e61574d7559323875656d45775754415442676371686b6a4f5051494242676771686b6a4f50514d4242774e43414153366836394e0a497162346435747330344532495256454561774f575249556f4e6e74767066485436536e78566a535a693765787a6e2f594f546930515164364e4751613569750a50464f5a456c6b6443754762676b79486f303077537a414f42674e56485138424166384542414d434234417744415944565230544151482f42414977414441720a42674e5648534d454a44416967434159686a5a37512b62515a527651764544624856335874794c553055577671662f7438696345517247796354414b426767710a686b6a4f5051514441674e484144424541694171544d31366778684d3870337141383563494d32612f785158695a47333563336574426550302f3975474149670a4659325263422b7732426a544a59544d59774957516a2f4e394b5475414875674449544a386166763149553d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func2 -> DEBU 5a1[0m 0xc42000ed80 identity 0 does not satisfy principal: the identity is a member of a different MSP (expected Hospital1MSP, got OrdererMSP)
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func2 -> DEBU 5a2[0m 0xc42000ed80 principal evaluation fails
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func1 -> DEBU 5a3[0m 0xc42000ed80 gate 1548760926160266597 evaluation fails
[36m2019-01-29 11:22:06.160 UTC [policies] Evaluate -> DEBU 5a4[0m Signature set did not satisfy policy /Channel/Application/Hospital1MSP/Writers
[36m2019-01-29 11:22:06.160 UTC [policies] Evaluate -> DEBU 5a5[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital1MSP/Writers
[36m2019-01-29 11:22:06.160 UTC [policies] Evaluate -> DEBU 5a6[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital2MSP/Writers ==
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func1 -> DEBU 5a7[0m 0xc42000ed98 gate 1548760926160552315 evaluation starts
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func2 -> DEBU 5a8[0m 0xc42000ed98 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func2 -> DEBU 5a9[0m 0xc42000ed98 processing identity 0 with bytes of 0a0a4f7264657265724d535012ae062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d4949434c44434341644f674177494241674952414c536e6235635336395a6a4d4a7053314a496f5a456b77436759494b6f5a497a6a304541774977647a454c0a4d416b474131554542684d4356564d78457a415242674e5642416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e68626942470a636d467559326c7a59323878477a415a42674e5642416f54456e4e336158526a61444a73623264705979356a62793536595445654d4277474131554541784d560a593245756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445354d4445794f5441334e4445314e466f58445449354d4445794e6a41330a4e4445314e466f77616a454c4d416b474131554542684d4356564d78457a415242674e5642416754436b4e6862476c6d62334a7561574578466a415542674e560a4241635444564e6862694247636d467559326c7a593238784c6a417342674e5642414d544a5739795a4756795a5849774c6d687663334270644746734d69357a0a64326c30593267796247396e61574d7559323875656d45775754415442676371686b6a4f5051494242676771686b6a4f50514d4242774e43414153366836394e0a497162346435747330344532495256454561774f575249556f4e6e74767066485436536e78566a535a693765787a6e2f594f546930515164364e4751613569750a50464f5a456c6b6443754762676b79486f303077537a414f42674e56485138424166384542414d434234417744415944565230544151482f42414977414441720a42674e5648534d454a44416967434159686a5a37512b62515a527651764544624856335874794c553055577671662f7438696345517247796354414b426767710a686b6a4f5051514441674e484144424541694171544d31366778684d3870337141383563494d32612f785158695a47333563336574426550302f3975474149670a4659325263422b7732426a544a59544d59774957516a2f4e394b5475414875674449544a386166763149553d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func2 -> DEBU 5aa[0m 0xc42000ed98 identity 0 does not satisfy principal: the identity is a member of a different MSP (expected Hospital2MSP, got OrdererMSP)
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func2 -> DEBU 5ab[0m 0xc42000ed98 principal evaluation fails
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func1 -> DEBU 5ac[0m 0xc42000ed98 gate 1548760926160552315 evaluation fails
[36m2019-01-29 11:22:06.160 UTC [policies] Evaluate -> DEBU 5ad[0m Signature set did not satisfy policy /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 11:22:06.160 UTC [policies] Evaluate -> DEBU 5ae[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 11:22:06.160 UTC [policies] Evaluate -> DEBU 5af[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital3MSP/Writers ==
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func1 -> DEBU 5b0[0m 0xc42000eda8 gate 1548760926160778956 evaluation starts
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func2 -> DEBU 5b1[0m 0xc42000eda8 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func2 -> DEBU 5b2[0m 0xc42000eda8 processing identity 0 with bytes of 0a0a4f7264657265724d535012ae062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d4949434c44434341644f674177494241674952414c536e6235635336395a6a4d4a7053314a496f5a456b77436759494b6f5a497a6a304541774977647a454c0a4d416b474131554542684d4356564d78457a415242674e5642416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e68626942470a636d467559326c7a59323878477a415a42674e5642416f54456e4e336158526a61444a73623264705979356a62793536595445654d4277474131554541784d560a593245756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445354d4445794f5441334e4445314e466f58445449354d4445794e6a41330a4e4445314e466f77616a454c4d416b474131554542684d4356564d78457a415242674e5642416754436b4e6862476c6d62334a7561574578466a415542674e560a4241635444564e6862694247636d467559326c7a593238784c6a417342674e5642414d544a5739795a4756795a5849774c6d687663334270644746734d69357a0a64326c30593267796247396e61574d7559323875656d45775754415442676371686b6a4f5051494242676771686b6a4f50514d4242774e43414153366836394e0a497162346435747330344532495256454561774f575249556f4e6e74767066485436536e78566a535a693765787a6e2f594f546930515164364e4751613569750a50464f5a456c6b6443754762676b79486f303077537a414f42674e56485138424166384542414d434234417744415944565230544151482f42414977414441720a42674e5648534d454a44416967434159686a5a37512b62515a527651764544624856335874794c553055577671662f7438696345517247796354414b426767710a686b6a4f5051514441674e484144424541694171544d31366778684d3870337141383563494d32612f785158695a47333563336574426550302f3975474149670a4659325263422b7732426a544a59544d59774957516a2f4e394b5475414875674449544a386166763149553d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func2 -> DEBU 5b3[0m 0xc42000eda8 identity 0 does not satisfy principal: the identity is a member of a different MSP (expected Hospital3MSP, got OrdererMSP)
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func2 -> DEBU 5b4[0m 0xc42000eda8 principal evaluation fails
[36m2019-01-29 11:22:06.160 UTC [cauthdsl] func1 -> DEBU 5b5[0m 0xc42000eda8 gate 1548760926160778956 evaluation fails
[36m2019-01-29 11:22:06.160 UTC [policies] Evaluate -> DEBU 5b6[0m Signature set did not satisfy policy /Channel/Application/Hospital3MSP/Writers
[36m2019-01-29 11:22:06.160 UTC [policies] Evaluate -> DEBU 5b7[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital3MSP/Writers
[36m2019-01-29 11:22:06.160 UTC [policies] func1 -> DEBU 5b8[0m Evaluation Failed: Only 0 policies were satisfied, but needed 1 of [ Hospital3MSP.Writers Hospital1MSP.Writers Hospital2MSP.Writers ]
[36m2019-01-29 11:22:06.160 UTC [policies] Evaluate -> DEBU 5b9[0m Signature set did not satisfy policy /Channel/Application/Writers
[36m2019-01-29 11:22:06.160 UTC [policies] Evaluate -> DEBU 5ba[0m == Done Evaluating *policies.implicitMetaPolicy Policy /Channel/Application/Writers
[36m2019-01-29 11:22:06.161 UTC [policies] Evaluate -> DEBU 5bb[0m == Evaluating *policies.implicitMetaPolicy Policy /Channel/Orderer/Writers ==
[36m2019-01-29 11:22:06.161 UTC [policies] Evaluate -> DEBU 5bc[0m This is an implicit meta policy, it will trigger other policy evaluations, whose failures may be benign
[36m2019-01-29 11:22:06.161 UTC [policies] Evaluate -> DEBU 5bd[0m == Evaluating *cauthdsl.policy Policy /Channel/Orderer/OrdererOrg/Writers ==
[36m2019-01-29 11:22:06.161 UTC [cauthdsl] func1 -> DEBU 5be[0m 0xc42000edb8 gate 1548760926161074590 evaluation starts
[36m2019-01-29 11:22:06.161 UTC [cauthdsl] func2 -> DEBU 5bf[0m 0xc42000edb8 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:22:06.161 UTC [cauthdsl] func2 -> DEBU 5c0[0m 0xc42000edb8 processing identity 0 with bytes of 0a0a4f7264657265724d535012ae062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d4949434c44434341644f674177494241674952414c536e6235635336395a6a4d4a7053314a496f5a456b77436759494b6f5a497a6a304541774977647a454c0a4d416b474131554542684d4356564d78457a415242674e5642416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e68626942470a636d467559326c7a59323878477a415a42674e5642416f54456e4e336158526a61444a73623264705979356a62793536595445654d4277474131554541784d560a593245756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445354d4445794f5441334e4445314e466f58445449354d4445794e6a41330a4e4445314e466f77616a454c4d416b474131554542684d4356564d78457a415242674e5642416754436b4e6862476c6d62334a7561574578466a415542674e560a4241635444564e6862694247636d467559326c7a593238784c6a417342674e5642414d544a5739795a4756795a5849774c6d687663334270644746734d69357a0a64326c30593267796247396e61574d7559323875656d45775754415442676371686b6a4f5051494242676771686b6a4f50514d4242774e43414153366836394e0a497162346435747330344532495256454561774f575249556f4e6e74767066485436536e78566a535a693765787a6e2f594f546930515164364e4751613569750a50464f5a456c6b6443754762676b79486f303077537a414f42674e56485138424166384542414d434234417744415944565230544151482f42414977414441720a42674e5648534d454a44416967434159686a5a37512b62515a527651764544624856335874794c553055577671662f7438696345517247796354414b426767710a686b6a4f5051514441674e484144424541694171544d31366778684d3870337141383563494d32612f785158695a47333563336574426550302f3975474149670a4659325263422b7732426a544a59544d59774957516a2f4e394b5475414875674449544a386166763149553d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:22:06.161 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 5c1[0m Checking if identity satisfies MEMBER role for OrdererMSP
[36m2019-01-29 11:22:06.161 UTC [msp] Validate -> DEBU 5c2[0m MSP OrdererMSP validating identity
[36m2019-01-29 11:22:06.161 UTC [cauthdsl] func2 -> DEBU 5c3[0m 0xc42000edb8 principal matched by identity 0
[36m2019-01-29 11:22:06.161 UTC [msp/identity] Verify -> DEBU 5c4[0m Verify: digest = 00000000  2c 70 67 12 d1 e5 f2 3c  c7 4b 25 5f 74 d5 18 86  |,pg....<.K%_t...|
00000010  fc 94 e9 21 c6 a5 ca a9  11 3f c6 80 70 79 70 df  |...!.....?..pyp.|
[36m2019-01-29 11:22:06.161 UTC [msp/identity] Verify -> DEBU 5c5[0m Verify: sig = 00000000  30 45 02 21 00 b6 fb df  eb 60 1e d7 a2 31 ef 69  |0E.!.....`...1.i|
00000010  0b 5d c4 67 4d 12 b5 40  de d1 13 25 25 55 2c 1b  |.].gM..@...%%U,.|
00000020  5d 3a 70 1b 2d 02 20 4b  61 58 72 a8 93 c2 ba 73  |]:p.-. KaXr....s|
00000030  dd 95 cd 8c 7b 2b e2 7c  42 4b 31 a7 2e 8f b3 d4  |....{+.|BK1.....|
00000040  6d e3 99 11 3f 33 ce                              |m...?3.|
[36m2019-01-29 11:22:06.161 UTC [cauthdsl] func2 -> DEBU 5c6[0m 0xc42000edb8 principal evaluation succeeds for identity 0
[36m2019-01-29 11:22:06.161 UTC [cauthdsl] func1 -> DEBU 5c7[0m 0xc42000edb8 gate 1548760926161074590 evaluation succeeds
[36m2019-01-29 11:22:06.161 UTC [policies] Evaluate -> DEBU 5c8[0m Signature set satisfies policy /Channel/Orderer/OrdererOrg/Writers
[36m2019-01-29 11:22:06.161 UTC [policies] Evaluate -> DEBU 5c9[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Orderer/OrdererOrg/Writers
[36m2019-01-29 11:22:06.161 UTC [policies] Evaluate -> DEBU 5ca[0m Signature set satisfies policy /Channel/Orderer/Writers
[36m2019-01-29 11:22:06.162 UTC [policies] Evaluate -> DEBU 5cb[0m == Done Evaluating *policies.implicitMetaPolicy Policy /Channel/Orderer/Writers
[36m2019-01-29 11:22:06.162 UTC [policies] Evaluate -> DEBU 5cc[0m Signature set satisfies policy /Channel/Writers
[36m2019-01-29 11:22:06.162 UTC [policies] Evaluate -> DEBU 5cd[0m == Done Evaluating *policies.implicitMetaPolicy Policy /Channel/Writers
[36m2019-01-29 11:22:06.162 UTC [orderer/consensus/kafka] enqueue -> DEBU 5ce[0m [channel: comunitychannel] Enqueueing envelope...
[36m2019-01-29 11:22:06.162 UTC [orderer/consensus/kafka/sarama] handleResponse -> DEBU 5cf[0m producer/broker/0 state change to [closing] because EOF
[36m2019-01-29 11:22:06.162 UTC [orderer/consensus/kafka/sarama] handleError -> DEBU 5d0[0m Closed connection to broker kafka0.switch2logic.co.za:9092
[36m2019-01-29 11:22:06.162 UTC [orderer/consensus/kafka/sarama] dispatch -> DEBU 5d1[0m producer/leader/comunitychannel/0 state change to [retrying-1]
[36m2019-01-29 11:22:06.162 UTC [orderer/consensus/kafka/sarama] dispatch -> DEBU 5d2[0m producer/leader/comunitychannel/0 abandoning broker 0
[36m2019-01-29 11:22:06.162 UTC [orderer/consensus/kafka/sarama] run -> DEBU 5d3[0m producer/broker/0 shut down
[36m2019-01-29 11:22:06.263 UTC [orderer/consensus/kafka/sarama] RefreshMetadata -> DEBU 5d4[0m client/metadata fetching metadata for [comunitychannel] from broker kafka2.switch2logic.co.za:9092
[36m2019-01-29 11:22:06.265 UTC [orderer/consensus/kafka/sarama] Open -> DEBU 5d5[0m ClientID is the default of 'sarama', you should consider setting it to something application-specific.
[36m2019-01-29 11:22:06.265 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU 5d6[0m producer/broker/0 starting up
[36m2019-01-29 11:22:06.265 UTC [orderer/consensus/kafka/sarama] dispatch)-fm -> DEBU 5d8[0m producer/leader/comunitychannel/0 selected broker 0
[36m2019-01-29 11:22:06.265 UTC [orderer/consensus/kafka/sarama] run)-fm -> DEBU 5d7[0m producer/broker/0 state change to [open] on comunitychannel/0
[36m2019-01-29 11:22:06.266 UTC [orderer/consensus/kafka/sarama] dispatch -> DEBU 5d9[0m producer/leader/comunitychannel/0 state change to [flushing-1]
[36m2019-01-29 11:22:06.266 UTC [orderer/consensus/kafka/sarama] dispatch -> DEBU 5da[0m producer/leader/comunitychannel/0 state change to [normal]
[36m2019-01-29 11:22:06.267 UTC [orderer/consensus/kafka/sarama] withRecover -> DEBU 5db[0m Connected to broker at kafka0.switch2logic.co.za:9092 (registered as #0)
[36m2019-01-29 11:22:06.292 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 5dc[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 6. Inspecting type...
[36m2019-01-29 11:22:06.292 UTC [orderer/consensus/kafka] processRegular -> DEBU 5dd[0m [channel: comunitychannel] Processing regular Kafka message of type CONFIG
[36m2019-01-29 11:22:06.292 UTC [orderer/consensus/kafka] func2 -> DEBU 5de[0m [channel: comunitychannel] Received config message
[36m2019-01-29 11:22:06.292 UTC [orderer/consensus/kafka] func2 -> DEBU 5df[0m [channel: comunitychannel] Creating isolated block for config message
[36m2019-01-29 11:22:06.292 UTC [common/configtx] addToMap -> DEBU 5e0[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 11:22:06.292 UTC [common/configtx] addToMap -> DEBU 5e1[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 11:22:06.292 UTC [common/configtx] addToMap -> DEBU 5e2[0m Adding to config map: [Group]  /Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.293 UTC [common/configtx] addToMap -> DEBU 5e3[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/MSP
[36m2019-01-29 11:22:06.293 UTC [common/configtx] addToMap -> DEBU 5e4[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 11:22:06.293 UTC [common/configtx] addToMap -> DEBU 5e5[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 11:22:06.293 UTC [common/configtx] addToMap -> DEBU 5e6[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 11:22:06.293 UTC [common/configtx] addToMap -> DEBU 5e7[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 11:22:06.293 UTC [common/configtx] addToMap -> DEBU 5e8[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 11:22:06.293 UTC [common/configtx] addToMap -> DEBU 5e9[0m Adding to config map: [Group]  /Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.293 UTC [common/configtx] addToMap -> DEBU 5ea[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/MSP
[36m2019-01-29 11:22:06.293 UTC [common/configtx] addToMap -> DEBU 5eb[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/AnchorPeers
[36m2019-01-29 11:22:06.293 UTC [common/configtx] addToMap -> DEBU 5ec[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 11:22:06.293 UTC [common/configtx] addToMap -> DEBU 5ed[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 11:22:06.293 UTC [common/configtx] addToMap -> DEBU 5ee[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 11:22:06.293 UTC [common/configtx] verifyDeltaSet -> DEBU 5ef[0m Processing change to key: [Group]  /Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.295 UTC [common/configtx] policyForItem -> DEBU 5f0[0m Getting policy for item Hospital2MSP with mod_policy Admins
[36m2019-01-29 11:22:06.295 UTC [policies] Manager -> DEBU 5f1[0m Manager Channel looking up path [Application]
[36m2019-01-29 11:22:06.295 UTC [policies] Manager -> DEBU 5f2[0m Manager Channel has managers Application
[36m2019-01-29 11:22:06.295 UTC [policies] Manager -> DEBU 5f3[0m Manager Channel has managers Orderer
[36m2019-01-29 11:22:06.295 UTC [policies] Manager -> DEBU 5f4[0m Manager Channel/Application looking up path []
[36m2019-01-29 11:22:06.295 UTC [policies] Manager -> DEBU 5f5[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 11:22:06.295 UTC [policies] Manager -> DEBU 5f6[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 11:22:06.295 UTC [policies] Manager -> DEBU 5f7[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 11:22:06.295 UTC [policies] Manager -> DEBU 5f8[0m Manager Channel/Application looking up path [Hospital2MSP]
[36m2019-01-29 11:22:06.295 UTC [policies] Manager -> DEBU 5f9[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 11:22:06.295 UTC [policies] Manager -> DEBU 5fa[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 11:22:06.295 UTC [policies] Manager -> DEBU 5fb[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 11:22:06.295 UTC [policies] Manager -> DEBU 5fc[0m Manager Channel/Application/Hospital2MSP looking up path []
[36m2019-01-29 11:22:06.295 UTC [policies] Evaluate -> DEBU 5fd[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital2MSP/Admins ==
[36m2019-01-29 11:22:06.295 UTC [cauthdsl] func1 -> DEBU 5fe[0m 0xc42000f4c8 gate 1548760926295742038 evaluation starts
[36m2019-01-29 11:22:06.295 UTC [cauthdsl] func2 -> DEBU 5ff[0m 0xc42000f4c8 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:22:06.295 UTC [cauthdsl] func2 -> DEBU 600[0m 0xc42000f4c8 processing identity 0 with bytes of 0a0c486f73706974616c324d535012df062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d494943547a4343416661674177494241674952414a365874484d545457314a7a6470443534714363337777436759494b6f5a497a6a304541774977675973780a437a414a42674e5642415954416c56544d524d77455159445651514945777044595778705a6d3979626d6c684d525977464159445651514845773154595734670a526e4a68626d4e7063324e764d535577497759445651514b4578786f62334e7761585268624449756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70680a4d5367774a675944565151444578396a5953356f62334e7761585268624449756333647064474e6f4d6d78765a326c6a4c6d4e764c6e70684d423458445445350a4d4445794f5441334e4445314e466f58445449354d4445794e6a41334e4445314e466f776544454c4d416b474131554542684d4356564d78457a415242674e560a42416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e6862694247636d467559326c7a59323878447a414e42674e56424173540a426d4e7361575675644445724d436b47413155454177776951575274615735416147397a63476c30595777794c6e4e336158526a61444a73623264705979356a0a627935365954425a4d424d4742797147534d34394167454743437147534d3439417745484130494142412b7a31726239614131487748664e4c69395639565a650a62647754344d58616b3434357a477a3444587a5255736d4e65426e677a6e744b62367170674851706546747a627a4c782b7a7769796e52447666647a4f52476a0a5454424c4d41344741315564447745422f775145417749486744414d42674e5648524d4241663845416a41414d437347413155644977516b4d434b41495045430a616c696a326c39754279446345557572434452557345512f754f4e503348457037785657686864754d416f4743437147534d343942414d43413063414d4551430a494138413343434a654361737979376759642f4d316148596d77577365635937555937635655477934584f784169423072726d666e4757364a413131504443750a2b35633552706e306a4635646473466e2b5549707a4246766d673d3d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:22:06.295 UTC [cauthdsl] func2 -> DEBU 601[0m 0xc42000f4c8 principal matched by identity 0
[36m2019-01-29 11:22:06.296 UTC [msp/identity] Verify -> DEBU 602[0m Verify: digest = 00000000  8a d5 75 1d 1c c2 e6 24  2a 57 ab a4 f6 2e f5 ec  |..u....$*W......|
00000010  5b 3c 08 a2 15 39 d8 3b  09 36 09 a5 d9 fd e3 ed  |[<...9.;.6......|
[36m2019-01-29 11:22:06.296 UTC [msp/identity] Verify -> DEBU 603[0m Verify: sig = 00000000  30 44 02 20 6d 2a 1a 23  06 d6 7f 73 ea b2 4b 36  |0D. m*.#...s..K6|
00000010  b1 d5 e2 49 36 e6 61 25  e2 e5 58 86 3f 5e 03 f7  |...I6.a%..X.?^..|
00000020  cf e5 3d d0 02 20 7b e4  ee b4 5a 91 13 f9 ae 06  |..=.. {...Z.....|
00000030  6f bf 68 b3 84 fb 3a 37  49 98 5d 67 b6 c9 9b 00  |o.h...:7I.]g....|
00000040  54 66 c1 84 87 98                                 |Tf....|
[36m2019-01-29 11:22:06.296 UTC [cauthdsl] func2 -> DEBU 604[0m 0xc42000f4c8 principal evaluation succeeds for identity 0
[36m2019-01-29 11:22:06.296 UTC [cauthdsl] func1 -> DEBU 605[0m 0xc42000f4c8 gate 1548760926295742038 evaluation succeeds
[36m2019-01-29 11:22:06.296 UTC [policies] Evaluate -> DEBU 606[0m Signature set satisfies policy /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 11:22:06.296 UTC [policies] Evaluate -> DEBU 607[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 11:22:06.296 UTC [common/configtx] verifyDeltaSet -> DEBU 608[0m Processing change to key: [Value]  /Channel/Application/Hospital2MSP/AnchorPeers
[36m2019-01-29 11:22:06.297 UTC [common/configtx] recurseConfigMap -> DEBU 609[0m Setting policy for key Admins to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\022\022\020\n\014Hospital1MSP\020\001" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.297 UTC [common/configtx] recurseConfigMap -> DEBU 60a[0m Setting policy for key Readers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital1MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.297 UTC [common/configtx] recurseConfigMap -> DEBU 60b[0m Setting policy for key Writers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital1MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 60c[0m Setting policy for key Admins to 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 60d[0m Setting policy for key Readers to 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 60e[0m Setting policy for key Writers to 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 60f[0m Setting policy for key Writers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital3MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 610[0m Setting policy for key Admins to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\022\022\020\n\014Hospital3MSP\020\001" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 611[0m Setting policy for key Readers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital3MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 612[0m Setting policy for key Writers to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 613[0m Setting policy for key Admins to policy:<type:3 value:"\n\006Admins\020\002" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 614[0m Setting policy for key Readers to policy:<type:3 value:"\n\007Readers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 615[0m Setting policy for key Readers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\016\022\014\n\nOrdererMSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 616[0m Setting policy for key Writers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\016\022\014\n\nOrdererMSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 617[0m Setting policy for key Admins to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\nOrdererMSP\020\001" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 618[0m Setting policy for key Readers to policy:<type:3 value:"\n\007Readers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.298 UTC [common/configtx] recurseConfigMap -> DEBU 619[0m Setting policy for key Writers to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.299 UTC [common/configtx] recurseConfigMap -> DEBU 61a[0m Setting policy for key BlockValidation to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.299 UTC [common/configtx] recurseConfigMap -> DEBU 61b[0m Setting policy for key Admins to policy:<type:3 value:"\n\006Admins\020\002" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.299 UTC [common/configtx] recurseConfigMap -> DEBU 61c[0m Setting policy for key Readers to policy:<type:3 value:"\n\007Readers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.299 UTC [common/configtx] recurseConfigMap -> DEBU 61d[0m Setting policy for key Writers to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.299 UTC [common/configtx] recurseConfigMap -> DEBU 61e[0m Setting policy for key Admins to policy:<type:3 value:"\n\006Admins\020\002" > mod_policy:"Admins" 
[36m2019-01-29 11:22:06.299 UTC [common/channelconfig] NewStandardValues -> DEBU 61f[0m Initializing protos for *channelconfig.ChannelProtos
[36m2019-01-29 11:22:06.299 UTC [common/channelconfig] initializeProtosStruct -> DEBU 620[0m Processing field: HashingAlgorithm
[36m2019-01-29 11:22:06.299 UTC [common/channelconfig] initializeProtosStruct -> DEBU 621[0m Processing field: BlockDataHashingStructure
[36m2019-01-29 11:22:06.299 UTC [common/channelconfig] initializeProtosStruct -> DEBU 622[0m Processing field: OrdererAddresses
[36m2019-01-29 11:22:06.299 UTC [common/channelconfig] initializeProtosStruct -> DEBU 623[0m Processing field: Consortium
[36m2019-01-29 11:22:06.299 UTC [common/channelconfig] initializeProtosStruct -> DEBU 624[0m Processing field: Capabilities
[36m2019-01-29 11:22:06.299 UTC [common/channelconfig] NewStandardValues -> DEBU 625[0m Initializing protos for *channelconfig.ApplicationProtos
[36m2019-01-29 11:22:06.299 UTC [common/channelconfig] initializeProtosStruct -> DEBU 626[0m Processing field: ACLs
[36m2019-01-29 11:22:06.299 UTC [common/channelconfig] initializeProtosStruct -> DEBU 627[0m Processing field: Capabilities
[36m2019-01-29 11:22:06.300 UTC [common/channelconfig] NewStandardValues -> DEBU 628[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 11:22:06.300 UTC [common/channelconfig] initializeProtosStruct -> DEBU 629[0m Processing field: AnchorPeers
[36m2019-01-29 11:22:06.300 UTC [common/channelconfig] NewStandardValues -> DEBU 62a[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:22:06.300 UTC [common/channelconfig] initializeProtosStruct -> DEBU 62b[0m Processing field: MSP
[36m2019-01-29 11:22:06.300 UTC [common/channelconfig] Validate -> DEBU 62c[0m Anchor peers for org Hospital2MSP are anchor_peers:<host:"peer0.hospital2.switch2logic.co.za" port:7051 > 
[36m2019-01-29 11:22:06.300 UTC [common/channelconfig] validateMSP -> DEBU 62d[0m Setting up MSP for org Hospital2MSP
[36m2019-01-29 11:22:06.300 UTC [msp] newBccspMsp -> DEBU 62e[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:22:06.300 UTC [msp] New -> DEBU 62f[0m Creating Cache-MSP instance
[36m2019-01-29 11:22:06.300 UTC [msp] Setup -> DEBU 630[0m Setting up MSP instance Hospital2MSP
[36m2019-01-29 11:22:06.301 UTC [msp/identity] newIdentity -> DEBU 631[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdjCCAhygAwIBAgIRALZ3Pffn/xWUtUWPSK6CYVAwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFowgYsxCzAJBgNVBAYTAlVTMRMwEQYD
VQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4gRnJhbmNpc2NvMSUwIwYDVQQK
Exxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMSgwJgYDVQQDEx9jYS5ob3Nw
aXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcD
QgAESzVpiz6P4mIb+KwvrttcXJKZR5i137Is4298E7OrkYdAg0tB4rpfKTXzUMwW
vI12cTDujpyaZSiqQ3/zP4fOQqNfMF0wDgYDVR0PAQH/BAQDAgGmMA8GA1UdJQQI
MAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQg8QJqWKPaX24HINwR
S6sINFSwRD+440/ccSnvFVaGF24wCgYIKoZIzj0EAwIDSAAwRQIhAPO2Nng3/nqb
cKPliUqVPVjBMu+D55M90+jexWSOpkjcAiADPx8qv9exZ4BfP3+G49Qzpx0Meblj
53vzUgYFa/0EXw==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.301 UTC [msp/identity] newIdentity -> DEBU 632[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAJ6XtHMTTW1JzdpD54qCc3wwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwyLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABA+z1rb9aA1HwHfNLi9V9VZe
bdwT4MXak445zGz4DXzRUsmNeBngzntKb6qpgHQpeFtzbzLx+zwiynRDvfdzORGj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIPEC
alij2l9uByDcEUurCDRUsEQ/uONP3HEp7xVWhhduMAoGCCqGSM49BAMCA0cAMEQC
IA8A3CCJeCasyy7gYd/M1aHYmwWsecY7UY7cVUGy4XOxAiB0rrmfnGW6JA11PDCu
+5c5Rpn0jF5ddsFn+UIpzBFvmg==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.302 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 633[0m Checking if identity satisfies role [CLIENT] for Hospital2MSP
[36m2019-01-29 11:22:06.302 UTC [msp] Validate -> DEBU 634[0m MSP Hospital2MSP validating identity
[36m2019-01-29 11:22:06.303 UTC [orderer/consensus/kafka] enqueue -> DEBU 635[0m [channel: comunitychannel] Envelope enqueued successfully
[36m2019-01-29 11:22:06.303 UTC [orderer/common/broadcast] Handle -> DEBU 636[0m [channel: comunitychannel] Broadcast has successfully enqueued message of type CONFIG_UPDATE from 10.0.0.38:40156
[33m2019-01-29 11:22:06.313 UTC [common/deliver] Handle -> WARN 637[0m Error reading from 10.0.0.38:40154: rpc error: code = Canceled desc = context canceled
[36m2019-01-29 11:22:06.313 UTC [orderer/common/server] func1 -> DEBU 638[0m Closing Deliver stream
[33m2019-01-29 11:22:06.313 UTC [orderer/common/broadcast] Handle -> WARN 639[0m Error reading from 10.0.0.38:40156: rpc error: code = Canceled desc = context canceled
[36m2019-01-29 11:22:06.313 UTC [orderer/common/server] func1 -> DEBU 63a[0m Closing Broadcast stream
[36m2019-01-29 11:22:06.315 UTC [msp] getCertificationChain -> DEBU 63b[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 11:22:06.315 UTC [msp] hasOURole -> DEBU 63c[0m MSP Hospital2MSP checking if the identity is a client
[36m2019-01-29 11:22:06.315 UTC [msp] getCertificationChain -> DEBU 63d[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 11:22:06.316 UTC [common/channelconfig] NewStandardValues -> DEBU 63e[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 11:22:06.316 UTC [common/channelconfig] initializeProtosStruct -> DEBU 63f[0m Processing field: AnchorPeers
[36m2019-01-29 11:22:06.316 UTC [common/channelconfig] NewStandardValues -> DEBU 640[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:22:06.316 UTC [common/channelconfig] initializeProtosStruct -> DEBU 641[0m Processing field: MSP
[36m2019-01-29 11:22:06.316 UTC [common/channelconfig] Validate -> DEBU 642[0m Anchor peers for org Hospital3MSP are anchor_peers:<host:"peer0.hospital3.switch2logic.co.za" port:7051 > 
[36m2019-01-29 11:22:06.316 UTC [common/channelconfig] validateMSP -> DEBU 643[0m Setting up MSP for org Hospital3MSP
[36m2019-01-29 11:22:06.316 UTC [msp] newBccspMsp -> DEBU 644[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:22:06.316 UTC [msp] New -> DEBU 645[0m Creating Cache-MSP instance
[36m2019-01-29 11:22:06.316 UTC [msp] Setup -> DEBU 646[0m Setting up MSP instance Hospital3MSP
[36m2019-01-29 11:22:06.317 UTC [msp/identity] newIdentity -> DEBU 647[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdTCCAhugAwIBAgIQCCXeHGgObIJo8aq4AdvgVjAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMy5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQm1Oo/AEu7ZZToE15Y5ntlaN128Hs/exX3jNH5nO6r4tvyFtBBNEn1ecXxxPtm
dmQ+nPHONorLwDC42SMAKwfro18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCA7vVWFXWpgZBojQ1ZL
xUvgBLeia59MivIRcjxmYanpyTAKBggqhkjOPQQDAgNIADBFAiEAlOUoPtpfO8V7
vFRCanjU5zZWGO5ajFlPDJjjDTy3UrwCICrUYV32JrR/m3dslCl15dSThHrKtYCC
Ehvyw1+lNqiG
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.317 UTC [msp/identity] newIdentity -> DEBU 648[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAI8BA/5Jf+5m8ncI+D7aSiMwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwzLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABF1IehIKIjh8tXYZ7rw4QOuc
g/tpBAkJeOt44zr/LepbjhyFW8vIRnkw75i6Wcg+LOoAS+2NFNg2oNjqg//yCHWj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIDu9
VYVdamBkGiNDVkvFS+AEt6Jrn0yK8hFyPGZhqenJMAoGCCqGSM49BAMCA0cAMEQC
IFyc85pwbCAxGNdw4fflsX2I3HrP3h93YAB2zSDC8HtkAiAQxblAZfEnXUiQKrqE
8I10bYJqD6pJz1jb3Pv+4xplTA==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.318 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 649[0m Checking if identity satisfies role [CLIENT] for Hospital3MSP
[36m2019-01-29 11:22:06.318 UTC [msp] Validate -> DEBU 64a[0m MSP Hospital3MSP validating identity
[36m2019-01-29 11:22:06.319 UTC [msp] getCertificationChain -> DEBU 64b[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 11:22:06.319 UTC [msp] hasOURole -> DEBU 64c[0m MSP Hospital3MSP checking if the identity is a client
[36m2019-01-29 11:22:06.319 UTC [msp] getCertificationChain -> DEBU 64d[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 11:22:06.320 UTC [common/channelconfig] NewStandardValues -> DEBU 64e[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 11:22:06.320 UTC [common/channelconfig] initializeProtosStruct -> DEBU 64f[0m Processing field: AnchorPeers
[36m2019-01-29 11:22:06.320 UTC [common/channelconfig] NewStandardValues -> DEBU 650[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:22:06.320 UTC [common/channelconfig] initializeProtosStruct -> DEBU 651[0m Processing field: MSP
[36m2019-01-29 11:22:06.320 UTC [common/channelconfig] Validate -> DEBU 652[0m Anchor peers for org Hospital1MSP are 
[36m2019-01-29 11:22:06.320 UTC [common/channelconfig] validateMSP -> DEBU 653[0m Setting up MSP for org Hospital1MSP
[36m2019-01-29 11:22:06.320 UTC [msp] newBccspMsp -> DEBU 654[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:22:06.320 UTC [msp] New -> DEBU 655[0m Creating Cache-MSP instance
[36m2019-01-29 11:22:06.320 UTC [msp] Setup -> DEBU 656[0m Setting up MSP instance Hospital1MSP
[36m2019-01-29 11:22:06.321 UTC [msp/identity] newIdentity -> DEBU 657[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdDCCAhugAwIBAgIQZxH8VsnceZxXgKxlURLgVTAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMS5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQX9V4k/h/3pFxByKDscjgQrC0YS/bSbKvzSG2Z2PvltEWp40qB9OaKUN0GQYzo
yK2Etdvyjfd1OFwaTjpGSvv9o18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCBVU7DoP9Msf/nNTNl6
5FxwAXZ82eaGBT7zWYdyh4QbBjAKBggqhkjOPQQDAgNHADBEAiBmXGWQbxCGRp0c
5/y9qJyciB1CDHsknRZDjNzt5f563wIgMy7VPi1R8DpIIIRN9B3mfhDpRa+J+8PA
S4DOJy7rjp4=
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.321 UTC [msp/identity] newIdentity -> DEBU 658[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfWgAwIBAgIQbzxpSKiuJCzDiDlZp+XbWDAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjB4MQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZyYW5jaXNjbzEPMA0GA1UECxMG
Y2xpZW50MSswKQYDVQQDDCJBZG1pbkBob3NwaXRhbDEuc3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEnpADl8+aUBcVWv6q3IgMQ4yg
ISawQ0wamHmpSv+/b1B5hf4V2HyoPrawIr45+o4/Qz++WazZlyY7PkoT27r7KaNN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgVVOw
6D/TLH/5zUzZeuRccAF2fNnmhgU+81mHcoeEGwYwCgYIKoZIzj0EAwIDSAAwRQIh
ALavdMm9i6xSsnWdlliMh10s6dmGBaXO0CxaCowLJIMtAiBEduudGJymDDE1zbiX
YwX83cYWZHUcYV8IXeZPFymC+w==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.322 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 659[0m Checking if identity satisfies role [CLIENT] for Hospital1MSP
[36m2019-01-29 11:22:06.322 UTC [msp] Validate -> DEBU 65a[0m MSP Hospital1MSP validating identity
[36m2019-01-29 11:22:06.322 UTC [msp] getCertificationChain -> DEBU 65b[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 11:22:06.323 UTC [msp] hasOURole -> DEBU 65c[0m MSP Hospital1MSP checking if the identity is a client
[36m2019-01-29 11:22:06.323 UTC [msp] getCertificationChain -> DEBU 65d[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 11:22:06.323 UTC [common/channelconfig] NewStandardValues -> DEBU 65e[0m Initializing protos for *channelconfig.OrdererProtos
[36m2019-01-29 11:22:06.323 UTC [common/channelconfig] initializeProtosStruct -> DEBU 65f[0m Processing field: ConsensusType
[36m2019-01-29 11:22:06.323 UTC [common/channelconfig] initializeProtosStruct -> DEBU 660[0m Processing field: BatchSize
[36m2019-01-29 11:22:06.323 UTC [common/channelconfig] initializeProtosStruct -> DEBU 661[0m Processing field: BatchTimeout
[36m2019-01-29 11:22:06.323 UTC [common/channelconfig] initializeProtosStruct -> DEBU 662[0m Processing field: KafkaBrokers
[36m2019-01-29 11:22:06.323 UTC [common/channelconfig] initializeProtosStruct -> DEBU 663[0m Processing field: ChannelRestrictions
[36m2019-01-29 11:22:06.323 UTC [common/channelconfig] initializeProtosStruct -> DEBU 664[0m Processing field: Capabilities
[36m2019-01-29 11:22:06.324 UTC [common/channelconfig] NewStandardValues -> DEBU 665[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:22:06.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 666[0m Processing field: MSP
[36m2019-01-29 11:22:06.324 UTC [common/channelconfig] validateMSP -> DEBU 667[0m Setting up MSP for org OrdererOrg
[36m2019-01-29 11:22:06.324 UTC [msp] newBccspMsp -> DEBU 668[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:22:06.324 UTC [msp] New -> DEBU 669[0m Creating Cache-MSP instance
[36m2019-01-29 11:22:06.324 UTC [msp] Setup -> DEBU 66a[0m Setting up MSP instance OrdererMSP
[36m2019-01-29 11:22:06.324 UTC [msp/identity] newIdentity -> DEBU 66b[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICSzCCAfKgAwIBAgIRAO7EFp+tGDrZX/4Yn1ExG4IwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowdzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEe
MBwGA1UEAxMVY2Euc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZI
zj0DAQcDQgAE+ci0VrQQEnBN2VlYMEvGL0RvqwQ9zVhgyxdKDi9AB8iyQ0dhyWzJ
CZ9MnAWGk29pw9b+9HdNkbalpJKWkcctJ6NfMF0wDgYDVR0PAQH/BAQDAgGmMA8G
A1UdJQQIMAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgGIY2e0Pm
0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDRwAwRAIgcoBa
RHN5r57Qu7sd8TwCzfyJI+uozczAYI2SsN06iKgCIAeAP4FbTHxjqSLcNZMNGbTZ
YWA1h+rDBMa99duId/0D
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.324 UTC [msp/identity] newIdentity -> DEBU 66c[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICHzCCAcWgAwIBAgIQRo5Qm6m11gCv1i2SXwRJAjAKBggqhkjOPQQDAjB3MQsw
CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy
YW5jaXNjbzEbMBkGA1UEChMSc3dpdGNoMmxvZ2ljLmNvLnphMR4wHAYDVQQDExVj
YS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkwMTI5MDc0MTU0WhcNMjkwMTI2MDc0
MTU0WjBdMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UE
BxMNU2FuIEZyYW5jaXNjbzEhMB8GA1UEAwwYQWRtaW5Ac3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE0QeSwnrMZdy7TKSYF/JzQ12C
vfINZcjx7xyeUuj/96gj42fjc1ctn7oo/tDl1eJNZbDhFvkRzefYmxtoSnH5Y6NN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgGIY2
e0Pm0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDSAAwRQIh
AM8EkjCZIKrAf9sL1d1fThizng+66jmEVlKPbTpimVbiAiAhCJZoeBIJGcgxbCr2
5Rd2IW34zWcPhemkNZvCKv27WA==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:06.325 UTC [msp] Validate -> DEBU 66d[0m MSP OrdererMSP validating identity
[36m2019-01-29 11:22:06.325 UTC [msp] Setup -> DEBU 66e[0m Setting up the MSP manager (4 msps)
[36m2019-01-29 11:22:06.325 UTC [msp] Setup -> DEBU 66f[0m MSP manager setup complete, setup 4 msps
[36m2019-01-29 11:22:06.325 UTC [policies] NewManagerImpl -> DEBU 670[0m Proposed new policy Admins for Channel/Application/Hospital3MSP
[36m2019-01-29 11:22:06.325 UTC [policies] NewManagerImpl -> DEBU 671[0m Proposed new policy Readers for Channel/Application/Hospital3MSP
[36m2019-01-29 11:22:06.325 UTC [policies] NewManagerImpl -> DEBU 672[0m Proposed new policy Writers for Channel/Application/Hospital3MSP
[36m2019-01-29 11:22:06.325 UTC [policies] NewManagerImpl -> DEBU 673[0m Proposed new policy Admins for Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:06.325 UTC [policies] NewManagerImpl -> DEBU 674[0m Proposed new policy Readers for Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:06.325 UTC [policies] NewManagerImpl -> DEBU 675[0m Proposed new policy Writers for Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:06.325 UTC [policies] NewManagerImpl -> DEBU 676[0m Proposed new policy Readers for Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.325 UTC [policies] NewManagerImpl -> DEBU 677[0m Proposed new policy Writers for Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.325 UTC [policies] NewManagerImpl -> DEBU 678[0m Proposed new policy Admins for Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.325 UTC [policies] NewManagerImpl -> DEBU 679[0m Proposed new policy Writers for Channel/Application
[36m2019-01-29 11:22:06.325 UTC [policies] NewManagerImpl -> DEBU 67a[0m Proposed new policy Admins for Channel/Application
[36m2019-01-29 11:22:06.325 UTC [policies] NewManagerImpl -> DEBU 67b[0m Proposed new policy Readers for Channel/Application
[36m2019-01-29 11:22:06.326 UTC [policies] NewManagerImpl -> DEBU 67c[0m Proposed new policy Writers for Channel/Orderer/OrdererOrg
[36m2019-01-29 11:22:06.326 UTC [policies] NewManagerImpl -> DEBU 67d[0m Proposed new policy Admins for Channel/Orderer/OrdererOrg
[36m2019-01-29 11:22:06.326 UTC [policies] NewManagerImpl -> DEBU 67e[0m Proposed new policy Readers for Channel/Orderer/OrdererOrg
[36m2019-01-29 11:22:06.326 UTC [policies] NewManagerImpl -> DEBU 67f[0m Proposed new policy BlockValidation for Channel/Orderer
[36m2019-01-29 11:22:06.326 UTC [policies] NewManagerImpl -> DEBU 680[0m Proposed new policy Admins for Channel/Orderer
[36m2019-01-29 11:22:06.326 UTC [policies] NewManagerImpl -> DEBU 681[0m Proposed new policy Readers for Channel/Orderer
[36m2019-01-29 11:22:06.326 UTC [policies] NewManagerImpl -> DEBU 682[0m Proposed new policy Writers for Channel/Orderer
[36m2019-01-29 11:22:06.326 UTC [policies] NewManagerImpl -> DEBU 683[0m Proposed new policy Admins for Channel
[36m2019-01-29 11:22:06.326 UTC [policies] NewManagerImpl -> DEBU 684[0m Proposed new policy Readers for Channel
[36m2019-01-29 11:22:06.326 UTC [policies] NewManagerImpl -> DEBU 685[0m Proposed new policy Writers for Channel
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 686[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 687[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 688[0m Adding to config map: [Group]  /Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 689[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/MSP
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 68a[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/AnchorPeers
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 68b[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 68c[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 68d[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 68e[0m Adding to config map: [Group]  /Channel/Application/Hospital3MSP
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 68f[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/AnchorPeers
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 690[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/MSP
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 691[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Writers
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 692[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Admins
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 693[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Readers
[36m2019-01-29 11:22:06.326 UTC [common/configtx] addToMap -> DEBU 694[0m Adding to config map: [Group]  /Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 695[0m Adding to config map: [Value]  /Channel/Application/Hospital1MSP/MSP
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 696[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Readers
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 697[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Writers
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 698[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Admins
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 699[0m Adding to config map: [Value]  /Channel/Application/Capabilities
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 69a[0m Adding to config map: [Policy] /Channel/Application/Writers
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 69b[0m Adding to config map: [Policy] /Channel/Application/Admins
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 69c[0m Adding to config map: [Policy] /Channel/Application/Readers
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 69d[0m Adding to config map: [Group]  /Channel/Orderer
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 69e[0m Adding to config map: [Group]  /Channel/Orderer/OrdererOrg
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 69f[0m Adding to config map: [Value]  /Channel/Orderer/OrdererOrg/MSP
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6a0[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Writers
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6a1[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Admins
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6a2[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Readers
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6a3[0m Adding to config map: [Value]  /Channel/Orderer/ConsensusType
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6a4[0m Adding to config map: [Value]  /Channel/Orderer/BatchSize
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6a5[0m Adding to config map: [Value]  /Channel/Orderer/BatchTimeout
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6a6[0m Adding to config map: [Value]  /Channel/Orderer/ChannelRestrictions
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6a7[0m Adding to config map: [Value]  /Channel/Orderer/Capabilities
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6a8[0m Adding to config map: [Value]  /Channel/Orderer/KafkaBrokers
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6a9[0m Adding to config map: [Policy] /Channel/Orderer/BlockValidation
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6aa[0m Adding to config map: [Policy] /Channel/Orderer/Admins
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6ab[0m Adding to config map: [Policy] /Channel/Orderer/Readers
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6ac[0m Adding to config map: [Policy] /Channel/Orderer/Writers
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6ad[0m Adding to config map: [Value]  /Channel/OrdererAddresses
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6ae[0m Adding to config map: [Value]  /Channel/Capabilities
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6af[0m Adding to config map: [Value]  /Channel/Consortium
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6b0[0m Adding to config map: [Value]  /Channel/HashingAlgorithm
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6b1[0m Adding to config map: [Value]  /Channel/BlockDataHashingStructure
[36m2019-01-29 11:22:06.327 UTC [common/configtx] addToMap -> DEBU 6b2[0m Adding to config map: [Policy] /Channel/Admins
[36m2019-01-29 11:22:06.328 UTC [common/configtx] addToMap -> DEBU 6b3[0m Adding to config map: [Policy] /Channel/Readers
[36m2019-01-29 11:22:06.328 UTC [common/configtx] addToMap -> DEBU 6b4[0m Adding to config map: [Policy] /Channel/Writers
[36m2019-01-29 11:22:06.328 UTC [common/channelconfig] LogSanityChecks -> DEBU 6b5[0m As expected, current configuration has policy '/Channel/Readers'
[36m2019-01-29 11:22:06.328 UTC [common/channelconfig] LogSanityChecks -> DEBU 6b6[0m As expected, current configuration has policy '/Channel/Writers'
[36m2019-01-29 11:22:06.328 UTC [policies] Manager -> DEBU 6b7[0m Manager Channel looking up path [Application]
[36m2019-01-29 11:22:06.328 UTC [policies] Manager -> DEBU 6b8[0m Manager Channel has managers Application
[36m2019-01-29 11:22:06.328 UTC [policies] Manager -> DEBU 6b9[0m Manager Channel has managers Orderer
[36m2019-01-29 11:22:06.328 UTC [policies] Manager -> DEBU 6ba[0m Manager Channel/Application looking up path []
[36m2019-01-29 11:22:06.328 UTC [policies] Manager -> DEBU 6bb[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 11:22:06.328 UTC [policies] Manager -> DEBU 6bc[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 11:22:06.328 UTC [policies] Manager -> DEBU 6bd[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 11:22:06.328 UTC [common/channelconfig] LogSanityChecks -> DEBU 6be[0m As expected, current configuration has policy '/Channel/Application/Readers'
[36m2019-01-29 11:22:06.328 UTC [common/channelconfig] LogSanityChecks -> DEBU 6bf[0m As expected, current configuration has policy '/Channel/Application/Writers'
[36m2019-01-29 11:22:06.328 UTC [common/channelconfig] LogSanityChecks -> DEBU 6c0[0m As expected, current configuration has policy '/Channel/Application/Admins'
[36m2019-01-29 11:22:06.328 UTC [policies] Manager -> DEBU 6c1[0m Manager Channel looking up path [Orderer]
[36m2019-01-29 11:22:06.328 UTC [policies] Manager -> DEBU 6c2[0m Manager Channel has managers Application
[36m2019-01-29 11:22:06.328 UTC [policies] Manager -> DEBU 6c3[0m Manager Channel has managers Orderer
[36m2019-01-29 11:22:06.328 UTC [policies] Manager -> DEBU 6c4[0m Manager Channel/Orderer looking up path []
[36m2019-01-29 11:22:06.328 UTC [policies] Manager -> DEBU 6c5[0m Manager Channel/Orderer has managers OrdererOrg
[36m2019-01-29 11:22:06.328 UTC [common/channelconfig] LogSanityChecks -> DEBU 6c6[0m As expected, current configuration has policy '/Channel/Orderer/BlockValidation'
[36m2019-01-29 11:22:06.328 UTC [common/capabilities] Supported -> DEBU 6c7[0m Orderer capability V1_1 is supported and is enabled
[36m2019-01-29 11:22:06.328 UTC [common/capabilities] Supported -> DEBU 6c8[0m Channel capability V1_1 is supported and is enabled
[36m2019-01-29 11:22:06.328 UTC [msp] GetDefaultSigningIdentity -> DEBU 6c9[0m Obtaining default signing identity
[36m2019-01-29 11:22:06.328 UTC [msp] GetDefaultSigningIdentity -> DEBU 6ca[0m Obtaining default signing identity
[36m2019-01-29 11:22:06.328 UTC [msp/identity] Sign -> DEBU 6cb[0m Sign: plaintext: 0ABD060A0A4F7264657265724D535012...5425392F1F373837A67D6D1E818CA8E4 
[36m2019-01-29 11:22:06.328 UTC [msp/identity] Sign -> DEBU 6cc[0m Sign: digest: 07B35C304622C3B6432B36E4425371EDE4E825B88F8359F04C07A5CC3F70AAFE 
[36m2019-01-29 11:22:06.328 UTC [orderer/commmon/multichannel] addLastConfigSignature -> DEBU 6cd[0m [channel: comunitychannel] Detected lastConfigSeq transitioning from 2 to 3, setting lastConfigBlockNum from 1 to 2
[36m2019-01-29 11:22:06.328 UTC [msp] GetDefaultSigningIdentity -> DEBU 6ce[0m Obtaining default signing identity
[36m2019-01-29 11:22:06.328 UTC [orderer/commmon/multichannel] addLastConfigSignature -> DEBU 6cf[0m [channel: comunitychannel] About to write block, setting its LAST_CONFIG to 2
[36m2019-01-29 11:22:06.328 UTC [msp] GetDefaultSigningIdentity -> DEBU 6d0[0m Obtaining default signing identity
[36m2019-01-29 11:22:06.328 UTC [msp/identity] Sign -> DEBU 6d1[0m Sign: plaintext: 08020ABD060A0A4F7264657265724D53...5425392F1F373837A67D6D1E818CA8E4 
[36m2019-01-29 11:22:06.328 UTC [msp/identity] Sign -> DEBU 6d2[0m Sign: digest: 723F76898A77CD662214CB28031AD4A20543AB6132619DFD048C7123ABF4A691 
[36m2019-01-29 11:22:06.335 UTC [fsblkstorage] indexBlock -> DEBU 6d3[0m Indexing block [blockNum=2, blockHash=[]byte{0xfc, 0xfe, 0xf0, 0xa2, 0x3d, 0x94, 0xdf, 0x5a, 0x51, 0xb3, 0xb3, 0xcb, 0x76, 0x22, 0xee, 0xd6, 0x7b, 0x9b, 0x60, 0xb5, 0x59, 0x9b, 0x4f, 0xf2, 0x63, 0xc8, 0x8, 0x8f, 0xef, 0xc0, 0xa6, 0x6b} txOffsets=
txId= locPointer=offset=71, bytesLength=21751
]
[36m2019-01-29 11:22:06.345 UTC [fsblkstorage] updateCheckpoint -> DEBU 6d4[0m Broadcasting about update checkpointInfo: latestFileChunkSuffixNum=[0], latestFileChunksize=[69095], isChainEmpty=[false], lastBlockNumber=[2]
[36m2019-01-29 11:22:06.345 UTC [orderer/commmon/multichannel] commitBlock -> DEBU 6d5[0m [channel: comunitychannel] Wrote block 2
[36m2019-01-29 11:22:22.115 UTC [orderer/consensus/kafka] try -> DEBU 6d6[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 11:22:22.118 UTC [orderer/consensus/kafka] try -> DEBU 6d7[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
[36m2019-01-29 11:22:46.317 UTC [orderer/consensus/kafka] processMessagesToBlocks -> DEBU 6d8[0m [channel: comunitychannel] Successfully unmarshalled consumed message, offset is 7. Inspecting type...
[36m2019-01-29 11:22:46.318 UTC [orderer/consensus/kafka] processRegular -> DEBU 6d9[0m [channel: comunitychannel] Processing regular Kafka message of type CONFIG
[36m2019-01-29 11:22:46.318 UTC [orderer/consensus/kafka] func2 -> DEBU 6da[0m [channel: comunitychannel] Received config message
[36m2019-01-29 11:22:46.318 UTC [orderer/consensus/kafka] func2 -> DEBU 6db[0m [channel: comunitychannel] Creating isolated block for config message
[36m2019-01-29 11:22:46.318 UTC [common/configtx] addToMap -> DEBU 6dc[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 11:22:46.318 UTC [common/configtx] addToMap -> DEBU 6dd[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 11:22:46.318 UTC [common/configtx] addToMap -> DEBU 6de[0m Adding to config map: [Group]  /Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:46.318 UTC [common/configtx] addToMap -> DEBU 6df[0m Adding to config map: [Value]  /Channel/Application/Hospital1MSP/MSP
[36m2019-01-29 11:22:46.318 UTC [common/configtx] addToMap -> DEBU 6e0[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Admins
[36m2019-01-29 11:22:46.318 UTC [common/configtx] addToMap -> DEBU 6e1[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Readers
[36m2019-01-29 11:22:46.318 UTC [common/configtx] addToMap -> DEBU 6e2[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Writers
[36m2019-01-29 11:22:46.318 UTC [common/configtx] addToMap -> DEBU 6e3[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 11:22:46.318 UTC [common/configtx] addToMap -> DEBU 6e4[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 11:22:46.319 UTC [common/configtx] addToMap -> DEBU 6e5[0m Adding to config map: [Group]  /Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:46.319 UTC [common/configtx] addToMap -> DEBU 6e6[0m Adding to config map: [Value]  /Channel/Application/Hospital1MSP/MSP
[36m2019-01-29 11:22:46.319 UTC [common/configtx] addToMap -> DEBU 6e7[0m Adding to config map: [Value]  /Channel/Application/Hospital1MSP/AnchorPeers
[36m2019-01-29 11:22:46.319 UTC [common/configtx] addToMap -> DEBU 6e8[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Readers
[36m2019-01-29 11:22:46.320 UTC [common/configtx] addToMap -> DEBU 6e9[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Writers
[36m2019-01-29 11:22:46.320 UTC [common/configtx] addToMap -> DEBU 6ea[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Admins
[36m2019-01-29 11:22:46.320 UTC [common/configtx] verifyDeltaSet -> DEBU 6eb[0m Processing change to key: [Group]  /Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:46.320 UTC [common/configtx] policyForItem -> DEBU 6ec[0m Getting policy for item Hospital1MSP with mod_policy Admins
[36m2019-01-29 11:22:46.320 UTC [policies] Manager -> DEBU 6ed[0m Manager Channel looking up path [Application]
[36m2019-01-29 11:22:46.320 UTC [policies] Manager -> DEBU 6ee[0m Manager Channel has managers Application
[36m2019-01-29 11:22:46.320 UTC [policies] Manager -> DEBU 6ef[0m Manager Channel has managers Orderer
[36m2019-01-29 11:22:46.320 UTC [policies] Manager -> DEBU 6f0[0m Manager Channel/Application looking up path []
[36m2019-01-29 11:22:46.320 UTC [policies] Manager -> DEBU 6f1[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 11:22:46.320 UTC [policies] Manager -> DEBU 6f2[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 11:22:46.320 UTC [policies] Manager -> DEBU 6f3[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 11:22:46.320 UTC [policies] Manager -> DEBU 6f4[0m Manager Channel/Application looking up path [Hospital1MSP]
[36m2019-01-29 11:22:46.320 UTC [policies] Manager -> DEBU 6f5[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 11:22:46.320 UTC [policies] Manager -> DEBU 6f6[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 11:22:46.320 UTC [policies] Manager -> DEBU 6f7[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 11:22:46.321 UTC [policies] Manager -> DEBU 6f8[0m Manager Channel/Application/Hospital1MSP looking up path []
[36m2019-01-29 11:22:46.321 UTC [policies] Evaluate -> DEBU 6f9[0m == Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital1MSP/Admins ==
2019-01-29 11:22:46.321 UTC [msp] DeserializeIdentity -> INFO 6fa[0m Obtaining identity
[36m2019-01-29 11:22:46.321 UTC [msp/identity] newIdentity -> DEBU 6fb[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfWgAwIBAgIQbzxpSKiuJCzDiDlZp+XbWDAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjB4MQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZyYW5jaXNjbzEPMA0GA1UECxMG
Y2xpZW50MSswKQYDVQQDDCJBZG1pbkBob3NwaXRhbDEuc3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEnpADl8+aUBcVWv6q3IgMQ4yg
ISawQ0wamHmpSv+/b1B5hf4V2HyoPrawIr45+o4/Qz++WazZlyY7PkoT27r7KaNN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgVVOw
6D/TLH/5zUzZeuRccAF2fNnmhgU+81mHcoeEGwYwCgYIKoZIzj0EAwIDSAAwRQIh
ALavdMm9i6xSsnWdlliMh10s6dmGBaXO0CxaCowLJIMtAiBEduudGJymDDE1zbiX
YwX83cYWZHUcYV8IXeZPFymC+w==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:46.321 UTC [cauthdsl] func1 -> DEBU 6fc[0m 0xc4200bc748 gate 1548760966321971309 evaluation starts
[36m2019-01-29 11:22:46.322 UTC [cauthdsl] func2 -> DEBU 6fd[0m 0xc4200bc748 signed by 0 principal evaluation starts (used [false])
[36m2019-01-29 11:22:46.322 UTC [cauthdsl] func2 -> DEBU 6fe[0m 0xc4200bc748 processing identity 0 with bytes of 0a0c486f73706974616c314d535012df062d2d2d2d2d424547494e2043455254494649434154452d2d2d2d2d0a4d494943547a4343416657674177494241674951627a7870534b69754a437a4469446c5a702b58625744414b42676771686b6a4f50515144416a4342697a454c0a4d416b474131554542684d4356564d78457a415242674e5642416754436b4e6862476c6d62334a7561574578466a415542674e564241635444564e68626942470a636d467559326c7a593238784a54416a42674e5642416f544847687663334270644746734d53357a64326c30593267796247396e61574d7559323875656d45780a4b44416d42674e5642414d5448324e684c6d687663334270644746734d53357a64326c30593267796247396e61574d7559323875656d45774868634e4d546b770a4d5449354d4463304d5455305768634e4d6a6b774d5449324d4463304d545530576a42344d517377435159445651514745774a56557a45544d424547413155450a43424d4b5132467361575a76636d3570595445574d4251474131554542784d4e5532467549455a795957356a61584e6a627a45504d4130474131554543784d470a593278705a5735304d5373774b5159445651514444434a425a473170626b426f62334e7761585268624445756333647064474e6f4d6d78765a326c6a4c6d4e760a4c6e70684d466b77457759484b6f5a497a6a3043415159494b6f5a497a6a304441516344516741456e7041446c382b6155426356577636713349674d513479670a49536177513077616d486d7053762b2f62314235686634563248796f50726177497234352b6f342f517a2b2b57617a5a6c795937506b6f54323772374b614e4e0a4d45737744675944565230504151482f42415144416765414d41774741315564457745422f7751434d4141774b7759445652306a42435177496f416756564f770a36442f544c482f357a557a5a6575526363414632664e6e6d6867552b38316d48636f654547775977436759494b6f5a497a6a30454177494453414177525149680a414c6176644d6d3969367853736e57646c6c694d6831307336646d474261584f30437861436f774c4a494d744169424564757564474a796d444445317a6269580a59775838336359575a4855635956384958655a5046796d432b773d3d0a2d2d2d2d2d454e442043455254494649434154452d2d2d2d2d0a
[36m2019-01-29 11:22:46.322 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 6ff[0m Checking if identity satisfies ADMIN role for Hospital1MSP
[36m2019-01-29 11:22:46.322 UTC [cauthdsl] func2 -> DEBU 700[0m 0xc4200bc748 principal matched by identity 0
[36m2019-01-29 11:22:46.322 UTC [msp/identity] Verify -> DEBU 701[0m Verify: digest = 00000000  2a b7 e0 fc 5e 0e fa d9  8c 68 56 4b 83 df 68 8e  |*...^....hVK..h.|
00000010  52 74 fd e1 61 6d b6 a3  f4 b4 13 5e cc ae 0c d6  |Rt..am.....^....|
[36m2019-01-29 11:22:46.322 UTC [msp/identity] Verify -> DEBU 702[0m Verify: sig = 00000000  30 45 02 21 00 fd 8b 6f  88 cf 7e 8b af 32 6e df  |0E.!...o..~..2n.|
00000010  f3 0a 58 cc 86 42 b1 60  8e b1 e5 6d 6d ee 48 57  |..X..B.`...mm.HW|
00000020  2e b1 97 f9 1a 02 20 32  72 f0 68 23 a9 15 3f 45  |...... 2r.h#..?E|
00000030  31 84 b4 61 dc f1 5d b0  a5 e6 ec 01 f9 b5 5b 97  |1..a..].......[.|
00000040  77 8e 39 8a 75 b5 cc                              |w.9.u..|
[36m2019-01-29 11:22:46.322 UTC [cauthdsl] func2 -> DEBU 703[0m 0xc4200bc748 principal evaluation succeeds for identity 0
[36m2019-01-29 11:22:46.322 UTC [cauthdsl] func1 -> DEBU 704[0m 0xc4200bc748 gate 1548760966321971309 evaluation succeeds
[36m2019-01-29 11:22:46.322 UTC [policies] Evaluate -> DEBU 705[0m Signature set satisfies policy /Channel/Application/Hospital1MSP/Admins
[36m2019-01-29 11:22:46.322 UTC [policies] Evaluate -> DEBU 706[0m == Done Evaluating *cauthdsl.policy Policy /Channel/Application/Hospital1MSP/Admins
[36m2019-01-29 11:22:46.322 UTC [common/configtx] verifyDeltaSet -> DEBU 707[0m Processing change to key: [Value]  /Channel/Application/Hospital1MSP/AnchorPeers
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 708[0m Setting policy for key Readers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital3MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 709[0m Setting policy for key Writers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital3MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 70a[0m Setting policy for key Admins to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\022\022\020\n\014Hospital3MSP\020\001" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 70b[0m Setting policy for key Admins to 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 70c[0m Setting policy for key Readers to 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 70d[0m Setting policy for key Writers to 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 70e[0m Setting policy for key Readers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital2MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 70f[0m Setting policy for key Writers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\014Hospital2MSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 710[0m Setting policy for key Admins to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\022\022\020\n\014Hospital2MSP\020\001" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 711[0m Setting policy for key Writers to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 712[0m Setting policy for key Admins to policy:<type:3 value:"\n\006Admins\020\002" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 713[0m Setting policy for key Readers to policy:<type:3 value:"\n\007Readers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 714[0m Setting policy for key Readers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\016\022\014\n\nOrdererMSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 715[0m Setting policy for key Writers to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\016\022\014\n\nOrdererMSP" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 716[0m Setting policy for key Admins to policy:<type:1 value:"\022\010\022\006\010\001\022\002\010\000\032\020\022\016\n\nOrdererMSP\020\001" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 717[0m Setting policy for key Readers to policy:<type:3 value:"\n\007Readers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 718[0m Setting policy for key Writers to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 719[0m Setting policy for key BlockValidation to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 71a[0m Setting policy for key Admins to policy:<type:3 value:"\n\006Admins\020\002" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 71b[0m Setting policy for key Readers to policy:<type:3 value:"\n\007Readers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 71c[0m Setting policy for key Writers to policy:<type:3 value:"\n\007Writers" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.323 UTC [common/configtx] recurseConfigMap -> DEBU 71d[0m Setting policy for key Admins to policy:<type:3 value:"\n\006Admins\020\002" > mod_policy:"Admins" 
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] NewStandardValues -> DEBU 71e[0m Initializing protos for *channelconfig.ChannelProtos
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 71f[0m Processing field: HashingAlgorithm
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 720[0m Processing field: BlockDataHashingStructure
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 721[0m Processing field: OrdererAddresses
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 722[0m Processing field: Consortium
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 723[0m Processing field: Capabilities
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] NewStandardValues -> DEBU 724[0m Initializing protos for *channelconfig.OrdererProtos
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 725[0m Processing field: ConsensusType
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 726[0m Processing field: BatchSize
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 727[0m Processing field: BatchTimeout
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 728[0m Processing field: KafkaBrokers
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 729[0m Processing field: ChannelRestrictions
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 72a[0m Processing field: Capabilities
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] NewStandardValues -> DEBU 72b[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] initializeProtosStruct -> DEBU 72c[0m Processing field: MSP
[36m2019-01-29 11:22:46.324 UTC [common/channelconfig] validateMSP -> DEBU 72d[0m Setting up MSP for org OrdererOrg
[36m2019-01-29 11:22:46.324 UTC [msp] newBccspMsp -> DEBU 72e[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:22:46.324 UTC [msp] New -> DEBU 72f[0m Creating Cache-MSP instance
[36m2019-01-29 11:22:46.324 UTC [msp] Setup -> DEBU 730[0m Setting up MSP instance OrdererMSP
[36m2019-01-29 11:22:46.327 UTC [msp/identity] newIdentity -> DEBU 731[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICSzCCAfKgAwIBAgIRAO7EFp+tGDrZX/4Yn1ExG4IwCgYIKoZIzj0EAwIwdzEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEeMBwGA1UEAxMV
Y2Euc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5MDEyOTA3NDE1NFoXDTI5MDEyNjA3
NDE1NFowdzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNV
BAcTDVNhbiBGcmFuY2lzY28xGzAZBgNVBAoTEnN3aXRjaDJsb2dpYy5jby56YTEe
MBwGA1UEAxMVY2Euc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZI
zj0DAQcDQgAE+ci0VrQQEnBN2VlYMEvGL0RvqwQ9zVhgyxdKDi9AB8iyQ0dhyWzJ
CZ9MnAWGk29pw9b+9HdNkbalpJKWkcctJ6NfMF0wDgYDVR0PAQH/BAQDAgGmMA8G
A1UdJQQIMAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgGIY2e0Pm
0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDRwAwRAIgcoBa
RHN5r57Qu7sd8TwCzfyJI+uozczAYI2SsN06iKgCIAeAP4FbTHxjqSLcNZMNGbTZ
YWA1h+rDBMa99duId/0D
-----END CERTIFICATE-----
[36m2019-01-29 11:22:46.327 UTC [msp/identity] newIdentity -> DEBU 732[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICHzCCAcWgAwIBAgIQRo5Qm6m11gCv1i2SXwRJAjAKBggqhkjOPQQDAjB3MQsw
CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy
YW5jaXNjbzEbMBkGA1UEChMSc3dpdGNoMmxvZ2ljLmNvLnphMR4wHAYDVQQDExVj
YS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkwMTI5MDc0MTU0WhcNMjkwMTI2MDc0
MTU0WjBdMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UE
BxMNU2FuIEZyYW5jaXNjbzEhMB8GA1UEAwwYQWRtaW5Ac3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE0QeSwnrMZdy7TKSYF/JzQ12C
vfINZcjx7xyeUuj/96gj42fjc1ctn7oo/tDl1eJNZbDhFvkRzefYmxtoSnH5Y6NN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgGIY2
e0Pm0GUb0LxA2x1d17ci1NFFr6n/7fInBEKxsnEwCgYIKoZIzj0EAwIDSAAwRQIh
AM8EkjCZIKrAf9sL1d1fThizng+66jmEVlKPbTpimVbiAiAhCJZoeBIJGcgxbCr2
5Rd2IW34zWcPhemkNZvCKv27WA==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:46.328 UTC [msp] Validate -> DEBU 733[0m MSP OrdererMSP validating identity
[36m2019-01-29 11:22:46.328 UTC [common/channelconfig] NewStandardValues -> DEBU 734[0m Initializing protos for *channelconfig.ApplicationProtos
[36m2019-01-29 11:22:46.328 UTC [common/channelconfig] initializeProtosStruct -> DEBU 735[0m Processing field: ACLs
[36m2019-01-29 11:22:46.328 UTC [common/channelconfig] initializeProtosStruct -> DEBU 736[0m Processing field: Capabilities
[36m2019-01-29 11:22:46.328 UTC [common/channelconfig] NewStandardValues -> DEBU 737[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 11:22:46.328 UTC [common/channelconfig] initializeProtosStruct -> DEBU 738[0m Processing field: AnchorPeers
[36m2019-01-29 11:22:46.328 UTC [common/channelconfig] NewStandardValues -> DEBU 739[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:22:46.328 UTC [common/channelconfig] initializeProtosStruct -> DEBU 73a[0m Processing field: MSP
[36m2019-01-29 11:22:46.328 UTC [common/channelconfig] Validate -> DEBU 73b[0m Anchor peers for org Hospital1MSP are anchor_peers:<host:"peer0.hospital1.switch2logic.co.za" port:7051 > 
[36m2019-01-29 11:22:46.328 UTC [common/channelconfig] validateMSP -> DEBU 73c[0m Setting up MSP for org Hospital1MSP
[36m2019-01-29 11:22:46.328 UTC [msp] newBccspMsp -> DEBU 73d[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:22:46.328 UTC [msp] New -> DEBU 73e[0m Creating Cache-MSP instance
[36m2019-01-29 11:22:46.328 UTC [msp] Setup -> DEBU 73f[0m Setting up MSP instance Hospital1MSP
[36m2019-01-29 11:22:46.329 UTC [msp/identity] newIdentity -> DEBU 740[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdDCCAhugAwIBAgIQZxH8VsnceZxXgKxlURLgVTAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMS5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQX9V4k/h/3pFxByKDscjgQrC0YS/bSbKvzSG2Z2PvltEWp40qB9OaKUN0GQYzo
yK2Etdvyjfd1OFwaTjpGSvv9o18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCBVU7DoP9Msf/nNTNl6
5FxwAXZ82eaGBT7zWYdyh4QbBjAKBggqhkjOPQQDAgNHADBEAiBmXGWQbxCGRp0c
5/y9qJyciB1CDHsknRZDjNzt5f563wIgMy7VPi1R8DpIIIRN9B3mfhDpRa+J+8PA
S4DOJy7rjp4=
-----END CERTIFICATE-----
[36m2019-01-29 11:22:46.329 UTC [msp/identity] newIdentity -> DEBU 741[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfWgAwIBAgIQbzxpSKiuJCzDiDlZp+XbWDAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMS5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjB4MQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZyYW5jaXNjbzEPMA0GA1UECxMG
Y2xpZW50MSswKQYDVQQDDCJBZG1pbkBob3NwaXRhbDEuc3dpdGNoMmxvZ2ljLmNv
LnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEnpADl8+aUBcVWv6q3IgMQ4yg
ISawQ0wamHmpSv+/b1B5hf4V2HyoPrawIr45+o4/Qz++WazZlyY7PkoT27r7KaNN
MEswDgYDVR0PAQH/BAQDAgeAMAwGA1UdEwEB/wQCMAAwKwYDVR0jBCQwIoAgVVOw
6D/TLH/5zUzZeuRccAF2fNnmhgU+81mHcoeEGwYwCgYIKoZIzj0EAwIDSAAwRQIh
ALavdMm9i6xSsnWdlliMh10s6dmGBaXO0CxaCowLJIMtAiBEduudGJymDDE1zbiX
YwX83cYWZHUcYV8IXeZPFymC+w==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:46.330 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 742[0m Checking if identity satisfies role [CLIENT] for Hospital1MSP
[36m2019-01-29 11:22:46.330 UTC [msp] Validate -> DEBU 743[0m MSP Hospital1MSP validating identity
[36m2019-01-29 11:22:46.330 UTC [msp] getCertificationChain -> DEBU 744[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 11:22:46.331 UTC [msp] hasOURole -> DEBU 745[0m MSP Hospital1MSP checking if the identity is a client
[36m2019-01-29 11:22:46.331 UTC [msp] getCertificationChain -> DEBU 746[0m MSP Hospital1MSP getting certification chain
[36m2019-01-29 11:22:46.332 UTC [common/channelconfig] NewStandardValues -> DEBU 747[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 11:22:46.332 UTC [common/channelconfig] initializeProtosStruct -> DEBU 748[0m Processing field: AnchorPeers
[36m2019-01-29 11:22:46.332 UTC [common/channelconfig] NewStandardValues -> DEBU 749[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:22:46.332 UTC [common/channelconfig] initializeProtosStruct -> DEBU 74a[0m Processing field: MSP
[36m2019-01-29 11:22:46.332 UTC [common/channelconfig] Validate -> DEBU 74b[0m Anchor peers for org Hospital2MSP are anchor_peers:<host:"peer0.hospital2.switch2logic.co.za" port:7051 > 
[36m2019-01-29 11:22:46.332 UTC [common/channelconfig] validateMSP -> DEBU 74c[0m Setting up MSP for org Hospital2MSP
[36m2019-01-29 11:22:46.332 UTC [msp] newBccspMsp -> DEBU 74d[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:22:46.332 UTC [msp] New -> DEBU 74e[0m Creating Cache-MSP instance
[36m2019-01-29 11:22:46.332 UTC [msp] Setup -> DEBU 74f[0m Setting up MSP instance Hospital2MSP
[36m2019-01-29 11:22:46.333 UTC [msp/identity] newIdentity -> DEBU 750[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdjCCAhygAwIBAgIRALZ3Pffn/xWUtUWPSK6CYVAwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFowgYsxCzAJBgNVBAYTAlVTMRMwEQYD
VQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4gRnJhbmNpc2NvMSUwIwYDVQQK
Exxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMSgwJgYDVQQDEx9jYS5ob3Nw
aXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcD
QgAESzVpiz6P4mIb+KwvrttcXJKZR5i137Is4298E7OrkYdAg0tB4rpfKTXzUMwW
vI12cTDujpyaZSiqQ3/zP4fOQqNfMF0wDgYDVR0PAQH/BAQDAgGmMA8GA1UdJQQI
MAYGBFUdJQAwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQg8QJqWKPaX24HINwR
S6sINFSwRD+440/ccSnvFVaGF24wCgYIKoZIzj0EAwIDSAAwRQIhAPO2Nng3/nqb
cKPliUqVPVjBMu+D55M90+jexWSOpkjcAiADPx8qv9exZ4BfP3+G49Qzpx0Meblj
53vzUgYFa/0EXw==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:46.337 UTC [msp/identity] newIdentity -> DEBU 751[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAJ6XtHMTTW1JzdpD54qCc3wwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDIuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwyLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABA+z1rb9aA1HwHfNLi9V9VZe
bdwT4MXak445zGz4DXzRUsmNeBngzntKb6qpgHQpeFtzbzLx+zwiynRDvfdzORGj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIPEC
alij2l9uByDcEUurCDRUsEQ/uONP3HEp7xVWhhduMAoGCCqGSM49BAMCA0cAMEQC
IA8A3CCJeCasyy7gYd/M1aHYmwWsecY7UY7cVUGy4XOxAiB0rrmfnGW6JA11PDCu
+5c5Rpn0jF5ddsFn+UIpzBFvmg==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:46.338 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 752[0m Checking if identity satisfies role [CLIENT] for Hospital2MSP
[36m2019-01-29 11:22:46.338 UTC [msp] Validate -> DEBU 753[0m MSP Hospital2MSP validating identity
[36m2019-01-29 11:22:46.338 UTC [msp] getCertificationChain -> DEBU 754[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 11:22:46.339 UTC [msp] hasOURole -> DEBU 755[0m MSP Hospital2MSP checking if the identity is a client
[36m2019-01-29 11:22:46.339 UTC [msp] getCertificationChain -> DEBU 756[0m MSP Hospital2MSP getting certification chain
[36m2019-01-29 11:22:46.339 UTC [common/channelconfig] NewStandardValues -> DEBU 757[0m Initializing protos for *channelconfig.ApplicationOrgProtos
[36m2019-01-29 11:22:46.339 UTC [common/channelconfig] initializeProtosStruct -> DEBU 758[0m Processing field: AnchorPeers
[36m2019-01-29 11:22:46.339 UTC [common/channelconfig] NewStandardValues -> DEBU 759[0m Initializing protos for *channelconfig.OrganizationProtos
[36m2019-01-29 11:22:46.339 UTC [common/channelconfig] initializeProtosStruct -> DEBU 75a[0m Processing field: MSP
[36m2019-01-29 11:22:46.339 UTC [common/channelconfig] Validate -> DEBU 75b[0m Anchor peers for org Hospital3MSP are anchor_peers:<host:"peer0.hospital3.switch2logic.co.za" port:7051 > 
[36m2019-01-29 11:22:46.340 UTC [common/channelconfig] validateMSP -> DEBU 75c[0m Setting up MSP for org Hospital3MSP
[36m2019-01-29 11:22:46.340 UTC [msp] newBccspMsp -> DEBU 75d[0m Creating BCCSP-based MSP instance
[36m2019-01-29 11:22:46.340 UTC [msp] New -> DEBU 75e[0m Creating Cache-MSP instance
[36m2019-01-29 11:22:46.340 UTC [msp] Setup -> DEBU 75f[0m Setting up MSP instance Hospital3MSP
[36m2019-01-29 11:22:46.340 UTC [msp/identity] newIdentity -> DEBU 760[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICdTCCAhugAwIBAgIQCCXeHGgObIJo8aq4AdvgVjAKBggqhkjOPQQDAjCBizEL
MAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG
cmFuY2lzY28xJTAjBgNVBAoTHGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEx
KDAmBgNVBAMTH2NhLmhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemEwHhcNMTkw
MTI5MDc0MTU0WhcNMjkwMTI2MDc0MTU0WjCBizELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xJTAjBgNVBAoT
HGhvc3BpdGFsMy5zd2l0Y2gybG9naWMuY28uemExKDAmBgNVBAMTH2NhLmhvc3Bp
dGFsMy5zd2l0Y2gybG9naWMuY28uemEwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNC
AAQm1Oo/AEu7ZZToE15Y5ntlaN128Hs/exX3jNH5nO6r4tvyFtBBNEn1ecXxxPtm
dmQ+nPHONorLwDC42SMAKwfro18wXTAOBgNVHQ8BAf8EBAMCAaYwDwYDVR0lBAgw
BgYEVR0lADAPBgNVHRMBAf8EBTADAQH/MCkGA1UdDgQiBCA7vVWFXWpgZBojQ1ZL
xUvgBLeia59MivIRcjxmYanpyTAKBggqhkjOPQQDAgNIADBFAiEAlOUoPtpfO8V7
vFRCanjU5zZWGO5ajFlPDJjjDTy3UrwCICrUYV32JrR/m3dslCl15dSThHrKtYCC
Ehvyw1+lNqiG
-----END CERTIFICATE-----
[36m2019-01-29 11:22:46.340 UTC [msp/identity] newIdentity -> DEBU 761[0m Creating identity instance for cert -----BEGIN CERTIFICATE-----
MIICTzCCAfagAwIBAgIRAI8BA/5Jf+5m8ncI+D7aSiMwCgYIKoZIzj0EAwIwgYsx
CzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRYwFAYDVQQHEw1TYW4g
RnJhbmNpc2NvMSUwIwYDVQQKExxob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnph
MSgwJgYDVQQDEx9jYS5ob3NwaXRhbDMuc3dpdGNoMmxvZ2ljLmNvLnphMB4XDTE5
MDEyOTA3NDE1NFoXDTI5MDEyNjA3NDE1NFoweDELMAkGA1UEBhMCVVMxEzARBgNV
BAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lzY28xDzANBgNVBAsT
BmNsaWVudDErMCkGA1UEAwwiQWRtaW5AaG9zcGl0YWwzLnN3aXRjaDJsb2dpYy5j
by56YTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABF1IehIKIjh8tXYZ7rw4QOuc
g/tpBAkJeOt44zr/LepbjhyFW8vIRnkw75i6Wcg+LOoAS+2NFNg2oNjqg//yCHWj
TTBLMA4GA1UdDwEB/wQEAwIHgDAMBgNVHRMBAf8EAjAAMCsGA1UdIwQkMCKAIDu9
VYVdamBkGiNDVkvFS+AEt6Jrn0yK8hFyPGZhqenJMAoGCCqGSM49BAMCA0cAMEQC
IFyc85pwbCAxGNdw4fflsX2I3HrP3h93YAB2zSDC8HtkAiAQxblAZfEnXUiQKrqE
8I10bYJqD6pJz1jb3Pv+4xplTA==
-----END CERTIFICATE-----
[36m2019-01-29 11:22:46.341 UTC [msp] satisfiesPrincipalInternalPreV13 -> DEBU 762[0m Checking if identity satisfies role [CLIENT] for Hospital3MSP
[36m2019-01-29 11:22:46.341 UTC [msp] Validate -> DEBU 763[0m MSP Hospital3MSP validating identity
[36m2019-01-29 11:22:46.341 UTC [msp] getCertificationChain -> DEBU 764[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 11:22:46.342 UTC [msp] hasOURole -> DEBU 765[0m MSP Hospital3MSP checking if the identity is a client
[36m2019-01-29 11:22:46.342 UTC [msp] getCertificationChain -> DEBU 766[0m MSP Hospital3MSP getting certification chain
[36m2019-01-29 11:22:46.342 UTC [msp] Setup -> DEBU 767[0m Setting up the MSP manager (4 msps)
[36m2019-01-29 11:22:46.342 UTC [msp] Setup -> DEBU 768[0m MSP manager setup complete, setup 4 msps
[36m2019-01-29 11:22:46.342 UTC [policies] NewManagerImpl -> DEBU 769[0m Proposed new policy Writers for Channel/Orderer/OrdererOrg
[36m2019-01-29 11:22:46.342 UTC [policies] NewManagerImpl -> DEBU 76a[0m Proposed new policy Admins for Channel/Orderer/OrdererOrg
[36m2019-01-29 11:22:46.342 UTC [policies] NewManagerImpl -> DEBU 76b[0m Proposed new policy Readers for Channel/Orderer/OrdererOrg
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 76c[0m Proposed new policy BlockValidation for Channel/Orderer
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 76d[0m Proposed new policy Admins for Channel/Orderer
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 76e[0m Proposed new policy Readers for Channel/Orderer
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 76f[0m Proposed new policy Writers for Channel/Orderer
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 770[0m Proposed new policy Writers for Channel/Application/Hospital3MSP
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 771[0m Proposed new policy Admins for Channel/Application/Hospital3MSP
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 772[0m Proposed new policy Readers for Channel/Application/Hospital3MSP
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 773[0m Proposed new policy Readers for Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 774[0m Proposed new policy Writers for Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 775[0m Proposed new policy Admins for Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 776[0m Proposed new policy Writers for Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 777[0m Proposed new policy Admins for Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 778[0m Proposed new policy Readers for Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 779[0m Proposed new policy Admins for Channel/Application
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 77a[0m Proposed new policy Readers for Channel/Application
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 77b[0m Proposed new policy Writers for Channel/Application
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 77c[0m Proposed new policy Admins for Channel
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 77d[0m Proposed new policy Readers for Channel
[36m2019-01-29 11:22:46.343 UTC [policies] NewManagerImpl -> DEBU 77e[0m Proposed new policy Writers for Channel
[36m2019-01-29 11:22:46.343 UTC [common/configtx] addToMap -> DEBU 77f[0m Adding to config map: [Group]  /Channel
[36m2019-01-29 11:22:46.343 UTC [common/configtx] addToMap -> DEBU 780[0m Adding to config map: [Group]  /Channel/Orderer
[36m2019-01-29 11:22:46.343 UTC [common/configtx] addToMap -> DEBU 781[0m Adding to config map: [Group]  /Channel/Orderer/OrdererOrg
[36m2019-01-29 11:22:46.343 UTC [common/configtx] addToMap -> DEBU 782[0m Adding to config map: [Value]  /Channel/Orderer/OrdererOrg/MSP
[36m2019-01-29 11:22:46.343 UTC [common/configtx] addToMap -> DEBU 783[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Admins
[36m2019-01-29 11:22:46.343 UTC [common/configtx] addToMap -> DEBU 784[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Readers
[36m2019-01-29 11:22:46.343 UTC [common/configtx] addToMap -> DEBU 785[0m Adding to config map: [Policy] /Channel/Orderer/OrdererOrg/Writers
[36m2019-01-29 11:22:46.343 UTC [common/configtx] addToMap -> DEBU 786[0m Adding to config map: [Value]  /Channel/Orderer/KafkaBrokers
[36m2019-01-29 11:22:46.343 UTC [common/configtx] addToMap -> DEBU 787[0m Adding to config map: [Value]  /Channel/Orderer/ConsensusType
[36m2019-01-29 11:22:46.343 UTC [common/configtx] addToMap -> DEBU 788[0m Adding to config map: [Value]  /Channel/Orderer/BatchSize
[36m2019-01-29 11:22:46.343 UTC [common/configtx] addToMap -> DEBU 789[0m Adding to config map: [Value]  /Channel/Orderer/BatchTimeout
[36m2019-01-29 11:22:46.343 UTC [common/configtx] addToMap -> DEBU 78a[0m Adding to config map: [Value]  /Channel/Orderer/ChannelRestrictions
[36m2019-01-29 11:22:46.343 UTC [common/configtx] addToMap -> DEBU 78b[0m Adding to config map: [Value]  /Channel/Orderer/Capabilities
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 78c[0m Adding to config map: [Policy] /Channel/Orderer/Readers
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 78d[0m Adding to config map: [Policy] /Channel/Orderer/Writers
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 78e[0m Adding to config map: [Policy] /Channel/Orderer/BlockValidation
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 78f[0m Adding to config map: [Policy] /Channel/Orderer/Admins
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 790[0m Adding to config map: [Group]  /Channel/Application
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 791[0m Adding to config map: [Group]  /Channel/Application/Hospital1MSP
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 792[0m Adding to config map: [Value]  /Channel/Application/Hospital1MSP/MSP
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 793[0m Adding to config map: [Value]  /Channel/Application/Hospital1MSP/AnchorPeers
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 794[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Readers
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 795[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Writers
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 796[0m Adding to config map: [Policy] /Channel/Application/Hospital1MSP/Admins
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 797[0m Adding to config map: [Group]  /Channel/Application/Hospital2MSP
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 798[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/AnchorPeers
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 799[0m Adding to config map: [Value]  /Channel/Application/Hospital2MSP/MSP
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 79a[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Readers
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 79b[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Writers
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 79c[0m Adding to config map: [Policy] /Channel/Application/Hospital2MSP/Admins
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 79d[0m Adding to config map: [Group]  /Channel/Application/Hospital3MSP
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 79e[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/AnchorPeers
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 79f[0m Adding to config map: [Value]  /Channel/Application/Hospital3MSP/MSP
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 7a0[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Writers
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 7a1[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Admins
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 7a2[0m Adding to config map: [Policy] /Channel/Application/Hospital3MSP/Readers
[36m2019-01-29 11:22:46.344 UTC [common/configtx] addToMap -> DEBU 7a3[0m Adding to config map: [Value]  /Channel/Application/Capabilities
[36m2019-01-29 11:22:46.345 UTC [common/configtx] addToMap -> DEBU 7a4[0m Adding to config map: [Policy] /Channel/Application/Admins
[36m2019-01-29 11:22:46.345 UTC [common/configtx] addToMap -> DEBU 7a5[0m Adding to config map: [Policy] /Channel/Application/Readers
[36m2019-01-29 11:22:46.345 UTC [common/configtx] addToMap -> DEBU 7a6[0m Adding to config map: [Policy] /Channel/Application/Writers
[36m2019-01-29 11:22:46.354 UTC [common/configtx] addToMap -> DEBU 7a7[0m Adding to config map: [Value]  /Channel/OrdererAddresses
[36m2019-01-29 11:22:46.354 UTC [common/configtx] addToMap -> DEBU 7a8[0m Adding to config map: [Value]  /Channel/Capabilities
[36m2019-01-29 11:22:46.355 UTC [common/configtx] addToMap -> DEBU 7a9[0m Adding to config map: [Value]  /Channel/Consortium
[36m2019-01-29 11:22:46.355 UTC [common/configtx] addToMap -> DEBU 7aa[0m Adding to config map: [Value]  /Channel/HashingAlgorithm
[36m2019-01-29 11:22:46.355 UTC [common/configtx] addToMap -> DEBU 7ab[0m Adding to config map: [Value]  /Channel/BlockDataHashingStructure
[36m2019-01-29 11:22:46.355 UTC [common/configtx] addToMap -> DEBU 7ac[0m Adding to config map: [Policy] /Channel/Admins
[36m2019-01-29 11:22:46.355 UTC [common/configtx] addToMap -> DEBU 7ad[0m Adding to config map: [Policy] /Channel/Readers
[36m2019-01-29 11:22:46.356 UTC [common/configtx] addToMap -> DEBU 7ae[0m Adding to config map: [Policy] /Channel/Writers
[36m2019-01-29 11:22:46.356 UTC [common/channelconfig] LogSanityChecks -> DEBU 7af[0m As expected, current configuration has policy '/Channel/Readers'
[36m2019-01-29 11:22:46.356 UTC [common/channelconfig] LogSanityChecks -> DEBU 7b0[0m As expected, current configuration has policy '/Channel/Writers'
[36m2019-01-29 11:22:46.356 UTC [policies] Manager -> DEBU 7b1[0m Manager Channel looking up path [Application]
[36m2019-01-29 11:22:46.356 UTC [policies] Manager -> DEBU 7b2[0m Manager Channel has managers Application
[36m2019-01-29 11:22:46.356 UTC [policies] Manager -> DEBU 7b3[0m Manager Channel has managers Orderer
[36m2019-01-29 11:22:46.356 UTC [policies] Manager -> DEBU 7b4[0m Manager Channel/Application looking up path []
[36m2019-01-29 11:22:46.356 UTC [policies] Manager -> DEBU 7b5[0m Manager Channel/Application has managers Hospital3MSP
[36m2019-01-29 11:22:46.356 UTC [policies] Manager -> DEBU 7b6[0m Manager Channel/Application has managers Hospital1MSP
[36m2019-01-29 11:22:46.356 UTC [policies] Manager -> DEBU 7b7[0m Manager Channel/Application has managers Hospital2MSP
[36m2019-01-29 11:22:46.356 UTC [common/channelconfig] LogSanityChecks -> DEBU 7b8[0m As expected, current configuration has policy '/Channel/Application/Readers'
[36m2019-01-29 11:22:46.356 UTC [common/channelconfig] LogSanityChecks -> DEBU 7b9[0m As expected, current configuration has policy '/Channel/Application/Writers'
[36m2019-01-29 11:22:46.356 UTC [common/channelconfig] LogSanityChecks -> DEBU 7ba[0m As expected, current configuration has policy '/Channel/Application/Admins'
[36m2019-01-29 11:22:46.356 UTC [policies] Manager -> DEBU 7bb[0m Manager Channel looking up path [Orderer]
[36m2019-01-29 11:22:46.356 UTC [policies] Manager -> DEBU 7bc[0m Manager Channel has managers Orderer
[36m2019-01-29 11:22:46.356 UTC [policies] Manager -> DEBU 7bd[0m Manager Channel has managers Application
[36m2019-01-29 11:22:46.356 UTC [policies] Manager -> DEBU 7be[0m Manager Channel/Orderer looking up path []
[36m2019-01-29 11:22:46.356 UTC [policies] Manager -> DEBU 7bf[0m Manager Channel/Orderer has managers OrdererOrg
[36m2019-01-29 11:22:46.356 UTC [common/channelconfig] LogSanityChecks -> DEBU 7c0[0m As expected, current configuration has policy '/Channel/Orderer/BlockValidation'
[36m2019-01-29 11:22:46.356 UTC [common/capabilities] Supported -> DEBU 7c1[0m Orderer capability V1_1 is supported and is enabled
[36m2019-01-29 11:22:46.356 UTC [common/capabilities] Supported -> DEBU 7c2[0m Channel capability V1_1 is supported and is enabled
[36m2019-01-29 11:22:46.356 UTC [msp] GetDefaultSigningIdentity -> DEBU 7c3[0m Obtaining default signing identity
[36m2019-01-29 11:22:46.356 UTC [msp] GetDefaultSigningIdentity -> DEBU 7c4[0m Obtaining default signing identity
[36m2019-01-29 11:22:46.356 UTC [msp/identity] Sign -> DEBU 7c5[0m Sign: plaintext: 0ABD060A0A4F7264657265724D535012...8DD5B893371CB6035011BD69E7B67DC9 
[36m2019-01-29 11:22:46.356 UTC [msp/identity] Sign -> DEBU 7c6[0m Sign: digest: 4746BC1E5B68D873723A219854609A8CCCBAC184FE0525F871B76F2D56D517D6 
[36m2019-01-29 11:22:46.356 UTC [orderer/commmon/multichannel] addLastConfigSignature -> DEBU 7c7[0m [channel: comunitychannel] Detected lastConfigSeq transitioning from 3 to 4, setting lastConfigBlockNum from 2 to 3
[36m2019-01-29 11:22:46.356 UTC [msp] GetDefaultSigningIdentity -> DEBU 7c8[0m Obtaining default signing identity
[36m2019-01-29 11:22:46.356 UTC [orderer/commmon/multichannel] addLastConfigSignature -> DEBU 7c9[0m [channel: comunitychannel] About to write block, setting its LAST_CONFIG to 3
[36m2019-01-29 11:22:46.356 UTC [msp] GetDefaultSigningIdentity -> DEBU 7ca[0m Obtaining default signing identity
[36m2019-01-29 11:22:46.357 UTC [msp/identity] Sign -> DEBU 7cb[0m Sign: plaintext: 08030ABD060A0A4F7264657265724D53...8DD5B893371CB6035011BD69E7B67DC9 
[36m2019-01-29 11:22:46.357 UTC [msp/identity] Sign -> DEBU 7cc[0m Sign: digest: 16BE3602D38C75042C0633B9BAAEDEF37C62B3936A9E89050716DFA20306E6F2 
[36m2019-01-29 11:22:46.359 UTC [fsblkstorage] indexBlock -> DEBU 7cd[0m Indexing block [blockNum=3, blockHash=[]byte{0xe3, 0x53, 0x1a, 0x6c, 0x50, 0xfb, 0xc9, 0xd0, 0xac, 0xe3, 0xa5, 0x40, 0x98, 0x5f, 0x53, 0x2f, 0x52, 0x42, 0x2c, 0xda, 0xdd, 0xd3, 0x19, 0x17, 0x3b, 0xf3, 0xca, 0xa5, 0x43, 0xcc, 0x4b, 0x8a} txOffsets=
txId= locPointer=offset=71, bytesLength=21822
]
[36m2019-01-29 11:22:46.360 UTC [fsblkstorage] updateCheckpoint -> DEBU 7ce[0m Broadcasting about update checkpointInfo: latestFileChunkSuffixNum=[0], latestFileChunksize=[92875], isChainEmpty=[false], lastBlockNumber=[3]
[36m2019-01-29 11:22:46.360 UTC [orderer/commmon/multichannel] commitBlock -> DEBU 7cf[0m [channel: comunitychannel] Wrote block 3
[36m2019-01-29 11:27:22.115 UTC [orderer/consensus/kafka] try -> DEBU 7d0[0m [channel: testchainid] Connecting to the Kafka cluster
[36m2019-01-29 11:27:22.118 UTC [orderer/consensus/kafka] try -> DEBU 7d1[0m [channel: testchainid] Need to retry because process failed = kafka server: The requested offset is outside the range of offsets maintained by the server for the given topic/partition.
